
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>04 - CONVOLUTIONAL NETWORKS &#8212; Fundamentos de Deep Learning</title>
    
  <link href="../_static/css/theme.css" rel="stylesheet" />
  <link href="../_static/css/index.c5995385ac14fb8791e8eb36b4908be2.css" rel="stylesheet" />

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      

    
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="../_static/sphinx-book-theme.5f77b4aec8189eecf79907ce328c390d.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="../_static/js/index.1c5a1a01449ed65a7b51.js">

    <script id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/togglebutton.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script >var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../_static/sphinx-book-theme.12a9622fbb08dcb3a2a40b2c02b83a57.js"></script>
    <script async="async" src="https://unpkg.com/thebelab@latest/lib/index.js"></script>
    <script >
        const thebe_selector = ".thebe"
        const thebe_selector_input = "pre"
        const thebe_selector_output = ".output"
    </script>
    <script async="async" src="../_static/sphinx-thebe.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="4.1 - Convolutions" href="U4.01%20-%20Convolutions.html" />
    <link rel="prev" title="LAB 3.2 - Low level tensorflow" href="U3%20LAB%2002%20-%20Low%20level%20Tensorflow.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en" />
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../index.html">
      
      <img src="../_static/fudea.jpg" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">Fundamentos de Deep Learning</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">
    <div class="bd-toc-item active">
        <ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../intro.html">
   Welcome
  </a>
 </li>
</ul>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="M00.html">
   Información 20212 - UdeA
  </a>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="M01.html">
   01 - INTRODUCTION
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/>
  <label for="toctree-checkbox-1">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="U1.01%20-%20DL%20Overview.html">
     1.1 - DL Overview
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="U1.02%20-%20Modelos%20derivados%20de%20los%20datos.html">
     1.2 - Models derived from data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="U1.03%20-%20Como%20se%20disena%20un%20algoritmo%20de%20Machine%20Learning.html">
     1.3 - ML algorithm design
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="U1%20LAB%2001%20-%20WARMUP.html">
     LAB 01.01 - WARM UP
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="M02.html">
   02 - NEURAL NETWORKS
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/>
  <label for="toctree-checkbox-2">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="U2.01%20-%20The%20Perceptron.html">
     2.1 - The Perceptron
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="U2.02%20-%20The%20Multilayer%20Perceptron.html">
     2.2 - The Multilayer Perceptron
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="U2.03%20-%20Overfitting%20and%20regularization.html">
     2.3 - Overfitting and regularization
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="U2.04%20-%20Loss%20functions.html">
     2.4 - Loss functions in Tensorflow
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="U2.05%20-%20Network%20Architectures%20-%20Autoencoders.html">
     2.5 - Autoencoders
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="U2.06%20-%20Network%20Architectures%20-%20Multimodal%20information.html">
     2.6 - Multimodal architectures
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="U2.07%20-%20Vanishing%20gradients.html">
     2.7 - Vanishing gradients
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="U2.08%20-%20Weights%20initialization.html">
     2.8 - Weights initialization
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="U2%20LAB%2001%20-%20Customized%20loss%20functions%20and%20regularization.html">
     LAB 2.1 - Customized loss function
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="U2%20LAB%2002%20-%20Autoencoders.html">
     LAB 2.2 - Sparse Autoencoders
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="U2%20LAB%2003%20-%20Pairwise%20image%20classification.html">
     LAB 2.3 - Pairwise classification
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="U2%20LAB%2004%20-%20Model%20instrumentation%20and%20monitoring.html">
     LAB 2.4 - Model instrumentation
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="M03.html">
   03 - TENSORFLOW CORE
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/>
  <label for="toctree-checkbox-3">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="U3.01%20-%20Simbolic%20computing%20for%20ML.html">
     3.1 - Symbolic computing for ML
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="U3.02%20-%20TF%20for%20symbolic%20computing.html">
     3.2 - TF symbolic engine
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="U3.03%20-%20Using%20tf.function.html">
     3.3 - Using
     <code class="docutils literal notranslate">
      <span class="pre">
       tf.function
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="U3.04%20-%20Batch%20Normalization.html">
     3.4 - Batch normalization
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="U3%20LAB%2001%20-%20Tensorflow%20model%20subclassing.html">
     LAB 3.1 - TF model subclassing
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="U3%20LAB%2002%20-%20Low%20level%20Tensorflow.html">
     LAB 3.2 - Low level
     <code class="docutils literal notranslate">
      <span class="pre">
       tensorflow
      </span>
     </code>
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 current active has-children">
  <a class="current reference internal" href="#">
   04 - CONVOLUTIONAL NETWORKS
  </a>
  <input checked="" class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/>
  <label for="toctree-checkbox-4">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="U4.01%20-%20Convolutions.html">
     4.1 - Convolutions
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="U4.02%20-%20Convolutional%20Neural%20Networks.html">
     4.2 - CNNs
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="U4.03%20-%20Dropout%2C%20pooling.html">
     4.3 - Dropout, pooling
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="U4.04%20-%20CNN%20Architectures.html">
     4.4 - CNN Architectures
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="U4.05%20-%20Transfer%20learning.html">
     4.5 - Transfer learning
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="U4.06%20-%20Object%20Detection.html">
     4.6 - Object detection
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="U4.07%20-%20Transposed%20convolutions.html">
     4.7 - Transposed convolutions
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="U4.08%20-%20UNet%20image%20segmentation.html">
     <strong>
      4.8
     </strong>
     - UNet Image segmentation
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="U4.09%20-%20Atrous%20convolutions.html">
     4.9 - Atrous convolutions
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="U4%20LAB%2001%20-%20Convolutions.html">
     LAB 4.1 - Convolutions
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="U4%20LAB%2002%20-%20Transfer%20Learning.html">
     LAB 4.2 - Transfer learning
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="U4%20LAB%2003%20-%20Object%20Detection.html">
     LAB 4.3 - Object detection
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="U4%20LAB%2004%20-%20Semantic%20segmentation.html">
     LAB 4.4 - Semantic segmentation
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="M05.html">
   05 - SEQUENCE MODELS
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" type="checkbox"/>
  <label for="toctree-checkbox-5">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="U5.00%20-%20Intro%20time%20series.html">
     5.0 Crossvalidation in time series
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="U5.01%20-%20Recurrent%20Neural%20Networks.html">
     5.1 Recurrent Neural Networks
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="U5.02%20-%20Long%20Short%20Term%20Memory%20RNN.html">
     5.2 LSTM and GRU
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="U5.03%20-%20Truncated%20BPTT.html">
     5.3 Truncated BPTT
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="U5.04%20-%20Basic%20concepts%20of%20text%20processing.html">
     5.4 Text processing
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="U5.05%20-%20Sequences%20generation%20using%20LSTM.html">
     5.5 Sequences generation
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="U5.06%20-%20Bidirectional%20RNNs%20-%20Attention%20Model.html">
     5.6 Bidirectional RNNs
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="U5.07%20-%20ELMo%20-%20NER.html">
     5.7 ELMo
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="U5.08%20-%20Self-Attention%20-%20Transformer%20-%20BERT.html">
     5.8 Transformer
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="U5.09%20-%20CNN-LSTM%20architectures.html">
     5.9  CNN-LSTM architectures
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="U5%20LAB%2001%20-%20Multivariate%20time%20series%20prediction.html">
     LAB 5.1 - Time series prediction
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="U5%20LAB%2002%20-%20Padding%2C%20Masking%20-%20Sentiment%20Analysis.html">
     LAB 5.2 - Padding - Masking
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="U5%20LAB%2003%20-%20Sentiment%20Analysis%20using%20BERT.html">
     LAB 5.3 - Transformer - BERT
    </a>
   </li>
  </ul>
 </li>
</ul>

    </div>
</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="topbar container-xl fixed-top">
    <div class="topbar-contents row">
        <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show"></div>
        <div class="col pl-md-4 topbar-main">
            
            <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
                data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
                aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
                title="Toggle navigation" data-toggle="tooltip" data-placement="left">
                <i class="fas fa-bars"></i>
                <i class="fas fa-arrow-left"></i>
                <i class="fas fa-arrow-up"></i>
            </button>
            
            
<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="../_sources/content/M04.md"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.md</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
            onClick="window.print()" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
</div>

            <!-- Source interaction buttons -->

            <!-- Full screen (wrap in <a> to have style consistency -->

<a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
        data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
        title="Fullscreen mode"><i
            class="fas fa-expand"></i></button></a>

            <!-- Launch buttons -->

        </div>

        <!-- Table of contents -->
        <div class="d-none d-md-block col-md-2 bd-toc show">
            
            <div class="tocsection onthispage pt-5 pb-3">
                <i class="fas fa-list"></i> Contents
            </div>
            <nav id="bd-toc-nav">
                <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#introduccion">
   Introducción
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#redes-convolucionales">
   Redes convolucionales
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#laboratorio-1">
   LABORATORIO 1
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#arquitecturas-de-redes-convolucionales">
   Arquitecturas de redes convolucionales
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#laboratorio-2">
   LABORATORIO 2
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#deteccion-de-objetos">
   Detección de objetos
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#laboratorio-3">
   LABORATORIO 3
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#segmentacion-semantica">
   Segmentación semántica
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#laboratorio-4">
   LABORATORIO 4
  </a>
 </li>
</ul>

            </nav>
        </div>
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
        
              <div>
                
  <div class="section" id="convolutional-networks">
<h1>04 - CONVOLUTIONAL NETWORKS<a class="headerlink" href="#convolutional-networks" title="Permalink to this headline">¶</a></h1>
<div class="section" id="introduccion">
<h2>Introducción<a class="headerlink" href="#introduccion" title="Permalink to this headline">¶</a></h2>
<p><strong>01 - Tareas de analítica de imágenes</strong>: <a class="reference external" href="https://youtu.be/OTGJTkcaA6k">Video 17mins</a><br/>Revisamos los tipos de tareas de analítica de imágenes más comunes: clasificación, detección de objetos y segmentación.</p>
<p><strong>02 - Construcción de datasets anotados de imágenes</strong>: <a class="reference external" href="https://youtu.be/Ym-XirC4QKM">Video 13mins</a><br/>Mostramos algunos datasets anotados de imágenes para aprendizaje supervisado y discutimos los costos de adquisición, pertinencia respecto a la tarea que tenemos como objetivo, planificación de campañas de adquisición de datos, etc.</p>
<p><strong>03 - Servicios en la nube para analítica de imágenes</strong>: <a class="reference external" href="https://youtu.be/AdI7oTCzNtY">Video 8mins</a><br/> Mostramos algunos servicios en la nube que ofrecen predicciones de modelos ya entrenados.</p>
<p><strong>04 - Ejemplo de modelo de clasificación de imágenes</strong>: <a class="reference external" href="https://youtu.be/Jougllr6bVo">Video 13mins</a><br/>Demostramos el uso <a href="https://teachablemachine.withgoogle.com/">Teaching Machine</a> como ejemplo de juguete para crear un dataset de imágenes, entrenar un modelo y ponerlo en servicio desde el navegador.</p>
</div>
<div class="section" id="redes-convolucionales">
<h2>Redes convolucionales<a class="headerlink" href="#redes-convolucionales" title="Permalink to this headline">¶</a></h2>
<p><strong>05 - Intuición sobre convolución</strong>: <a class="reference external" href="https://youtu.be/RGxdAmOWHF8">Video 13mins</a><br/>Explicamos la noción básica de convolución como una operación entre dos funciones</p>
<p><strong>06 - Convolución 1D: Cálculo y operación</strong>: <a class="reference external" href="https://youtu.be/atUV_bvb5-s">Video 9mins</a><br/>Calculamos con <code class="docutils literal notranslate"><span class="pre">numpy</span></code> y a mano la convolución 1D entre vectores.</p>
<p><strong>07 - Convolución 2D</strong>: <a class="reference external" href="https://youtu.be/HYOFCw6jk9I">Video 11mins</a><br/>Extendemos la noción de convolución a imágenes.</p>
<p><strong>08 - Ejemplo de convoluciones 2D</strong>: <a class="reference external" href="https://youtu.be/imR6mhYSlJM">Video 17mins</a> <br/>Realizamos convoluciones en 2D con las herramientas de <code class="docutils literal notranslate"><span class="pre">numpy</span></code> y de <code class="docutils literal notranslate"><span class="pre">Tensorflow</span></code> y vemos con ejemplos los efectos de distintos tipos de filtros como <em>feature detectors</em>.</p>
<p><strong>09 - Jerarquías de convoluciones 2D</strong>: <a class="reference external" href="https://youtu.be/Li2S7bdda_M">Video 13mins</a> <br/>Explicamos cómo podemos hacer convoluciones 2D sobre el resultado de convoluciones previas, conformando jerarquías de <em>feature detectors</em> de distintos niveles de abstracción.</p>
<p><strong>10 - Ensamblando convoluciones</strong>: <a class="reference external" href="https://youtu.be/XvbKz1ZLamY">Video 14mins</a> <br/>Mostramos cómo finalmente podemos ensamblar distintas capas convolucionales y capas densas (perceptrones) para conformar una <strong>red convolucional</strong> de principio a fin.</p>
<p><strong>11 - Una red convolucional en <code class="docutils literal notranslate"><span class="pre">Tensorflow</span></code></strong>: <a class="reference external" href="https://youtu.be/69NS2FuXbVk">Video 20mins</a> <br/>Finalmente, explicamos cómo construir arquitecturas de redes convolucionales con <code class="docutils literal notranslate"><span class="pre">Tensorflow</span></code> y varios ejemplos prácticos.</p>
<p><strong>12 - Dropout</strong>: <a class="reference external" href="https://youtu.be/4S2Wm90Ac4k">Video 15mins</a> <br/> Detallamos el mecanismo de Dropout como medio de regularización en redes neuronales.</p>
<p><strong>13 - Pooling</strong>: <a class="reference external" href="https://youtu.be/ygOnNOR1G2M">Video 16mins</a> <br/> Detallamos el mecanismo de Pooling como medio de reducción de la dimensionalidad de la salida de las capas convolucionales de una red.</p>
</div>
<div class="section" id="laboratorio-1">
<h2>LABORATORIO 1<a class="headerlink" href="#laboratorio-1" title="Permalink to this headline">¶</a></h2>
<p><strong>LAB 1 - Convolutions</strong>: <a class="reference external" href="https://youtu.be/Cm2nAnWP5js">Video 15mins</a> <br/> En este laboratorio implementarás las convoluciones y operaciones asociadas para consolidar tu entendimiento de las mismas.</p>
</div>
<div class="section" id="arquitecturas-de-redes-convolucionales">
<h2>Arquitecturas de redes convolucionales<a class="headerlink" href="#arquitecturas-de-redes-convolucionales" title="Permalink to this headline">¶</a></h2>
<p><strong>14 - Competencias sobre Imagenet</strong>: <a class="reference external" href="https://youtu.be/As5uhkT0Hb0">Video 10mins</a> <br/> Describimos el conjunto de competencias asociadas al dataset de Imagenet a través de las cuales
evolucionó el campo de las redes convolucionales desde 2012.</p>
<p><strong>15 - AlexNet y VGG</strong>: <a class="reference external" href="https://youtu.be/dYGFOVuSQg0">Video 13mins</a> <br/> Describimos las arquitecturas de <code class="docutils literal notranslate"><span class="pre">AlexNet</span></code> y <code class="docutils literal notranslate"><span class="pre">VGG</span></code>, que fueron abrieron el camino para el uso de CNNs para imágenes de manera generalizada y que, a día de hoy, constituyen puntos de partida excelentes para empezar a abordar cualquier problema nuevo.</p>
<p><strong>16 - ResNet</strong>: <a class="reference external" href="https://youtu.be/5l5Wivk1YKM">Video 6mins</a> <br/> Describimos la familia de redes de <code class="docutils literal notranslate"><span class="pre">ResNet</span></code>, basadas en aprender los residuales incrementales entre las entradas y las salidas de las capas.</p>
<p><strong>17 - Inception and 1x1 convolutions</strong>: <a class="reference external" href="https://youtu.be/PCp0jBm8TKU">Video 12 mins</a> <br/> Explicamos las convoluciones 1x1 como medio para reducir la dimensionalidad en los canales de cualquier mapa de activación, y describimos la familia de redes <code class="docutils literal notranslate"><span class="pre">Inception</span></code> que usan filtros de distintas resoluciones en una misma capa.</p>
<p><strong>18 - Usando arquitecturas de Redes Convolucionales</strong>: <a class="reference external" href="https://youtu.be/1a5UlX7q_l8">Video 18 mins</a> <br/> Demostramos cómo usar las redes preentrenadas disponibles dentro de <code class="docutils literal notranslate"><span class="pre">tensorflow.keras.applications</span></code> e introducimos el repositorio de modelos de <a class="reference external" href="https://www.tensorflow.org/hub">Tensorflow Hub</a>.</p>
<p><strong>19 - Transfer learning</strong>: <a class="reference external" href="https://youtu.be/apLFNuWgMcg">Video 15mins</a> <br/> Explicamos cómo usar transfer learning para reutilizar redes preentrenadas en nuestros problemas específicos.</p>
<p><strong>20 - Ejemplo de transfer learning</strong>: <a class="reference external" href="https://youtu.be/uWBg1Nr71nI">Video 17mins</a> <br/> Implementamos y analizamos un ejemplo de transfer learning desde AlexNet a nuestro problema de clasificación de imágenes con un subconjunto del dataset CIFAR.</p>
</div>
<div class="section" id="laboratorio-2">
<h2>LABORATORIO 2<a class="headerlink" href="#laboratorio-2" title="Permalink to this headline">¶</a></h2>
<p><strong>LAB 2 - Transfer learning</strong>: <a class="reference external" href="https://youtu.be/8STIz10xCYo">Video 20mins</a> <br/> En este laboratorio usarás modelos publicados en <a class="reference external" href="https://www.tensorflow.org/hub"><code class="docutils literal notranslate"><span class="pre">tensorflow</span> <span class="pre">hub</span></code></a> para distintas tareas de transfer learning.</p>
</div>
<div class="section" id="deteccion-de-objetos">
<h2>Detección de objetos<a class="headerlink" href="#deteccion-de-objetos" title="Permalink to this headline">¶</a></h2>
<p><strong>21 - Introducción a la detección de objetos</strong>: <a class="reference external" href="https://youtu.be/HnL9DdRvLdE">Video 5mins</a><br/>
Describimos la tarea de detección de objetos y los retos que se presentan en términos de datasets y arquitecturas de redes.</p>
<p><strong>22 - Datasets para la detección de objetos</strong>: <a class="reference external" href="https://youtu.be/rZeZJcnvEbk">Video 10mins</a><br/>Mostramos la organización de un dataset anotado para detección de objetos, tomando como ejemplo <a class="reference external" href="https://storage.googleapis.com/openimages/web/index.html">Open Images V6 Dataset</a>.</p>
<p><strong>23 - Two stage detectors</strong>: <a class="reference external" href="https://youtu.be/k9ZK4gMNBCY">Video 12mins</a><br/>Explicamos el mecanismo de funcionamiento de los detectores de dos etapas: una de propuesta de regiones, seguida por una clasificación.</p>
<p><strong>24 - Two stage detectors example</strong>: <a class="reference external" href="https://youtu.be/-afkumzSNlA">Video 11mins</a><br/>Mostramos un ejemplo de clasificación de parches de imágenes con distintos modelos para un esquema de detección de dos etapas, junto con las dificultades y retos que plantea.</p>
<p><strong>25 - One stage detectors</strong>: <a class="reference external" href="https://youtu.be/0DfsPWXdc8o">Video 15mins</a><br/>Describimos los principios de los detectores de una etapa y cómo se organiza la salida que esperamos de una red convolucional de detección de objetos.</p>
<p><strong>26 - Definiendo anchor boxes</strong>: <a class="reference external" href="https://youtu.be/l6JVUahbDpA">Video 10mins</a> <br/>Explicamos cómo generar un conjunto de anchor boxes (region priors) para nuestro detector de una etapa, basado en clustering con KMeans.</p>
<p><strong>27 - Función de pérdida</strong>: <a class="reference external" href="https://youtu.be/s8zU6G9-pvI">Video 15mins</a> <br/> Explicamos cómo se construye la salida de una red de detección de objetos con convoluciones 1x1 y mostramos los componentes de la función de pérdida para entrenamiento.</p>
<p><strong>28 - Arquitecturas para la detección de objetos</strong>: <a class="reference external" href="https://youtu.be/wSFo4MmuLkU">Video 14mins</a> <br/>Mencionamos algunas de las arquitecturas más utilizadas para la detección de objetos y sus principios generales.</p>
</div>
<div class="section" id="laboratorio-3">
<h2>LABORATORIO 3<a class="headerlink" href="#laboratorio-3" title="Permalink to this headline">¶</a></h2>
<p><strong>LAB 3 - Detección de objetos</strong>: <a class="reference external" href="https://youtu.be/3CXkVJeP1iw">Video 15mins</a> <br/>En este laboratorio te familiarizarás con las estructuras de salida de una red de detección de objetos.</p>
</div>
<div class="section" id="segmentacion-semantica">
<h2>Segmentación semántica<a class="headerlink" href="#segmentacion-semantica" title="Permalink to this headline">¶</a></h2>
<p><strong>29 - Introducción a la segmentación</strong>: <a class="reference external" href="https://youtu.be/Ow67kIz_Et0">Video 13mins</a> <br/>
Revisamos los datalles de la segmentación de imágenes y los retos que nos genera.</p>
<p><strong>30 - Tipos de convoluciones</strong>: <a class="reference external" href="https://youtu.be/4mlK2gEKch8">Video 15mins</a> <br/>
Revisamos las tipos de convoluciones vistos hasta ahora (strided, 1x1) y vemos cómo
se pueden generar nuevos tipos de convoluciones maniplando los filtros o las imágenes
previamente a realizar la operación de convolución en sí.</p>
<p><strong>31 - Convoluciones transpuestas</strong>: <a class="reference external" href="https://youtu.be/a4kyQqJF1Wg">Video 15mins</a> <br/>
Explicamos cómo se realiza una convolución transpuesta y cómo nos puede ayudar a aumentar las
dimensiones de los mapas de activación en una red convolucional.</p>
<p><strong>32 - Intuición de las convoluciones transpuestas</strong>: <a class="reference external" href="https://youtu.be/k18Ru0x5quE">Video 17mins</a> <br/>
Realizamos algunos experimentos con tensorflow para reforzar la intuición sobre las convoluciones transpuestas.</p>
<p><strong>33 - La arquitectura UNet</strong>: <a class="reference external" href="https://youtu.be/e9Q57NKPwr8">Video 18mins</a> <br/>
Describimos la arquitectura de UNet, que es un buen punto de partida para muchos problemas
de segmentación de imágenes, por su sencillez y eficacia.</p>
<p><strong>34 - Convoluciones atrous</strong>: <a class="reference external" href="https://youtu.be/e_z7FAJp17k">Video 13mins</a> <br/>
Explicamos el mecanismo y la intuición de las convoluciones atrous, usadas en varias arquitecturas
de redes convolucionales para la segmentación.</p>
<p><strong>35 - Arquitecturas de segmentación</strong>: <a class="reference external" href="https://youtu.be/0wu9lobsmpY">Video 15mins</a><br/>
Describimos brevemente las arquitecturas de Mask R-CNN y DeepLap, así como los conceptos
de <b>Backbone</b> y <b>Spatial Pyramids</b> que se usan en muchas architecturas.</p>
</div>
<div class="section" id="laboratorio-4">
<h2>LABORATORIO 4<a class="headerlink" href="#laboratorio-4" title="Permalink to this headline">¶</a></h2>
<p><strong>LAB 4 - Segmentación de objectos</strong>: <a class="reference external" href="https://youtu.be/802-ncXnHBg">Video 12mins</a><br/>
En este laboratorio crearás architecturas de segmentación basadas en UNet para poder apreciar
los efectos de sus distintos componentes.</p>
<div class="toctree-wrapper compound">
</div>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./content"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
        
        <div class='prev-next-bottom'>
            
    <a class='left-prev' id="prev-link" href="U3%20LAB%2002%20-%20Low%20level%20Tensorflow.html" title="previous page">LAB 3.2 - Low level <code class="docutils literal notranslate"><span class="pre">tensorflow</span></code></a>
    <a class='right-next' id="next-link" href="U4.01%20-%20Convolutions.html" title="next page">4.1 - Convolutions</a>

        </div>
        
        </div>
    </div>
    <footer class="footer mt-5 mt-md-0">
    <div class="container">
      <p>
        
          By Raúl Ramos, Julián Arias / Universidad de Antioquia<br/>
        
            &copy; Copyright 2020.<br/>
      </p>
    </div>
  </footer>
</main>


      </div>
    </div>
  
  <script src="../_static/js/index.1c5a1a01449ed65a7b51.js"></script>

  
<script async="" src="https://www.google-analytics.com/analytics.js"></script>
<script>
                        window.ga = window.ga || function () {
                            (ga.q = ga.q || []).push(arguments) };
                        ga.l = +new Date;
                        ga('create', 'UA-43235448-3', 'auto');
                        ga('set', 'anonymizeIp', true);
                        ga('send', 'pageview');
                    </script>

  </body>
</html>