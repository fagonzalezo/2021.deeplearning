{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The aim of this lab is to build a system for sentiment analysis on a dataset of tweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget --no-cache -O init.py -q https://raw.githubusercontent.com/rramosp/2020.deeplearning/master/init.py\n",
    "from init import init; init(force_download=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "if 'google.colab' in sys.modules:\n",
    "    print (\"setting tensorflow version in colab\")\n",
    "    %tensorflow_version 2.x\n",
    "import tensorflow as tf\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data consist on passenger's reviews of U.S. airlines: https://www.kaggle.com/crowdflower/twitter-airline-sentiment "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('2020.deeplearning/local/data/Tweets.csv')\n",
    "# Keeping only the neccessary columns\n",
    "data = data[['text','airline_sentiment']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>airline_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@VirginAmerica What @dhepburn said.</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@VirginAmerica plus you've added commercials t...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@VirginAmerica I didn't today... Must mean I n...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@VirginAmerica it's really aggressive to blast...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@VirginAmerica and it's a really big bad thing...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14635</th>\n",
       "      <td>@AmericanAir thank you we got on a different f...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14636</th>\n",
       "      <td>@AmericanAir leaving over 20 minutes Late Flig...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14637</th>\n",
       "      <td>@AmericanAir Please bring American Airlines to...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14638</th>\n",
       "      <td>@AmericanAir you have my money, you change my ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14639</th>\n",
       "      <td>@AmericanAir we have 8 ppl so we need 2 know h...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14640 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text airline_sentiment\n",
       "0                    @VirginAmerica What @dhepburn said.           neutral\n",
       "1      @VirginAmerica plus you've added commercials t...          positive\n",
       "2      @VirginAmerica I didn't today... Must mean I n...           neutral\n",
       "3      @VirginAmerica it's really aggressive to blast...          negative\n",
       "4      @VirginAmerica and it's a really big bad thing...          negative\n",
       "...                                                  ...               ...\n",
       "14635  @AmericanAir thank you we got on a different f...          positive\n",
       "14636  @AmericanAir leaving over 20 minutes Late Flig...          negative\n",
       "14637  @AmericanAir Please bring American Airlines to...           neutral\n",
       "14638  @AmericanAir you have my money, you change my ...          negative\n",
       "14639  @AmericanAir we have 8 ppl so we need 2 know h...           neutral\n",
       "\n",
       "[14640 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2363\n",
      "9178\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "#Remove neutral class\n",
    "data = data[data.airline_sentiment != \"neutral\"]\n",
    "\n",
    "#text normalization\n",
    "data['text'] = data['text'].apply(lambda x: x.lower())\n",
    "data['text'] = data['text'].apply((lambda x:re.sub('@[^\\s]+','',x)))#remove the name of the airline\n",
    "data['text'] = data['text'].apply((lambda x: re.sub('[^a-zA-z0-9\\s]','',x)))\n",
    "print(np.sum(data['airline_sentiment'].values == 'positive'))\n",
    "print(np.sum(data['airline_sentiment'].values == 'negative'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>airline_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>plus youve added commercials to the experienc...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>its really aggressive to blast obnoxious ente...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>and its a really big bad thing about it</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>seriously would pay 30 a flight for seats tha...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>yes nearly every time i fly vx this ear worm ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14633</th>\n",
       "      <td>my flight was cancelled flightled leaving tom...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14634</th>\n",
       "      <td>right on cue with the delays</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14635</th>\n",
       "      <td>thank you we got on a different flight to chi...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14636</th>\n",
       "      <td>leaving over 20 minutes late flight no warnin...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14638</th>\n",
       "      <td>you have my money you change my flight and do...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11541 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text airline_sentiment\n",
       "1       plus youve added commercials to the experienc...          positive\n",
       "3       its really aggressive to blast obnoxious ente...          negative\n",
       "4                and its a really big bad thing about it          negative\n",
       "5       seriously would pay 30 a flight for seats tha...          negative\n",
       "6       yes nearly every time i fly vx this ear worm ...          positive\n",
       "...                                                  ...               ...\n",
       "14633   my flight was cancelled flightled leaving tom...          negative\n",
       "14634                       right on cue with the delays          negative\n",
       "14635   thank you we got on a different flight to chi...          positive\n",
       "14636   leaving over 20 minutes late flight no warnin...          negative\n",
       "14638   you have my money you change my flight and do...          negative\n",
       "\n",
       "[11541 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx,row in data.iterrows():\n",
    "    row[0] = row[0].replace('rt',' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>airline_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>plus youve added commercials to the experienc...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>its really aggressive to blast obnoxious ente...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>and its a really big bad thing about it</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>seriously would pay 30 a flight for seats tha...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>yes nearly every time i fly vx this ear worm ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14633</th>\n",
       "      <td>my flight was cancelled flightled leaving tom...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14634</th>\n",
       "      <td>right on cue with the delays</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14635</th>\n",
       "      <td>thank you we got on a different flight to chi...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14636</th>\n",
       "      <td>leaving over 20 minutes late flight no warnin...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14638</th>\n",
       "      <td>you have my money you change my flight and do...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11541 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text airline_sentiment\n",
       "1       plus youve added commercials to the experienc...          positive\n",
       "3       its really aggressive to blast obnoxious ente...          negative\n",
       "4                and its a really big bad thing about it          negative\n",
       "5       seriously would pay 30 a flight for seats tha...          negative\n",
       "6       yes nearly every time i fly vx this ear worm ...          positive\n",
       "...                                                  ...               ...\n",
       "14633   my flight was cancelled flightled leaving tom...          negative\n",
       "14634                       right on cue with the delays          negative\n",
       "14635   thank you we got on a different flight to chi...          positive\n",
       "14636   leaving over 20 minutes late flight no warnin...          negative\n",
       "14638   you have my money you change my flight and do...          negative\n",
       "\n",
       "[11541 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/julian/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /home/julian/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing Stop Words\n",
    "from nltk.corpus import stopwords\n",
    "all_sentences = data['text'].values\n",
    "all_words = [nltk.word_tokenize(sent) for sent in all_sentences]\n",
    "stop_words = stopwords.words('english')\n",
    "stop_words.append('')\n",
    "\n",
    "for i in range(len(all_words)):  \n",
    "    all_words[i] = [w for w in all_words[i] if w not in stop_words]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1\n",
    "\n",
    "all_words is a list with all the tweets that are going to be used to train the model. Tokenize the tweets using a dictionary of 2000 words. Once the sentences are tokenized, take into account that the length of every tweet is different so before they can be passed to the training step, the tweets must be **padded** in order to provide them with equal length.\n",
    "\n",
    "Review the padding function in the preprocessing module of keras and apply it to the tokenized sequences. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "max_fatures = 2001\n",
    "tokenizer = Tokenizer(num_words=max_fatures, split=' ')\n",
    "tokenizer.fit_on_texts(all_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tokenizer.texts_to_sequences(all_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "NewX = pad_sequences(sequences=X, padding=\"post\", value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11541, 21)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NewX.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2\n",
    "\n",
    "The previous step add 0's to some tweets in order to provide them with the same length. Now it is necessary to define a model that be able to discard those 0's. Review the masking layer and masking option of the embedding layer of keras. \n",
    "\n",
    "Define a LSTM architecture to classify the tweets as \"negative\" or \"positive\". Use the Embedding layer and its masking option to discard the 0's added during padding step. Evaluate the performance of the model for embed_dim = [32,64,128] and a LSTM layer with cells = [32,64,128]. Use 20% of the data for testing purposes and 10 epochs for training. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "y = data['airline_sentiment'].values\n",
    "Encoder = LabelEncoder()\n",
    "Encoder.fit(np.unique(y))\n",
    "Y = Encoder.transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.layers import LSTM, Embedding, Dense, Input, Conv1D, Flatten, Dropout, GlobalMaxPooling1D\n",
    "from tensorflow.keras import optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Model_Sentimen(Embeb,cells):\n",
    "    model = Sequential([\n",
    "        Embedding(input_dim=max_fatures, output_dim=Embeb, mask_zero=True),\n",
    "        LSTM(cells,activation='relu'),\n",
    "        Dense(10,activation='relu'),\n",
    "        Dropout(0.3),\n",
    "        Dense(1,activation='sigmoid')\n",
    "    ])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_tr, X_te, y_tr, y_te = train_test_split(NewX, Y, test_size=0.2, random_state=2018)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import recall_score, accuracy_score\n",
    "from sklearn.utils.class_weight import compute_class_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def especi_score(y_te,y_pred):\n",
    "    Ns = np.sum(y_te == 0)\n",
    "    return np.sum(y_te[y_te == 0] == y_pred[y_te == 0])/Ns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8308 samples, validate on 924 samples\n",
      "Epoch 1/10\n",
      "8308/8308 [==============================] - 2s 290us/sample - loss: 0.4047 - accuracy: 0.8315 - val_loss: 0.2892 - val_accuracy: 0.9080\n",
      "Epoch 2/10\n",
      "8308/8308 [==============================] - 2s 181us/sample - loss: 0.2064 - accuracy: 0.9253 - val_loss: 0.3267 - val_accuracy: 0.9058\n",
      "Epoch 3/10\n",
      "8308/8308 [==============================] - 1s 178us/sample - loss: 0.1544 - accuracy: 0.9405 - val_loss: 0.3455 - val_accuracy: 0.9015\n",
      "Epoch 4/10\n",
      "8308/8308 [==============================] - 1s 179us/sample - loss: 0.1294 - accuracy: 0.9498 - val_loss: 0.4853 - val_accuracy: 0.9026\n",
      "Epoch 5/10\n",
      "8308/8308 [==============================] - 2s 183us/sample - loss: 0.1093 - accuracy: 0.9573 - val_loss: 0.5668 - val_accuracy: 0.9037\n",
      "Epoch 6/10\n",
      "8308/8308 [==============================] - 2s 181us/sample - loss: 0.0925 - accuracy: 0.9652 - val_loss: 0.4965 - val_accuracy: 0.9026\n",
      "Epoch 7/10\n",
      "8308/8308 [==============================] - 1s 180us/sample - loss: 0.0848 - accuracy: 0.9682 - val_loss: 0.8476 - val_accuracy: 0.9015\n",
      "Epoch 8/10\n",
      "8308/8308 [==============================] - 2s 183us/sample - loss: 0.0704 - accuracy: 0.9721 - val_loss: 0.9658 - val_accuracy: 0.8994\n",
      "Epoch 9/10\n",
      "8308/8308 [==============================] - 1s 180us/sample - loss: 0.0652 - accuracy: 0.9765 - val_loss: 1.4710 - val_accuracy: 0.9015\n",
      "Epoch 10/10\n",
      "8308/8308 [==============================] - 1s 178us/sample - loss: 0.0790 - accuracy: 0.9768 - val_loss: 0.7469 - val_accuracy: 0.8994\n",
      "Train on 8308 samples, validate on 924 samples\n",
      "Epoch 1/10\n",
      "8308/8308 [==============================] - 3s 308us/sample - loss: 0.3760 - accuracy: 0.8500 - val_loss: 0.2804 - val_accuracy: 0.8972\n",
      "Epoch 2/10\n",
      "8308/8308 [==============================] - 2s 203us/sample - loss: 0.1939 - accuracy: 0.9256 - val_loss: 0.2696 - val_accuracy: 0.9015\n",
      "Epoch 3/10\n",
      "8308/8308 [==============================] - 2s 205us/sample - loss: 0.1483 - accuracy: 0.9422 - val_loss: 0.3493 - val_accuracy: 0.8972\n",
      "Epoch 4/10\n",
      "8308/8308 [==============================] - 2s 204us/sample - loss: 0.1245 - accuracy: 0.9486 - val_loss: 0.5741 - val_accuracy: 0.9026\n",
      "Epoch 5/10\n",
      "8308/8308 [==============================] - 2s 203us/sample - loss: 0.1137 - accuracy: 0.9578 - val_loss: 0.4117 - val_accuracy: 0.8972\n",
      "Epoch 6/10\n",
      "8308/8308 [==============================] - 2s 203us/sample - loss: 0.0968 - accuracy: 0.9629 - val_loss: 0.6026 - val_accuracy: 0.9037\n",
      "Epoch 7/10\n",
      "8308/8308 [==============================] - 2s 204us/sample - loss: 0.0836 - accuracy: 0.9673 - val_loss: 0.6456 - val_accuracy: 0.9004\n",
      "Epoch 8/10\n",
      "8308/8308 [==============================] - 2s 205us/sample - loss: 0.0742 - accuracy: 0.9716 - val_loss: 1.1333 - val_accuracy: 0.9048\n",
      "Epoch 9/10\n",
      "8308/8308 [==============================] - 2s 202us/sample - loss: 0.0677 - accuracy: 0.9729 - val_loss: 1.5976 - val_accuracy: 0.9048\n",
      "Epoch 10/10\n",
      "8308/8308 [==============================] - 2s 207us/sample - loss: 0.0641 - accuracy: 0.9742 - val_loss: 1.3455 - val_accuracy: 0.9004\n",
      "Train on 8308 samples, validate on 924 samples\n",
      "Epoch 1/10\n",
      "8308/8308 [==============================] - 3s 391us/sample - loss: 0.4140 - accuracy: 0.8300 - val_loss: 0.3225 - val_accuracy: 0.8983\n",
      "Epoch 2/10\n",
      "8308/8308 [==============================] - 2s 279us/sample - loss: 0.2060 - accuracy: 0.9271 - val_loss: 0.2701 - val_accuracy: 0.9058\n",
      "Epoch 3/10\n",
      "8308/8308 [==============================] - 2s 279us/sample - loss: 0.1515 - accuracy: 0.9434 - val_loss: 0.2901 - val_accuracy: 0.9048\n",
      "Epoch 4/10\n",
      "8308/8308 [==============================] - 2s 274us/sample - loss: 0.1271 - accuracy: 0.9550 - val_loss: 0.3733 - val_accuracy: 0.8929\n",
      "Epoch 5/10\n",
      "8308/8308 [==============================] - 2s 280us/sample - loss: 0.2819 - accuracy: 0.9580 - val_loss: 0.3498 - val_accuracy: 0.8994\n",
      "Epoch 6/10\n",
      "8308/8308 [==============================] - 2s 275us/sample - loss: 0.0890 - accuracy: 0.9655 - val_loss: 0.6065 - val_accuracy: 0.9004\n",
      "Epoch 7/10\n",
      "8308/8308 [==============================] - 2s 276us/sample - loss: 0.0748 - accuracy: 0.9681 - val_loss: 1.3340 - val_accuracy: 0.8918\n",
      "Epoch 8/10\n",
      "8308/8308 [==============================] - 2s 274us/sample - loss: 0.0669 - accuracy: 0.9717 - val_loss: 2.3839 - val_accuracy: 0.9004\n",
      "Epoch 9/10\n",
      "8308/8308 [==============================] - 2s 273us/sample - loss: 0.0525 - accuracy: 0.9801 - val_loss: 2.0887 - val_accuracy: 0.8896\n",
      "Epoch 10/10\n",
      "8308/8308 [==============================] - 2s 278us/sample - loss: 0.0466 - accuracy: 0.9800 - val_loss: 1.9959 - val_accuracy: 0.8950\n",
      "Train on 8308 samples, validate on 924 samples\n",
      "Epoch 1/10\n",
      "8308/8308 [==============================] - 2s 296us/sample - loss: 0.3971 - accuracy: 0.8327 - val_loss: 0.2693 - val_accuracy: 0.9058\n",
      "Epoch 2/10\n",
      "8308/8308 [==============================] - 2s 186us/sample - loss: 0.2017 - accuracy: 0.9224 - val_loss: 0.2642 - val_accuracy: 0.9026\n",
      "Epoch 3/10\n",
      "8308/8308 [==============================] - 2s 181us/sample - loss: 0.1491 - accuracy: 0.9409 - val_loss: 0.2953 - val_accuracy: 0.9015\n",
      "Epoch 4/10\n",
      "8308/8308 [==============================] - 2s 182us/sample - loss: 0.1249 - accuracy: 0.9509 - val_loss: 0.3369 - val_accuracy: 0.8972\n",
      "Epoch 5/10\n",
      "8308/8308 [==============================] - 2s 183us/sample - loss: 0.1043 - accuracy: 0.9621 - val_loss: 0.4329 - val_accuracy: 0.9015\n",
      "Epoch 6/10\n",
      "8308/8308 [==============================] - 2s 185us/sample - loss: 0.0907 - accuracy: 0.9664 - val_loss: 0.4969 - val_accuracy: 0.8983\n",
      "Epoch 7/10\n",
      "8308/8308 [==============================] - 2s 188us/sample - loss: 0.0778 - accuracy: 0.9706 - val_loss: 0.6731 - val_accuracy: 0.8972\n",
      "Epoch 8/10\n",
      "8308/8308 [==============================] - 2s 184us/sample - loss: 0.0660 - accuracy: 0.9735 - val_loss: 0.9030 - val_accuracy: 0.8939\n",
      "Epoch 9/10\n",
      "8308/8308 [==============================] - 2s 185us/sample - loss: 0.0606 - accuracy: 0.9774 - val_loss: 0.6491 - val_accuracy: 0.8929\n",
      "Epoch 10/10\n",
      "8308/8308 [==============================] - 2s 182us/sample - loss: 0.0545 - accuracy: 0.9788 - val_loss: 0.5706 - val_accuracy: 0.8961\n",
      "Train on 8308 samples, validate on 924 samples\n",
      "Epoch 1/10\n",
      "8308/8308 [==============================] - 3s 314us/sample - loss: 0.3691 - accuracy: 0.8420 - val_loss: 0.2849 - val_accuracy: 0.9026\n",
      "Epoch 2/10\n",
      "8308/8308 [==============================] - 2s 207us/sample - loss: 0.2162 - accuracy: 0.9200 - val_loss: 0.2876 - val_accuracy: 0.9058\n",
      "Epoch 3/10\n",
      "8308/8308 [==============================] - 2s 208us/sample - loss: 0.1640 - accuracy: 0.9446 - val_loss: 0.3342 - val_accuracy: 0.9037\n",
      "Epoch 4/10\n",
      "8308/8308 [==============================] - 2s 210us/sample - loss: 0.1392 - accuracy: 0.9521 - val_loss: 0.4059 - val_accuracy: 0.8983\n",
      "Epoch 5/10\n",
      "8308/8308 [==============================] - 2s 209us/sample - loss: 0.1241 - accuracy: 0.9599 - val_loss: 0.5818 - val_accuracy: 0.8961\n",
      "Epoch 6/10\n",
      "8308/8308 [==============================] - 2s 208us/sample - loss: 0.1040 - accuracy: 0.9681 - val_loss: 1.3723 - val_accuracy: 0.8907\n",
      "Epoch 7/10\n",
      "8308/8308 [==============================] - 2s 209us/sample - loss: 0.0956 - accuracy: 0.9677 - val_loss: 0.7685 - val_accuracy: 0.8929\n",
      "Epoch 8/10\n",
      "8308/8308 [==============================] - 2s 208us/sample - loss: 0.0777 - accuracy: 0.9716 - val_loss: 0.8055 - val_accuracy: 0.8842\n",
      "Epoch 9/10\n",
      "8308/8308 [==============================] - 2s 209us/sample - loss: 0.0660 - accuracy: 0.9754 - val_loss: 0.9694 - val_accuracy: 0.8885\n",
      "Epoch 10/10\n",
      "8308/8308 [==============================] - 2s 209us/sample - loss: 0.0585 - accuracy: 0.9788 - val_loss: 1.4696 - val_accuracy: 0.8810\n",
      "Train on 8308 samples, validate on 924 samples\n",
      "Epoch 1/10\n",
      "8308/8308 [==============================] - 3s 385us/sample - loss: 0.3679 - accuracy: 0.8410 - val_loss: 0.2534 - val_accuracy: 0.8994\n",
      "Epoch 2/10\n",
      "8308/8308 [==============================] - 2s 283us/sample - loss: 0.1905 - accuracy: 0.9310 - val_loss: 0.2594 - val_accuracy: 0.9026\n",
      "Epoch 3/10\n",
      "8308/8308 [==============================] - 2s 283us/sample - loss: 0.1548 - accuracy: 0.9438 - val_loss: 0.2889 - val_accuracy: 0.9026\n",
      "Epoch 4/10\n",
      "8308/8308 [==============================] - 2s 281us/sample - loss: 0.1239 - accuracy: 0.9545 - val_loss: 0.3980 - val_accuracy: 0.9037\n",
      "Epoch 5/10\n",
      "8308/8308 [==============================] - 2s 281us/sample - loss: 0.1074 - accuracy: 0.9575 - val_loss: 0.4600 - val_accuracy: 0.8983\n",
      "Epoch 6/10\n",
      "8308/8308 [==============================] - 2s 281us/sample - loss: 0.1040 - accuracy: 0.9647 - val_loss: 0.8019 - val_accuracy: 0.8950\n",
      "Epoch 7/10\n",
      "8308/8308 [==============================] - 2s 281us/sample - loss: 0.0785 - accuracy: 0.9701 - val_loss: 1.5221 - val_accuracy: 0.8950\n",
      "Epoch 8/10\n",
      "8308/8308 [==============================] - 2s 281us/sample - loss: 0.0657 - accuracy: 0.9746 - val_loss: 1.4993 - val_accuracy: 0.8972\n",
      "Epoch 9/10\n",
      "8308/8308 [==============================] - 2s 281us/sample - loss: 0.0572 - accuracy: 0.9771 - val_loss: 2.1790 - val_accuracy: 0.8918\n",
      "Epoch 10/10\n",
      "8308/8308 [==============================] - 2s 281us/sample - loss: 0.0508 - accuracy: 0.9811 - val_loss: 2.4603 - val_accuracy: 0.8907\n",
      "Train on 8308 samples, validate on 924 samples\n",
      "Epoch 1/10\n",
      "8308/8308 [==============================] - 3s 306us/sample - loss: 0.4170 - accuracy: 0.8435 - val_loss: 0.2657 - val_accuracy: 0.9069\n",
      "Epoch 2/10\n",
      "8308/8308 [==============================] - 2s 199us/sample - loss: 0.2110 - accuracy: 0.9249 - val_loss: 0.2666 - val_accuracy: 0.9091\n",
      "Epoch 3/10\n",
      "8308/8308 [==============================] - 2s 199us/sample - loss: 0.1629 - accuracy: 0.9452 - val_loss: 0.2829 - val_accuracy: 0.9026\n",
      "Epoch 4/10\n",
      "8308/8308 [==============================] - 2s 199us/sample - loss: 0.1321 - accuracy: 0.9562 - val_loss: 0.3714 - val_accuracy: 0.8983\n",
      "Epoch 5/10\n",
      "8308/8308 [==============================] - 2s 198us/sample - loss: 0.1041 - accuracy: 0.9655 - val_loss: 0.5489 - val_accuracy: 0.9015\n",
      "Epoch 6/10\n",
      "8308/8308 [==============================] - 2s 199us/sample - loss: 0.0944 - accuracy: 0.9687 - val_loss: 0.6692 - val_accuracy: 0.9004\n",
      "Epoch 7/10\n",
      "8308/8308 [==============================] - 2s 201us/sample - loss: 0.0741 - accuracy: 0.9726 - val_loss: 0.7260 - val_accuracy: 0.8929\n",
      "Epoch 8/10\n",
      "8308/8308 [==============================] - 2s 204us/sample - loss: 0.0642 - accuracy: 0.9768 - val_loss: 0.7598 - val_accuracy: 0.8874\n",
      "Epoch 9/10\n",
      "8308/8308 [==============================] - 2s 195us/sample - loss: 0.0520 - accuracy: 0.9813 - val_loss: 0.9642 - val_accuracy: 0.8983\n",
      "Epoch 10/10\n",
      "8308/8308 [==============================] - 2s 197us/sample - loss: 0.0427 - accuracy: 0.9831 - val_loss: 1.3138 - val_accuracy: 0.8874\n",
      "Train on 8308 samples, validate on 924 samples\n",
      "Epoch 1/10\n",
      "8308/8308 [==============================] - 3s 370us/sample - loss: 0.3873 - accuracy: 0.8463 - val_loss: 0.2669 - val_accuracy: 0.9015\n",
      "Epoch 2/10\n",
      "8308/8308 [==============================] - 2s 230us/sample - loss: 0.1978 - accuracy: 0.9160 - val_loss: 0.2683 - val_accuracy: 0.9015\n",
      "Epoch 3/10\n",
      "8308/8308 [==============================] - 2s 224us/sample - loss: 0.1554 - accuracy: 0.9381 - val_loss: 0.3247 - val_accuracy: 0.8983\n",
      "Epoch 4/10\n",
      "8308/8308 [==============================] - 2s 227us/sample - loss: 0.1275 - accuracy: 0.9515 - val_loss: 0.3928 - val_accuracy: 0.9015\n",
      "Epoch 5/10\n",
      "8308/8308 [==============================] - 2s 227us/sample - loss: 0.1134 - accuracy: 0.9585 - val_loss: 0.3126 - val_accuracy: 0.8994\n",
      "Epoch 6/10\n",
      "8308/8308 [==============================] - 2s 226us/sample - loss: 0.0979 - accuracy: 0.9643 - val_loss: 0.4849 - val_accuracy: 0.8907\n",
      "Epoch 7/10\n",
      "8308/8308 [==============================] - 2s 225us/sample - loss: 0.0825 - accuracy: 0.9688 - val_loss: 0.4976 - val_accuracy: 0.8788\n",
      "Epoch 8/10\n",
      "8308/8308 [==============================] - 2s 232us/sample - loss: 0.0683 - accuracy: 0.9748 - val_loss: 0.9601 - val_accuracy: 0.8831\n",
      "Epoch 9/10\n",
      "8308/8308 [==============================] - 2s 234us/sample - loss: 0.0666 - accuracy: 0.9742 - val_loss: 0.7940 - val_accuracy: 0.8896\n",
      "Epoch 10/10\n",
      "8308/8308 [==============================] - 2s 227us/sample - loss: 0.0580 - accuracy: 0.9788 - val_loss: 0.8704 - val_accuracy: 0.8939\n",
      "Train on 8308 samples, validate on 924 samples\n",
      "Epoch 1/10\n",
      "8308/8308 [==============================] - 3s 410us/sample - loss: 0.4433 - accuracy: 0.8392 - val_loss: 0.2771 - val_accuracy: 0.9069\n",
      "Epoch 2/10\n",
      "8308/8308 [==============================] - 3s 308us/sample - loss: 0.2176 - accuracy: 0.9233 - val_loss: 0.3349 - val_accuracy: 0.8983\n",
      "Epoch 3/10\n",
      "8308/8308 [==============================] - 3s 309us/sample - loss: 0.1632 - accuracy: 0.9411 - val_loss: 0.2863 - val_accuracy: 0.8939\n",
      "Epoch 4/10\n",
      "8308/8308 [==============================] - 3s 307us/sample - loss: 0.1274 - accuracy: 0.9537 - val_loss: 0.5101 - val_accuracy: 0.9004\n",
      "Epoch 5/10\n",
      "8308/8308 [==============================] - 3s 306us/sample - loss: 0.1079 - accuracy: 0.9594 - val_loss: 1.1722 - val_accuracy: 0.8939\n",
      "Epoch 6/10\n",
      "8308/8308 [==============================] - 3s 306us/sample - loss: 0.0908 - accuracy: 0.9675 - val_loss: 1.2106 - val_accuracy: 0.8950\n",
      "Epoch 7/10\n",
      "8308/8308 [==============================] - 3s 306us/sample - loss: 0.0750 - accuracy: 0.9733 - val_loss: 0.9782 - val_accuracy: 0.8950\n",
      "Epoch 8/10\n",
      "8308/8308 [==============================] - 3s 307us/sample - loss: 0.0789 - accuracy: 0.9762 - val_loss: 2.4894 - val_accuracy: 0.8896\n",
      "Epoch 9/10\n",
      "8308/8308 [==============================] - 3s 306us/sample - loss: 0.0720 - accuracy: 0.9750 - val_loss: 1.4375 - val_accuracy: 0.8961\n",
      "Epoch 10/10\n",
      "8308/8308 [==============================] - 3s 307us/sample - loss: 0.0509 - accuracy: 0.9805 - val_loss: 1.8857 - val_accuracy: 0.9004\n"
     ]
    }
   ],
   "source": [
    "#weights = compute_class_weight('balanced', np.unique(y_tr), y_tr)\n",
    "#weights = weights[::-1]\n",
    "sensitivity = np.zeros((3,3))\n",
    "especificity = np.zeros((3,3))\n",
    "accuracy = np.zeros((3,3))\n",
    "for i, embed_dim in enumerate([32,64,128]):\n",
    "    for j,cells in enumerate([32,64,128]):\n",
    "        model = Model_Sentimen(embed_dim,cells)\n",
    "        #opt = optimizers.Adam(learning_rate=0.0001, beta_1=0.9, beta_2=0.999, amsgrad=False)\n",
    "        model.compile(optimizer='adam', loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "        model.fit(X_tr, y_tr, validation_split=0.1,batch_size=32, epochs=10, verbose=1)\n",
    "        y_pred = np.round(model.predict(X_te))\n",
    "        sensitivity[i,j] = recall_score(y_te,y_pred)\n",
    "        accuracy[i,j] = accuracy_score(y_te,y_pred)\n",
    "        especificity[i,j] = especi_score(y_te,y_pred.flatten())        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAArkAAADgCAYAAAAHQH6iAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8li6FKAAAgAElEQVR4nO3deZwV1bnv/8+3B3CIooYWEEFQJhvFqUFNTH6KGjFBOEpU1CQQTYjeY0wcjlGvMWqON2ZwTLzHgeOQGEXFEy9GIsQpGuMAGhVoRhEZBGwERVDApp/fH1VNNm0Pu5vu3s3u7/v12i92Va1d9VSz166nVq1apYjAzMzMzCyfFOQ6ADMzMzOz5uYk18zMzMzyjpNcMzMzM8s7TnLNzMzMLO84yTUzMzOzvOMk18zMzMzyjpNcM8sLktZJ2ree5bMkHZ3Fes6SNLVZgzPLMUlXSBqfMX2ypCVpvTmkEfWj3npm1pbI4+S2LEnPAQcBXSNiY47DMWs1ko4CfgUMBDYDs4EfR8S0Vtj2vcDSiLiyGdYVQN+IWLDNgVm7I2kR0IWkDlS7NyLOz01ECUlvAxdFxP/bhnXcSzPVM7OWUJTrAPKZpF7AV4CPgBHAI6203aKIqGyNbZnVRtKuwJ+B84CHgQ4kdcEnetYenRQRT+U6iBr2AWblOgizluTuCi3rO8DLwL3AmOqZknaUdIOkdyV9JOnvknZMlx0l6R+SPkwvJY1N5z8n6XsZ6xgr6e8Z0yHp3yXNB+an825J17FW0muSvpJRvjC9fPW2pI/T5T0k3SbphsydkDRJ0oUt8QeyvNUPICIejIjNEfFpREyNiLcAJJ0tabakNZKmSNqn+oPpd/lcSfPTenCbJKXL+kj6W1pvVkl6qMbn+kgaB5wFXJpeWn08Xb5I0nGS9pL0qaQ9Mj57SLq+4sy6Jen5tMib6bpOlzRT0kkZny1OP3tIi/01Le9k8V2+QNLCdNmvJRVkLK+v/gyU9FdJqyWtlHRFOv9qSfdL6ihpHVBI8r1+O12+SNJx6ftajw8ZsdVazyT9h6RHa+znrZJuabm/pFndnOS2rO8Af0xfJ0jqks7/DXAY8CVgD+BSoCr9ofoL8FugBDgYeKMR2/s34HCgNJ2elq5jD+AB4BFJO6TLLgLOAL4O7AqcDXwC3AecUf2DKqkzcFz6ebNszQM2S7pP0omSdq9eIGkkcAVwCsn3/AXgwRqfHw4MBgYBpwEnpPN/DkwFdgf2JqkrW4mIO0nq3K8i4gsRcVKN5e8BLwGjMmafCUyMiM9qlP1q+vagdF0PAb8HvpVR7OvA8oj4Zz1/D7OaGvounwyUAYcCI0l+o+utP5J2AZ4CngT2AvoAT2euNCI2RsQX0smDImK/WmKr6/iQuZ7a6tn9wDBJu6XxFAGjSeqMWatzkttClPRH3Ad4OCJeA94GzkyTx7OBH0XEsrSV6x9pf90zgafS1q/PIuKDiGhMkvuLiFgdEZ8CRMT96ToqI+IGoCPQPy37PeDKiJgbiTfTsq+SdK84Ni03GnguIlZu45/E2pGIWAscBQRwF1CRXhHoApxL8l2dnXar+T/AwZmtUcD1EfFhRCwGniU5WQP4jKRe7RURGyLi7zTNAyQHcdJW4tFkfyJ3P/B1JV0yAL4N/KGJcVj78Fh6VaL69X0a/i7/Mv09XwzcTPp9pf76MxxYERE3pOv8OCJeaUK8tR4fGvpQRCwHngdOTWcNA1alx0CzVuckt+WMAaZGxKp0+oF0XmdgB5Kkt6YedczP1pLMCUmXpJe0PpL0IdAp3X5D27qPf7VUfQsfwK0J0oPw2IjYGziApGXpZpID+y3VB3xgNSCge8bHV2S8/wSobnm6NC37qpK7wc9uYniPAkdK6gZ8FagiaRHLZr/eA14ERqUtVieStGiZ1eXfImK3jNddNPxdzvw9f5ek/kD99WdbjyHVtmU9Pn5Ym+Ebz1qAkv61pwGFkqoP1h2B3YBuwAZgP+DNGh9dAgypY7XrgZ0yprvWUmbLUBlK+t9eStIiOysiqiStIfkxrN7WfsDMWtZzPzBT0kHA/sBjdcRklpWImKPkTuwfkHz3rouIRieGEbEC+D5suVrylKTnaxn5oN5hYyJijZJhwk4n+Y5PiMYNNXMfSWtXEfBSRCxrxGfNsvku9+BfN4b1BN5L39dZf9LW3NHNEF59x4dMtdWZx4D/knQAScvypc0Qj1mTuCW3ZfwbyXAxpSSXWQ8mOZC+QNJP927gxvQGmEJJR0rqSNIadJyk0yQVSfqipOrLtG8Ap0jaSVIf4JwGYtgFqAQqgCJJV5H0rao2Hvi5pL5KDJL0RYCIWErSn/cPwKPV3R/MsiVpgKSLJe2dTvcgudz6MnA7cLmkgemyTpJOrXttW6331Op1AmtIDrJVtRRdCTQ0lucDJPXxm9TfVaG2dT1G0lfyR7i/oTVBFt/l/5C0e1p3fgRU35hWX/35M9BN0o/TG8x2kXR4E8Kr8/hQw+fqRkRsACaS1KlX0+4WZjnhJLdljAHuiYjFEbGi+gX8juRu1MuAGSSJ5Grgl0BB+mPwdeDidP4bJGPsAtwEbCL5UbmPhi+PTiG5+WAeyaWuDWx9+etGkqGdpgJrgf8GdsxYfh9wIL7UZE3zMclNkK9IWk+S3M4ELo6IP5F85ydIWpvOPzHL9Q5O17kOmETSt31hLeX+GyhNL+nWdSViEtCXpA9jzasqma4G7kvXdRpAeuL3KNAb+J8sY7f26/F0BILq159o+Lv8/4DXSI4DT5B8p6mv/kTEx8DxwEkkXX7mA8c0Id6Gjg/V6qpnPn5Ym+CHQVitJH2VpNvCPo28jGvWLqRXR/pFxLcaLGzWCNrOH0AiqScwh+QhSGtzHY+1X+6Ta58jqZjk8th4J7hmn6dkjN1zSEZWMLNUOoLQRST93J3gWk65u4JtRdL+wIckN8jdnONwzNqcdPinJcBfIuL5hsqbtReSdibp3nA88LMch2Pm7gpmZmZmufDaa6/tWVRUNJ5kmEU3PDZOFTCzsrLye4cddtj7tRVwdwUzMzOzHCgqKhrftWvX/UtKStYUFBS41bERqqqqVFFRUbpixYrxwIjayviswczMzCw3DigpKVnrBLfxCgoKoqSk5COSVvBa5awlt3PnztGrV69cbd5sK6+99tqqiCjJZQyuE9aWuE6Yba2F6kSBE9ymS/92dTbY5izJ7dWrF9OnT8/V5s22IundXMfgOmFtieuE2dbaQp1obp988okOP/zwAZs2bdLmzZt10kknrbnpppveAxgxYkTvt956a+fi4uI4+OCD199///3vduzYcZsS8lGjRvUaPnz4R9/97nfXDBkypP9vfvObJV/96lc/aZ69+Tz3yTUzMzNrAyQOa871RfBafct32GGH+Pvf/z63U6dOVRs3btTgwYP7P/300x8de+yx688666zVjz322DsAI0eO7H3zzTd3/slPflLRnPG1NPfJNTMzM2uHCgoK6NSpUxXApk2bVFlZKUkAnH766R8VFBRQUFBAWVnZ+qVLl3ao+fnKykrGjRu3d9++fQf269ev9LrrrtsT4IUXXthp8ODB/QcOHLj/UUcd1ffdd98triuGyspKRo0a1at6Hddcc82ezbV/bsk1MzMza6cqKys54IADShcvXtxxzJgx7w8dOnR95vKNGzfqoYce+uKNN964pOZnb7jhhpLFixd3KC8vn1VcXMzKlSsLN27cqAsuuKDnE088sWCvvfaqvOuuu3a/5JJLuj/yyCOLatv+Sy+9tNPy5cuL58+fPwtg1apVhc21b05yzczMzNqpoqIi5syZU75q1arCb3zjG/tNmzZth8GDB2+oXj5mzJieRxxxxLphw4atq/nZZ555Ztdzzz23org4aajt0qXL5mnTpu0wf/78HYcOHdoPoKqqipKSks/q2v6AAQM2LlmypOOYMWN6nHTSSR+dfPLJzfakPCe5ZmZmZu1c586dN3/lK1/5+PHHH+9UneRefPHF3VatWlU0ZcqUt7NdT0SoT58+n77xxhtzsilfUlKyeebMmeV/+tOfdr399ttLHnrooT3qavVtrLxKcnWNmvS5+JlH7zBrF9SE3wg/FdIsZ3xcb1nvvfdeUYcOHaJz586b161bp2effXbXSy65ZAXAjTfe2PmZZ57p9MILL8wtLKy9B8Gxxx679o477ug8fPjwtdXdFQYNGrRh9erVRU899dTOxx133PqNGzdqxowZHcvKyjbUto7ly5cXdezYsWrs2LEfDhw4cMO3v/3tfZtr/9psktuUYxFXt+LGmnjga9Vj7HZwQG/KD1hc3cSNOVkxM2sfmpRE0O6OE0uWLCkeO3Zs782bNxMRGjly5OozzjjjI4BLL710n27dum0sKyvbH2D48OFrfvOb3yzP/PyFF15YMW/evI4DBgwYWFRUFGPGjKm44oorKiZMmPD2BRdc0PPjjz8u3Lx5s84777yVdSW5ixYtKj7nnHN6VVVVCeDaa69d2lz712aTXPuXJp/JNnMc9Wnq70mTT0zMrF1r+m9OE39Pr27Kh7aDxpBW1KqNV9uphob8am6HH374p7Nnzy6vbVllZWWDsRQXFzN+/PilwFaJ6Ze+9KVPp0+fPrdm+UcffXRR9ftXX311y/Ly8vLZjYk7W05yzczMtnO+rG/2eU5yzbYDrd5q5QOfWfuQr83GZvhhEGZmZmaWh5zkmpmZmVnecXcFsyaQNAy4BSgExkfE9TWW3wQck07uBOwZEbu1bpTboI1fwtwebsY0M7PccpJr1kiSCoHbgONJ7iidJmlSRGy5QzUiLswo/0PgkFYP1MzMrB1zdwWzxhsCLIiIhRGxCZgAjKyn/BnAg60SmbUZUtNebX9jZpZPVq1aVThs2LB9e/fuPXDfffcd+NRTT+2cufxnP/tZF0mHLV++fJsbRkeNGtXrnnvu2R1gyJAh/Z9//vmdtnWd9XFLrlnjdQeWZEwvBQ6vraCkfYDewDOtEJeZmW3HdI0Oa871xc+iwbFux40b1+NrX/va2ieffHLhhg0btG7dui0NoAsWLCh++umnd+3Wrdum5oyrtbgl16xljQYmRsTm2hZKGidpuqTpFRUVrRxa2+AGSDOz3Pjggw8KX3nllV1+/OMfrwLYYYcdonPnzluOV+eff36PX//610tVxw9vZWUl48aN27tv374D+/XrV3rdddftCfDCCy/sNHjw4P4DBw7c/6ijjur77rvvFtcVQ2VlJaNGjepVvY5rrrlmz+baP7fkmjXeMqBHxvTe6bzajAb+va4VRcSdwJ0AZWVlvi/KzMxazdy5czvssccelaeeemqv8vLynQYNGrT+rrvuWrLrrrtW3X///bt169btsyOPPPLTuj5/ww03lCxevLhDeXn5rOLiYlauXFm4ceNGXXDBBT2feOKJBXvttVflXXfdtfsll1zS/ZFHHllU2zpeeumlnZYvX148f/78WZB0n2iu/XOSa9Z404C+knqTJLejgTNrFpI0ANgdeKl1w7PtWVNGjvDZkZk1RWVlpWbPnr3TLbfcsnjo0KHrv/vd7/b46U9/2vU///M/V/zqV7/q+uyzz86v7/PPPPPMrueee25FcXHSUNulS5fN06ZN22H+/Pk7Dh06tB9AVVUVJSUln9W1jgEDBmxcsmRJxzFjxvQ46aSTPjr55JPXNtf+ZdVdQdIwSXMlLZB0WS3Le0p6VtI/Jb0l6evNFaBZWxMRlcD5wBRgNvBwRMySdK2kERlFRwMTIvx4IDMza3t69eq1qUuXLpuGDh26HuD0009f8+abb+40e/bsjkuXLu04aNCg0u7dux+4cuXKDoceeuj+ixcvbrBxNCLUp0+fT+fMmVM+Z86c8nnz5pW/+OKLdSbLJSUlm2fOnFl+zDHHfHz77beXjB49uldz7V+DSW7GcEknAqXAGZJKaxS7kuRAfwjJgf3/NleAZm1RREyOiH4RsV9EXJfOuyoiJmWUuToiPndSaGZm1hb07NmzsmvXrpvefPPNjgBTp07dtX///huGDBny6erVq99ctmzZjGXLls3o0qXLptdff312z549KzM/f+yxx6694447On/2WdJQu3LlysJBgwZtWL16dVH1KA0bN27U9OnTd6grhuXLlxdt3ryZsWPHfviLX/xi2YwZM5ptxIVsuitsGS4JQFL1cEnlGWUC2DV93wl4r7kCNDMzM7OW8dvf/nbxWWedte+mTZvUs2fPjQ8++OCibD974YUXVsybN6/jgAEDBhYVFcWYMWMqrrjiiooJEya8fcEFF/T8+OOPCzdv3qzzzjtvZVlZ2Yba1rFo0aLic845p1dVVZUArr322qXNs2fZJbnZDJd0NTA1HfR+Z+C42lYkaRwwDqBnz56NjdXMzMwsb2Uz5Fdz+9KXvvTpzJkzZ9dXZtmyZTNqm19cXMz48eOXkuSGW61z+vTpc2uWf/TRRxdVv3/11Ve3LC8vL693+03VXEOInQHcGxF7A18H/iDpc+uOiDsjoiwiykpKSppp02ZmZmZmW8smyc1muKRzgIcBIuIlYAegc3MEaGZmZmbWWNkkuVuGS5LUgeTGskk1yiwGjgWQtD9Jkts+R7Y3MzMzs5xrMMnNcriki4HvS3oTeBAY62GTzMzMzCxXsnoYRERMBibXmHdVxvty4MvNG5qZmW0vJA0DbgEKgfERcX2N5T2B+4Dd0jKXpccWM7MW0Vw3npmZWTvl8dTNrC1ykmtmZttqy3jqEbEJqB5PPZPHUzdrg0499dRee+yxx0F9+/YdmDn/Bz/4wd69e/ce2K9fv9Ljjz9+v1WrVhVC8nCHU045pVe/fv1K991334GXX355122N4c9//vMuxxxzTB+AW2+99Yvf+c53mmWcWSe5Zma2rWobT717jTJXA9+StJSk+9sPa1uRpHGSpkuaXlHh+5etnZEOa9ZXFs4+++xVkyZN+txjd0844YS18+bNmzVv3rzyPn36bPjpT3/aFeCee+7ZfdOmTQXz5s0rf/PNN2f//ve/L5k7d26H5v5TNAcnuWZm1ho8nrpZG3TiiSeuKykpqaw5/5RTTllbXFwMwJFHHrl+2bJlHQAk8cknnxR89tlnrF+/XsXFxbHbbrttrvn5iRMn7lpaWrp///79S4888sh+AGvXri049dRTex144IH777///qX333//bvXFdvfdd+/et2/fgf379y8tKyvr39h9y+rGMzMzs3pkO576MEjGU5dUPZ76+60SoZk12b333tv5m9/85mqAsWPHrnn88cd323PPPQ/asGFDwc9//vMlXbp02SrJfe+994rOP//8Xs8999ycAQMGbFq5cmUhwBVXXNHtmGOOWfvII48sWrVqVWFZWdn+I0aMWFvXdq+//vpuU6dOnde7d+/PqrtLNIZbcs2aQNIwSXMlLZB0WR1lTpNULmmWpAdaO0azVuTx1M3y1E9+8pOuhYWFce65564G+Nvf/rZTQUFBrFix4q0FCxbM+N3vfte1vLx8q+4Kzz333M5Dhgz5eMCAAZsAqpPg5557btebbrqp24ABA0qPOuqo/hs3btSCBQvq7OpQVla27qyzzup1ww03dK6s/Fxjc4PckmvWSBl3kh9P0vdwmqRJ6VB61WX6ApcDX46INZL2zE20Zi0vIiolVY+nXgjcXT2eOjA9IiaRjKd+l6QLSW5C83jqZm3crbfe+sUpU6bs9sILL8wrKEjaRf/whz988YQTTvioY8eO0b1798rBgwev+8c//rFzaWnppobWFxFMnDhxwUEHHbQxc/57771XXFv5Bx54YPEzzzyz86RJkzoddthhpa+99lp5165dP9c1oi5uyTVrvGzuJP8+cFtErAGICF+StbwWEZMjol9E7BcR16XzrkoTXCKiPCK+HBEHRcTBETE1txGbWX0mTpy46y233NJ18uTJC3bZZZeq6vk9e/bc9Oyzz+4KSR/b119/fecDDzxwQ+Znjz766PWvvvrqLnPmzOkAUN1d4Zhjjll7ww03dKmqSlb34osv7lhfDLNmzeo4dOjQ9TfffPN7u+++e+XChQsbdYObk1yzxsvmTvJ+QD9JL0p6OR0o38zMrE056aSTeh911FED3nnnnY5dunQZdNNNN3UGuOiii3quX7++cOjQof0GDBhQeuaZZ/YEuPTSS99fv359QZ8+fQYecsgh+5955pmrDj/88E8z17nXXntV3nrrrYtOPvnkPv379y89+eST9wW4/vrr36usrNSAAQNK+/TpM/DKK6+seezcyoUXXrh3v379Svv27Ttw8ODB64444ohP6ytfk7srmLWMIqAvcDTJTTjPSzowIj7MLCRpHDAOoGfPZhkW0MzMtlcRr7X2Jh9//PF3apu/ePHimbXN79SpU9Vf/vKXhQ2t97TTTlt72mmnlWfO+8IXvhAPPPDAuzXLDh8+/OPhw4d/DHDBBRd8AHwAMHXq1Lez2IU6uSXXrPGyuZN8KTApIj6LiHeAeSRJ71Y8XJKZmVnLcJJr1njZ3En+GEkrLpI6k3RfaPDM18zMzJqHk1yzRoqISqD6TvLZwMPVd5JLGpEWmwJ8IKkceBb4j4j4IDcRm5mZtT/uk2vWBBExmeTRpJnzrsp4H8BF6cvMzKw2VVVVVSooKPBwek1QVVUloKqu5W7JNTMzM8uNmRUVFZ3SZM0aoaqqShUVFZ2AWm+QA7fkmpmZmeVEZWXl91asWDF+xYoVB+CGx8aqAmZWVlZ+r64CTnLNzMzMcuCwww57HxjRYEFrEp81mJmZmVnecZJrZmZmZnnHSa6ZmZmZ5R0nuWZmZmaWd5zkmpmZmVnecZJrZmZmZnnHSa6ZmZmZ5R0nuWZmZmaWd7JKciUNkzRX0gJJl9VR5jRJ5ZJmSXqgecM0MzMzM8teg0mupELgNuBEoBQ4Q1JpjTJ9gcuBL0fEQODHLRCrWZvR0ImfpLGSKiS9kb7qfOygmZmZNb9sHus7BFgQEQsBJE0ARgLlGWW+D9wWEWsAIuL95g7UrK3IOPE7HlgKTJM0KSLKaxR9KCLOb/UAzczMLKvuCt2BJRnTS9N5mfoB/SS9KOllScOaK0CzNmjLiV9EbAKqT/zMzMysjWiuG8+KgL7A0cAZwF2SdqtZSNI4SdMlTa+oqGimTZu1umxO/ABGSXpL0kRJPWpbkeuEmZlZy8gmyV0GZB6g907nZVoKTIqIzyLiHWAeSdK7lYi4MyLKIqKspKSkqTGbbQ8eB3pFxCDgr8B9tRVynTAzM2sZ2SS504C+knpL6gCMBibVKPMYSSsukjqTdF9Y2IxxmrUlDZ74RcQHEbExnRwPHNZKsZnlhEfhMbO2psEbzyKiUtL5wBSgELg7ImZJuhaYHhGT0mVfk1QObAb+IyI+aMnAzXJoy4kfSXI7Gjgzs4CkbhGxPJ0cAcxu3RDNWk82N2PWGIVnjaQ9cxOtmbUX2YyuQERMBibXmHdVxvsALkpfZnktyxO/CySNACqB1cDYnAVs1vI8Co+ZtTlZJblmtrUsTvwuJ2m1MmsParsZ8/AaZfoBSHqR5OTw6oh4snXCM7P2yEmumZm1hsxRePYGnpd0YER8mFlI0jhgHEDPnj1bO0YzyyPNNYSYmZm1Xx6Fx8zaHCe5Zma2rTwKj5m1OU5yzcxsm0REJVB9M+Zs4OHqmzHTGzBJl32QjsLzLB6Fx8xamPvkmpnZNvMoPGbW1rgl18zMzMzyjpNcMzMzM8s7TnLNzMzMLO84yTUzMzOzvOMk18zMzMzyjpNcMzMzM8s7TnLNmkDSMElzJS2QdFk95UZJCkllrRmfmZlZe+ck16yRJBUCtwEnAqXAGZJKaym3C/Aj4JXWjdDMzMyc5Jo13hBgQUQsjIhNwARgZC3lfg78EtjQmsGZmZmZk1yzpugOLMmYXprO20LSoUCPiHiiNQMzMzOzhJNcs2YmqQC4Ebg4i7LjJE2XNL2ioqLlgzMzM2snnOSaNd4yoEfG9N7pvGq7AAcAz0laBBwBTKrt5rOIuDMiyiKirKSkpAVDNjMza1+c5Jo13jSgr6TekjoAo4FJ1Qsj4qOI6BwRvSKiF/AyMCIipucmXDMzs/bHSa5ZI0VEJXA+MAWYDTwcEbMkXStpRG6jMzMzM4CiXAdgtj2KiMnA5Brzrqqj7NGtEZOZmZn9i1tyzczMzCzvOMk1MzMzs7zjJNfMzMzM8o6TXDMzMzPLO05yzczMzCzvZJXkShomaa6kBZIuq6fcKElR26D3ZmZmZmatpcEkV1IhcBtwIlAKnCGptJZyuwA/Al5p7iDNzMzMzBojm5bcIcCCiFgYEZuACcDIWsr9HPglsKEZ4zMzMzMza7RsktzuwJKM6aXpvC0kHQr0iIgnmjE2MzMzM7Mm2eYbzyQVADcCF2dRdpyk6ZKmV1RUbOumzcysjfC9G2bW1mST5C4DemRM753Oq7YLcADwnKRFwBHApNp+wCLizogoi4iykpKSpkdtZmZthu/dMLO2KJskdxrQV1JvSR2A0cCk6oUR8VFEdI6IXhHRC3gZGBER01skYjMza2t874aZtTkNJrkRUQmcD0wBZgMPR8QsSddKGtHSAZq1RQ1dmpV0rqQZkt6Q9PfaWrXM8kiz3bvhbm1m1lyKsikUEZOByTXmXVVH2aO3PSyztivj0uzxJAfzaZImRUR5RrEHIuL2tPwIkn7rw1o9WLM2IOPejbENlY2IO4E7AcrKyqJlIzOzfOYnnpk1XoOXZiNibcbkzoAP1pbPmu3eDTOz5pJVS66ZbaW2S7OH1ywk6d+Bi4AOwNDWCc0sJ7bcu0GS3I4GzqxeGBEfAZ2rpyU9B1ziezfMrCW5JdeshUTEbRGxH/AT4Mrayrj/oeUD37thZm2RW3LNGq+hS7M1TQD+q7YF7n9o+cL3bphZW+OWXLPGq3dYPQBJfTMmvwHMb8X4zMzM2j235Jo1UkRUSqq+NFsI3F19aRaYHhGTgPMlHQd8BqwBxuQuYjMzs/bHSa5ZEzR0aTYiftTqQZmZmdkW7q5gZmZmZnnHSa6ZmZmZ5R0nuWZmZmaWd5zkmpmZmVnecZJrZmZmZnnHSa6ZmZmZ5R0nuWZmZmaWd5zkmpmZmVnecZJrZmZmZnnHSaFJJZYAAA08SURBVK6ZmZmZ5R0nuWZmZmaWd5zkmpmZmVnecZJr1gSShkmaK2mBpMtqWX6RpHJJb0l6WtI+uYjTzMysvXKSa9ZIkgqB24ATgVLgDEmlNYr9EyiLiEHAROBXrRulmZlZ++Yk16zxhgALImJhRGwCJgAjMwtExLMR8Uk6+TKwdyvHaGZm1q45yTVrvO7Akozppem8upwD/KW2BZLGSZouaXpFRUUzhmhmZta+Ock1a0GSvgWUAb+ubXlE3BkRZRFRVlJS0rrBmZmZ5bGiXAdgth1aBvTImN47nbcVSccB/xv4/yJiYyvFZmZmZrgl16wppgF9JfWW1AEYDUzKLCDpEOAOYEREvJ+DGM3MzNq1rJJcD5dk9i8RUQmcD0wBZgMPR8QsSddKGpEW+zXwBeARSW9ImlTH6szMzKwFNNhdIWO4pONJbrCZJmlSRJRnFKseLukTSeeRDJd0eksEbNYWRMRkYHKNeVdlvD+u1YMyMzOzLbJpyfVwSWZmVi9f8TOztiabJNfDJZmZWZ38gBQza4ua9cYzD5dkZtYu+YqfmbU52SS5jR0uaYSHSzIza1d8xc/M2pxsklwPl2RmZs3CV/zMrLU0OLpCRFRKqh4uqRC4u3q4JGB6RExi6+GSABZHxIg6V2pmZvnED0gxszYnqyeeebgkMzOrx5YrfiTJ7WjgzMwCGVf8hvmKn5m1Bj/xzMzMtokfkGJmbVFWLblmZmb18RU/M2tr3JJrZmZmZnnHSa6ZmZmZ5R0nuWZmZmaWd5zkmjWBpGGS5kpaIOmyWpZ/VdLrkiolfTMXMZqZmbVnTnLNGklSIXAbcCJQCpwhqbRGscXAWOCB1o3OzMzMwKMrmDXFEGBBRCwEkDQBGAmUVxeIiEXpsqpcBGhmZtbeuSXXrPG6A0syppem8xpN0jhJ0yVNr6ioaJbgzMzMzEmuWU5FxJ0RURYRZSUlJbkOx8zMLG84yTVrvGVAj4zpvdN5ZmZm1kY4yTVrvGlAX0m9JXUARgN+RKmZmVkb4iTXrJEiohI4H5gCzAYejohZkq6VNAJA0mBJS4FTgTskzcpdxGZmZu2PR1cwa4KImAxMrjHvqoz300i6MZiZmVkOuCXXzMzMzPKOk1wzMzMzyztOcs3MzMws7zjJNTMzM7O84yTXzMzMzPKOk1wzMzMzyztOcs3MzMws7zjJNTMzM7O84yTXzMzMzPKOk1wzMzMzyztOcs3MzMws72SV5EoaJmmupAWSLqtleUdJD6XLX5HUq7kDNWtLXCfMtuY6YWZtTYNJrqRC4DbgRKAUOENSaY1i5wBrIqIPcBPwy+YO1KytcJ0w25rrhJm1Rdm05A4BFkTEwojYBEwARtYoMxK4L30/EThWkpovTLM2xXXCbGuuE2bW5mST5HYHlmRML03n1VomIiqBj4AvNkeAZm2Q64TZ1lwnzKzNKWrNjUkaB4xLJ9dJmtusG7i63qWdgVW1xtWUbbVmA8TV9S7dfvcL6tu35t0vaGjf9mnqareF60QTXV3v0u13v8B1wnWiaa6ud6n3K1ttsE5Y02WT5C4DemRM753Oq63MUklFQCfgg5oriog7gTubFuq2kTQ9Ispyse2W5P3KCdeJNsz7lROuE22Y98vaq2y6K0wD+krqLakDMBqYVKPMJGBM+v6bwDMREc0Xplmb4jphtjXXCTNrcxpsyY2ISknnA1OAQuDuiJgl6VpgekRMAv4b+IOkBcBqkh84s7zkOmG2NdcJM2uL1F5OpCWNSy+D5RXvlzVVvv6NvV/WVPn6N/Z+WXvVbpJcMzMzM2s//FhfMzMzM8s7eZfkStpB0quS3pQ0S9I16fw/po+cnCnpbknFuY61KSTtJmmipDmSZks6MmPZxZJCUudcxpiN9P/gfUkzM+b9Ot2vtyT9SdJu6fxiSfdJmpHu8+W5i3z74zrhOmFby+c6kS/1AVwnbNvlXZILbASGRsRBwMHAMElHAH8EBgAHAjsC38tdiNvkFuDJiBgAHATMBpDUA/gasDiHsTXGvcCwGvP+ChwQEYOAeUD1j9SpQMeIOBA4DPiB/Nz7xnCd2D7ci+tEa8nnOpEv9QFcJ2wb5V2SG4l16WRx+oqImJwuC+BVknEctyuSOgFfJblLmYjYFBEfpotvAi4FtotO1hHxPMkd1pnzpqZPQgJ4mX/9HwWws5KxNXcENgFrWyvW7Z3rhOuEbS1f60Q+1QdwnbBtl3dJLoCkQklvAO8Df42IVzKWFQPfBp7MVXzboDdQAdwj6Z+SxkvaWdJIYFlEvJnj+JrT2cBf0vcTgfXAcpJWiN9ExOq6Pmif5zqRF1wnmlGe1on2VB/AdcIakJdJbkRsjoiDSc7whkg6IGPx/wWej4gXchPdNikCDgX+KyIOIanQVwNXAFflMK5mJel/A5Uklw4BhgCbgb1IfsQvlrRvjsLbLrlObN9cJ5pfntaJdlEfwHXCspOXSW619DLNs6R9eiT9DCgBLsplXNtgKbA0o8VhIskPWm/gTUmLSH6wX5fUNTchbhtJY4HhwFkZT0M6k6SP2WcR8T7wIuBHOTaB68T2x3WiZeVZncj7+gCuE5a9vEtyJZVk3G25I3A8MEfS94ATgDMioiqXMTZVRKwAlkjqn846Fng9IvaMiF4R0YvkR+7QtOx2RdIwkj5jIyLik4xFi4GhaZmdgSOAOa0f4fbJdcJ1wraWr3Ui3+sDuE5Y4zT4WN/tUDfgPkmFJEn8wxHxZ0mVwLvAS5IA/icirs1hnE31Q+CPSp4PvxD4bo7jaRJJDwJHA50lLQV+RnKXbEfgr+n/0csRcS5wG0kfs1mAgHsi4q2cBL59cp3YDrhOtKp8rhN5UR/AdcK2nZ94ZmZmZmZ5J++6K5iZmZmZOck1MzMzs7zjJNfMzMzM8o6TXDMzMzPLO05yzczMzCzvtIskV9JmSW9kvC5rxGePlvTnbdh2nZ+XtEhS5/T9P5q6jQa2/5yksvT95OqxIVuTpGslHdfa27W6uU64TtjWXCdcJyz/5OM4ubX5NH18Y5sVEV9qhW18vaW3Ucd28+pxknnCdQLXCduK6wSuE5Zf2kVLbl3SM+RfpGft0yUdKmmKpLclnZtRdFdJT0iaK+l2SQXp578m6SVJr0t6RNIX0vnDJM2R9DpwSsb2vihpqqRZksaTDFhdvWxd+u/R6Vn1xHQdf1Q64rWkr6fzXpN0a21n/pJ2lDRB0mxJfwJ2rLG/nSX1Stdzr6R56TaOk/SipPmShqTld5Z0t6RXJf1T0sh0/lhJ/yPpybT8r9L5hek6Z0qaIenCdP69kr6Zvj82XdeMdN0dM2K7Jv1bzpA0YNv/h62xXCdcJ2xrrhOuE7Ydi4i8fwGbgTcyXqen8xcB56XvbwLeAnYheW75ynT+0cAGYF+gEPgr8E2gM/A8sHNa7ifAVcAOwBKgL8mP08PAn9MytwJXpe+/AQTQOZ1el7G9j0ieL14AvAQclbHe3mm5B6vXW2NfLwLuTt8PAiqBsoz97Qz0SucfmG7jNeDuNN6RwGNp+f8DfCt9vxswD9gZGEvyJJ1OaVzvAj2Aw4C/ZsSyW/rvvenfrHof+qXzfw/8OCO2H6bv/xcwPtffm3x+uU64TvjlOuE64Ve+v9pLS+6nEXFwxuuhjGWT0n9nAK9ExMcRUQFs1L/6Jb0aEQsjYjPJj8ZRJM/FLgVelPQGMAbYBxgAvBMR8yMigPsztvXV6umIeAJYU0e8r0bE0kienf4GyY/NAGBhRLyTlnmwjs9mbuMtkh/k2rwTETPSbcwCnk7jnZFuD+BrwGXp/j1H8uPTM132dER8FBEbgPJ03xcC+0r6rZLni6+tsc3+6XbnpdP3pfFW+5/039cyYrCW4Trxea4T7ZvrxOe5Tth2rb30ya3PxvTfqoz31dPVf5+azz4OkrPZv0bEGZkLJDVHn67MODbTMv9PNfc18+9QvT0BoyJibuYHJR1eW4wRsUbSQcAJwLnAacDZTYippfbZsuM64TphW3OdcJ2w7VB7acndVkMk9U77WJ0O/B14GfiypD6wpV9SP2AO0EvSfulnM3/cngfOTMufCOzeiBjmkpz99kqnT6+jXOY2DiC5FNVUU4AfZvT1OqS+wkruAC6IiEeBK4FDaxSZS/K36ZNOfxv42zbEZ7njOoHrhG3FdQLXCWtb2stZ0I7ppZRqT0ZE1sPDANOA3wF9gGeBP0VElaSxwIPVneKBKyNinqRxwBOSPgFeIOm/BXBNWn4W8A9gcbYBRMSnkv4X8KSk9WlMtfkv4B5Js4HZJJd0murnwM3AW+kP9zvA8HrKd0+3XX3ydHmNfdgg6bvAI5KK0n24fRvis6ZznWga14n85TrRNK4T1mYp6V5j2wNJX4iIdekZ823A/Ii4KddxmeWK64TZ1lwnzP7F3RW2L99PWxpmkdyxekeO4zHLNdcJs625Tpil3JJrZmZmZnnHLblmZmZmlnec5JqZmZlZ3nGSa2ZmZmZ5x0mumZmZmeUdJ7lmZmZmlnec5JqZmZlZ3vn/Abu0Q2tJRk1QAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 720x216 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best accuracy= 0.8973581637072325\n"
     ]
    }
   ],
   "source": [
    "fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(10,3))\n",
    "X = np.arange(3)\n",
    "ax1.bar(X + 0.00, accuracy[0,:], color = 'b', width = 0.25)\n",
    "ax1.bar(X + 0.25, accuracy[1,:], color = 'g', width = 0.25)\n",
    "ax1.bar(X + 0.50, accuracy[2,:], color = 'r', width = 0.25)\n",
    "ax1.set_xticks([0.25, 1.25, 2.25])\n",
    "ax1.set_xticklabels(['32','64', '128'])\n",
    "ax1.set_title('Accuracy')\n",
    "ax1.set_xlabel('Embedding dimension')\n",
    "ax2.bar(X + 0.00, sensitivity[0,:], color = 'b', width = 0.25)\n",
    "ax2.bar(X + 0.25, sensitivity[1,:], color = 'g', width = 0.25)\n",
    "ax2.bar(X + 0.50, sensitivity[2,:], color = 'r', width = 0.25)\n",
    "ax2.set_xticks([0.25, 1.25, 2.25])\n",
    "ax2.set_xticklabels(['32','64', '128'])\n",
    "ax2.set_title('Sensitivity')\n",
    "ax2.set_xlabel('Embedding dimension')\n",
    "ax3.bar(X + 0.00, especificity[0,:], color = 'b', width = 0.25)\n",
    "ax3.bar(X + 0.25, especificity[1,:], color = 'g', width = 0.25)\n",
    "ax3.bar(X + 0.50, especificity[2,:], color = 'r', width = 0.25)\n",
    "ax3.set_xticks([0.25, 1.25, 2.25])\n",
    "ax3.set_xticklabels(['32','64', '128'])\n",
    "ax3.set_title('Especificity')\n",
    "ax3.set_xlabel('Embedding dimension')\n",
    "ax3.legend(labels=['32 cells','64 cells','128 cells'],bbox_to_anchor=(1.1, 1.05))\n",
    "plt.show()\n",
    "print('Best accuracy= {}'.format(np.max(accuracy)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3\n",
    "\n",
    "Train a CBOW model with the dataset using and Embedding dimension of [32,64,128]. Create a new network and transfer the pretrained weights to the Embedding layer. Use the same architecture than before (except for the Embedding layer). Compare the results.\n",
    "\n",
    "**Note**: Take care on the tokenization of the words. Keras tokenizer does not assign the zero value to any word because of padding purposes. Make sure that the order of the vectors in the GloVe embedding matrix corresponds with the indexs used to represent the words in the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = list(tokenizer.word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.sklearn_api import W2VTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Model_Sentimen(Embeb,cells,wordsmatrix):\n",
    "    model = Sequential([\n",
    "        Embedding(input_dim=max_fatures, output_dim=Embeb, weights = [np.r_[np.zeros((1,Embeb)),wordsmatrix]], trainable = False, mask_zero=True),\n",
    "        LSTM(cells,activation='relu'),\n",
    "        Dense(10,activation='relu'),\n",
    "        Dropout(0.3),\n",
    "        Dense(1,activation='sigmoid')\n",
    "    ])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8308 samples, validate on 924 samples\n",
      "Epoch 1/10\n",
      "8308/8308 [==============================] - 2s 287us/sample - loss: 0.4109 - accuracy: 0.8303 - val_loss: 0.3080 - val_accuracy: 0.8777\n",
      "Epoch 2/10\n",
      "8308/8308 [==============================] - 1s 166us/sample - loss: 0.2982 - accuracy: 0.8914 - val_loss: 0.3073 - val_accuracy: 0.8766\n",
      "Epoch 3/10\n",
      "8308/8308 [==============================] - 1s 166us/sample - loss: 0.2652 - accuracy: 0.8997 - val_loss: 0.2912 - val_accuracy: 0.8820\n",
      "Epoch 4/10\n",
      "8308/8308 [==============================] - 1s 166us/sample - loss: 0.2475 - accuracy: 0.9096 - val_loss: 0.2983 - val_accuracy: 0.8810\n",
      "Epoch 5/10\n",
      "8308/8308 [==============================] - 1s 166us/sample - loss: 0.2355 - accuracy: 0.9108 - val_loss: 0.2859 - val_accuracy: 0.8853\n",
      "Epoch 6/10\n",
      "8308/8308 [==============================] - 1s 166us/sample - loss: 0.2168 - accuracy: 0.9160 - val_loss: 0.2953 - val_accuracy: 0.8810\n",
      "Epoch 7/10\n",
      "8308/8308 [==============================] - 1s 166us/sample - loss: 0.2047 - accuracy: 0.9254 - val_loss: 0.3631 - val_accuracy: 0.8788\n",
      "Epoch 8/10\n",
      "8308/8308 [==============================] - 1s 168us/sample - loss: 0.1891 - accuracy: 0.9269 - val_loss: 0.3566 - val_accuracy: 0.8777\n",
      "Epoch 9/10\n",
      "8308/8308 [==============================] - 1s 166us/sample - loss: 0.1763 - accuracy: 0.9331 - val_loss: 0.3399 - val_accuracy: 0.8853\n",
      "Epoch 10/10\n",
      "8308/8308 [==============================] - 1s 171us/sample - loss: 0.1622 - accuracy: 0.9390 - val_loss: 0.3462 - val_accuracy: 0.8799\n",
      "Train on 8308 samples, validate on 924 samples\n",
      "Epoch 1/10\n",
      "8308/8308 [==============================] - 2s 293us/sample - loss: 0.3531 - accuracy: 0.8576 - val_loss: 0.3054 - val_accuracy: 0.8885\n",
      "Epoch 2/10\n",
      "8308/8308 [==============================] - 2s 195us/sample - loss: 0.2626 - accuracy: 0.8994 - val_loss: 0.3047 - val_accuracy: 0.8755\n",
      "Epoch 3/10\n",
      "8308/8308 [==============================] - 2s 189us/sample - loss: 0.2350 - accuracy: 0.9101 - val_loss: 0.2813 - val_accuracy: 0.8939\n",
      "Epoch 4/10\n",
      "8308/8308 [==============================] - 2s 187us/sample - loss: 0.2112 - accuracy: 0.9182 - val_loss: 0.2940 - val_accuracy: 0.8864\n",
      "Epoch 5/10\n",
      "8308/8308 [==============================] - 2s 188us/sample - loss: 0.1896 - accuracy: 0.9261 - val_loss: 0.3065 - val_accuracy: 0.8853\n",
      "Epoch 6/10\n",
      "8308/8308 [==============================] - 2s 188us/sample - loss: 0.1704 - accuracy: 0.9312 - val_loss: 0.3501 - val_accuracy: 0.8853\n",
      "Epoch 7/10\n",
      "8308/8308 [==============================] - 2s 189us/sample - loss: 0.1494 - accuracy: 0.9401 - val_loss: 0.3170 - val_accuracy: 0.8864\n",
      "Epoch 8/10\n",
      "8308/8308 [==============================] - 2s 187us/sample - loss: 0.1325 - accuracy: 0.9455 - val_loss: 0.4079 - val_accuracy: 0.8853\n",
      "Epoch 9/10\n",
      "8308/8308 [==============================] - 2s 190us/sample - loss: 0.1124 - accuracy: 0.9541 - val_loss: 0.4130 - val_accuracy: 0.8874\n",
      "Epoch 10/10\n",
      "8308/8308 [==============================] - 2s 188us/sample - loss: 0.0998 - accuracy: 0.9579 - val_loss: 0.4642 - val_accuracy: 0.8896\n",
      "Train on 8308 samples, validate on 924 samples\n",
      "Epoch 1/10\n",
      "8308/8308 [==============================] - 3s 359us/sample - loss: 0.3623 - accuracy: 0.8619 - val_loss: 0.2960 - val_accuracy: 0.8853\n",
      "Epoch 2/10\n",
      "8308/8308 [==============================] - 2s 261us/sample - loss: 0.2845 - accuracy: 0.8991 - val_loss: 0.2948 - val_accuracy: 0.8777\n",
      "Epoch 3/10\n",
      "8308/8308 [==============================] - 2s 265us/sample - loss: 0.2530 - accuracy: 0.9130 - val_loss: 0.2972 - val_accuracy: 0.8885\n",
      "Epoch 4/10\n",
      "8308/8308 [==============================] - 2s 263us/sample - loss: 0.2276 - accuracy: 0.9214 - val_loss: 0.2660 - val_accuracy: 0.8950\n",
      "Epoch 5/10\n",
      "8308/8308 [==============================] - 2s 264us/sample - loss: 0.2075 - accuracy: 0.9313 - val_loss: 0.2975 - val_accuracy: 0.8950\n",
      "Epoch 6/10\n",
      "8308/8308 [==============================] - 2s 261us/sample - loss: 0.1771 - accuracy: 0.9391 - val_loss: 0.4138 - val_accuracy: 0.8896\n",
      "Epoch 7/10\n",
      "8308/8308 [==============================] - 2s 261us/sample - loss: 0.1540 - accuracy: 0.9457 - val_loss: 0.4187 - val_accuracy: 0.8907\n",
      "Epoch 8/10\n",
      "8308/8308 [==============================] - 2s 267us/sample - loss: 0.1292 - accuracy: 0.9574 - val_loss: 0.4138 - val_accuracy: 0.8842\n",
      "Epoch 9/10\n",
      "8308/8308 [==============================] - 2s 261us/sample - loss: 0.1173 - accuracy: 0.9627 - val_loss: 0.4233 - val_accuracy: 0.8961\n",
      "Epoch 10/10\n",
      "8308/8308 [==============================] - 2s 261us/sample - loss: 0.0961 - accuracy: 0.9727 - val_loss: 0.4772 - val_accuracy: 0.8939\n",
      "Train on 8308 samples, validate on 924 samples\n",
      "Epoch 1/10\n",
      "8308/8308 [==============================] - 2s 270us/sample - loss: 0.3783 - accuracy: 0.8427 - val_loss: 0.3164 - val_accuracy: 0.8777\n",
      "Epoch 2/10\n",
      "8308/8308 [==============================] - 1s 169us/sample - loss: 0.2678 - accuracy: 0.8988 - val_loss: 0.2839 - val_accuracy: 0.8929\n",
      "Epoch 3/10\n",
      "8308/8308 [==============================] - 1s 168us/sample - loss: 0.2321 - accuracy: 0.9102 - val_loss: 0.3107 - val_accuracy: 0.8961\n",
      "Epoch 4/10\n",
      "8308/8308 [==============================] - 1s 169us/sample - loss: 0.2032 - accuracy: 0.9226 - val_loss: 0.2916 - val_accuracy: 0.8853\n",
      "Epoch 5/10\n",
      "8308/8308 [==============================] - 1s 171us/sample - loss: 0.1813 - accuracy: 0.9303 - val_loss: 0.3201 - val_accuracy: 0.8885\n",
      "Epoch 6/10\n",
      "8308/8308 [==============================] - 1s 170us/sample - loss: 0.1655 - accuracy: 0.9377 - val_loss: 0.3239 - val_accuracy: 0.8842\n",
      "Epoch 7/10\n",
      "8308/8308 [==============================] - 1s 171us/sample - loss: 0.1443 - accuracy: 0.9456 - val_loss: 0.4279 - val_accuracy: 0.8755\n",
      "Epoch 8/10\n",
      "8308/8308 [==============================] - 1s 171us/sample - loss: 0.1249 - accuracy: 0.9527 - val_loss: 0.4285 - val_accuracy: 0.8680\n",
      "Epoch 9/10\n",
      "8308/8308 [==============================] - 1s 170us/sample - loss: 0.1090 - accuracy: 0.9599 - val_loss: 0.4891 - val_accuracy: 0.8799\n",
      "Epoch 10/10\n",
      "8308/8308 [==============================] - 1s 170us/sample - loss: 0.0911 - accuracy: 0.9646 - val_loss: 0.5885 - val_accuracy: 0.8810\n",
      "Train on 8308 samples, validate on 924 samples\n",
      "Epoch 1/10\n",
      "8308/8308 [==============================] - 3s 304us/sample - loss: 0.3478 - accuracy: 0.8546 - val_loss: 0.2855 - val_accuracy: 0.8885\n",
      "Epoch 2/10\n",
      "8308/8308 [==============================] - 2s 189us/sample - loss: 0.2523 - accuracy: 0.8962 - val_loss: 0.2747 - val_accuracy: 0.8820\n",
      "Epoch 3/10\n",
      "8308/8308 [==============================] - 2s 190us/sample - loss: 0.2196 - accuracy: 0.9178 - val_loss: 0.2916 - val_accuracy: 0.8918\n",
      "Epoch 4/10\n",
      "8308/8308 [==============================] - 2s 190us/sample - loss: 0.1889 - accuracy: 0.9262 - val_loss: 0.2821 - val_accuracy: 0.8799\n",
      "Epoch 5/10\n",
      "8308/8308 [==============================] - 2s 190us/sample - loss: 0.1626 - accuracy: 0.9386 - val_loss: 0.2857 - val_accuracy: 0.8831\n",
      "Epoch 6/10\n",
      "8308/8308 [==============================] - 2s 189us/sample - loss: 0.1351 - accuracy: 0.9509 - val_loss: 0.3488 - val_accuracy: 0.8907\n",
      "Epoch 7/10\n",
      "8308/8308 [==============================] - 2s 190us/sample - loss: 0.1040 - accuracy: 0.9621 - val_loss: 0.4513 - val_accuracy: 0.8907\n",
      "Epoch 8/10\n",
      "8308/8308 [==============================] - 2s 189us/sample - loss: 0.0983 - accuracy: 0.9629 - val_loss: 0.4047 - val_accuracy: 0.8896\n",
      "Epoch 9/10\n",
      "8308/8308 [==============================] - 2s 189us/sample - loss: 0.0755 - accuracy: 0.9709 - val_loss: 0.4581 - val_accuracy: 0.8907\n",
      "Epoch 10/10\n",
      "8308/8308 [==============================] - 2s 190us/sample - loss: 0.0525 - accuracy: 0.9810 - val_loss: 0.5487 - val_accuracy: 0.8874\n",
      "Train on 8308 samples, validate on 924 samples\n",
      "Epoch 1/10\n",
      "8308/8308 [==============================] - 3s 364us/sample - loss: 0.3441 - accuracy: 0.8666 - val_loss: 0.2733 - val_accuracy: 0.8907\n",
      "Epoch 2/10\n",
      "8308/8308 [==============================] - 2s 264us/sample - loss: 0.2455 - accuracy: 0.9068 - val_loss: 0.2564 - val_accuracy: 0.8950\n",
      "Epoch 3/10\n",
      "8308/8308 [==============================] - 2s 263us/sample - loss: 0.2076 - accuracy: 0.9227 - val_loss: 0.2886 - val_accuracy: 0.8972\n",
      "Epoch 4/10\n",
      "8308/8308 [==============================] - 2s 262us/sample - loss: 0.1713 - accuracy: 0.9349 - val_loss: 0.2918 - val_accuracy: 0.8874\n",
      "Epoch 5/10\n",
      "8308/8308 [==============================] - 2s 263us/sample - loss: 0.1403 - accuracy: 0.9486 - val_loss: 0.3964 - val_accuracy: 0.8853\n",
      "Epoch 6/10\n",
      "8308/8308 [==============================] - 2s 263us/sample - loss: 0.1212 - accuracy: 0.9570 - val_loss: 0.3979 - val_accuracy: 0.8885\n",
      "Epoch 7/10\n",
      "8308/8308 [==============================] - 2s 269us/sample - loss: 0.0963 - accuracy: 0.9661 - val_loss: 0.5620 - val_accuracy: 0.8831\n",
      "Epoch 8/10\n",
      "8308/8308 [==============================] - 2s 268us/sample - loss: 0.0738 - accuracy: 0.9732 - val_loss: 0.4682 - val_accuracy: 0.8810\n",
      "Epoch 9/10\n",
      "8308/8308 [==============================] - 2s 270us/sample - loss: 0.0608 - accuracy: 0.9799 - val_loss: 0.4919 - val_accuracy: 0.8842\n",
      "Epoch 10/10\n",
      "8308/8308 [==============================] - 2s 269us/sample - loss: 0.0491 - accuracy: 0.9845 - val_loss: 0.5858 - val_accuracy: 0.8788\n",
      "Train on 8308 samples, validate on 924 samples\n",
      "Epoch 1/10\n",
      "8308/8308 [==============================] - 2s 274us/sample - loss: 0.3745 - accuracy: 0.8458 - val_loss: 0.2915 - val_accuracy: 0.8766\n",
      "Epoch 2/10\n",
      "8308/8308 [==============================] - 1s 170us/sample - loss: 0.2511 - accuracy: 0.9032 - val_loss: 0.2867 - val_accuracy: 0.8864\n",
      "Epoch 3/10\n",
      "8308/8308 [==============================] - 1s 170us/sample - loss: 0.2125 - accuracy: 0.9163 - val_loss: 0.2956 - val_accuracy: 0.8874\n",
      "Epoch 4/10\n",
      "8308/8308 [==============================] - 1s 170us/sample - loss: 0.1780 - accuracy: 0.9330 - val_loss: 0.3145 - val_accuracy: 0.8907\n",
      "Epoch 5/10\n",
      "8308/8308 [==============================] - 1s 172us/sample - loss: 0.1543 - accuracy: 0.9387 - val_loss: 0.4043 - val_accuracy: 0.8918\n",
      "Epoch 6/10\n",
      "8308/8308 [==============================] - 1s 171us/sample - loss: 0.1221 - accuracy: 0.9535 - val_loss: 0.4016 - val_accuracy: 0.8885\n",
      "Epoch 7/10\n",
      "8308/8308 [==============================] - 1s 172us/sample - loss: 0.1009 - accuracy: 0.9609 - val_loss: 0.4250 - val_accuracy: 0.8799\n",
      "Epoch 8/10\n",
      "8308/8308 [==============================] - 1s 171us/sample - loss: 0.0802 - accuracy: 0.9682 - val_loss: 0.6039 - val_accuracy: 0.8788\n",
      "Epoch 9/10\n",
      "8308/8308 [==============================] - 1s 172us/sample - loss: 0.0775 - accuracy: 0.9709 - val_loss: 0.6397 - val_accuracy: 0.8853\n",
      "Epoch 10/10\n",
      "8308/8308 [==============================] - 1s 169us/sample - loss: 0.0541 - accuracy: 0.9797 - val_loss: 0.6568 - val_accuracy: 0.8831\n",
      "Train on 8308 samples, validate on 924 samples\n",
      "Epoch 1/10\n",
      "8308/8308 [==============================] - 2s 297us/sample - loss: 0.3429 - accuracy: 0.8652 - val_loss: 0.2820 - val_accuracy: 0.8972\n",
      "Epoch 2/10\n",
      "8308/8308 [==============================] - 2s 196us/sample - loss: 0.2266 - accuracy: 0.9136 - val_loss: 0.2941 - val_accuracy: 0.8950\n",
      "Epoch 3/10\n",
      "8308/8308 [==============================] - 2s 196us/sample - loss: 0.1915 - accuracy: 0.9251 - val_loss: 0.2997 - val_accuracy: 0.8820\n",
      "Epoch 4/10\n",
      "8308/8308 [==============================] - 2s 196us/sample - loss: 0.1560 - accuracy: 0.9385 - val_loss: 0.3335 - val_accuracy: 0.8799\n",
      "Epoch 5/10\n",
      "8308/8308 [==============================] - 2s 196us/sample - loss: 0.1233 - accuracy: 0.9508 - val_loss: 0.3494 - val_accuracy: 0.8788\n",
      "Epoch 6/10\n",
      "8308/8308 [==============================] - 2s 196us/sample - loss: 0.1023 - accuracy: 0.9598 - val_loss: 0.3974 - val_accuracy: 0.8842\n",
      "Epoch 7/10\n",
      "8308/8308 [==============================] - 2s 197us/sample - loss: 0.0713 - accuracy: 0.9717 - val_loss: 0.5352 - val_accuracy: 0.8896\n",
      "Epoch 8/10\n",
      "8308/8308 [==============================] - 2s 200us/sample - loss: 0.0594 - accuracy: 0.9775 - val_loss: 0.5440 - val_accuracy: 0.8842\n",
      "Epoch 9/10\n",
      "8308/8308 [==============================] - 2s 200us/sample - loss: 0.0513 - accuracy: 0.9813 - val_loss: 0.5504 - val_accuracy: 0.8831\n",
      "Epoch 10/10\n",
      "8308/8308 [==============================] - 2s 199us/sample - loss: 0.0363 - accuracy: 0.9860 - val_loss: 0.8221 - val_accuracy: 0.8777\n",
      "Train on 8308 samples, validate on 924 samples\n",
      "Epoch 1/10\n",
      "8308/8308 [==============================] - 3s 390us/sample - loss: 0.3535 - accuracy: 0.8748 - val_loss: 0.2745 - val_accuracy: 0.8831\n",
      "Epoch 2/10\n",
      "8308/8308 [==============================] - 2s 288us/sample - loss: 0.2644 - accuracy: 0.9124 - val_loss: 0.2636 - val_accuracy: 0.8907\n",
      "Epoch 3/10\n",
      "8308/8308 [==============================] - 2s 297us/sample - loss: 0.2208 - accuracy: 0.9260 - val_loss: 0.2669 - val_accuracy: 0.8929\n",
      "Epoch 4/10\n",
      "8308/8308 [==============================] - 2s 298us/sample - loss: 0.1829 - accuracy: 0.9435 - val_loss: 0.2969 - val_accuracy: 0.8907\n",
      "Epoch 5/10\n",
      "8308/8308 [==============================] - 2s 297us/sample - loss: 0.1443 - accuracy: 0.9561 - val_loss: 0.3410 - val_accuracy: 0.8864\n",
      "Epoch 6/10\n",
      "8308/8308 [==============================] - 2s 294us/sample - loss: 0.1132 - accuracy: 0.9693 - val_loss: 0.3916 - val_accuracy: 0.8853\n",
      "Epoch 7/10\n",
      "8308/8308 [==============================] - 2s 299us/sample - loss: 0.0866 - accuracy: 0.9769 - val_loss: 0.4372 - val_accuracy: 0.8907\n",
      "Epoch 8/10\n",
      "8308/8308 [==============================] - 2s 291us/sample - loss: 0.0687 - accuracy: 0.9838 - val_loss: 0.5106 - val_accuracy: 0.8853\n",
      "Epoch 9/10\n",
      "8308/8308 [==============================] - 2s 293us/sample - loss: 0.0575 - accuracy: 0.9886 - val_loss: 0.5068 - val_accuracy: 0.8907\n",
      "Epoch 10/10\n",
      "8308/8308 [==============================] - 2s 288us/sample - loss: 0.0576 - accuracy: 0.9870 - val_loss: 0.5198 - val_accuracy: 0.8885\n"
     ]
    }
   ],
   "source": [
    "sensitivity = np.zeros((3,3))\n",
    "especificity = np.zeros((3,3))\n",
    "accuracy = np.zeros((3,3))\n",
    "for i, embed_dim in enumerate([32,64,128]):\n",
    "    for j,cells in enumerate([32,64,128]):\n",
    "        #---------------------------------------------------------------------------------\n",
    "        model_CBOW = W2VTransformer(size=embed_dim, window = 10, max_vocab_size= len(tokenizer.word_index), min_count=0, seed=1, sg = 0, hs=1, iter = 50)\n",
    "        model_CBOW.fit(all_words)\n",
    "        wordsmatrix = model_CBOW.transform(words[:2000])\n",
    "        #-------------------------------------------------------------------------------------\n",
    "        model = Model_Sentimen(embed_dim,cells,wordsmatrix)\n",
    "        #opt = optimizers.Adam(learning_rate=0.0001, beta_1=0.9, beta_2=0.999, amsgrad=False)\n",
    "        model.compile(optimizer='adam', loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "        model.fit(X_tr, y_tr, validation_split=0.1,batch_size=32, epochs=10, verbose=1)\n",
    "        y_pred = np.round(model.predict(X_te))\n",
    "        sensitivity[i,j] = recall_score(y_te,y_pred)\n",
    "        accuracy[i,j] = accuracy_score(y_te,y_pred)\n",
    "        especificity[i,j] = especi_score(y_te,y_pred.flatten())     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAArkAAADgCAYAAAAHQH6iAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8li6FKAAAgAElEQVR4nO3deXxU9d33/9ebJOBSxYWIqMRg2QRFqwG1l+1PUSu2CJdaFbUtqC2192VtXS6r3q1V2961i2vrXRcul9YqKrbeWK1YFat1Ba0KhFVEFgGDUBEVMOTz++Oc0CFmmSSTTJi8n4/HPJg55zvnfE6Yz8xnvvM936OIwMzMzMyskHTJdwBmZmZmZrnmItfMzMzMCo6LXDMzMzMrOC5yzczMzKzguMg1MzMzs4LjItfMzMzMCo6LXDMrCJLWSdqnkfWzJB2RxXbOkPR4ToMzyzNJl0makPH4BElL0rz5XDPyo9E8M+tI5Hly25akp4EDgN0jYkOewzFrN5IOB34JDAY2AbOB70fEtHbY953A0oj4YQ62FUC/iFjQ6sCs05G0COhJkgO17oyIc/MTUULSm8AFEfH/WrGNO8lRnpm1heJ8B1DIJJUDXwDeB0YBD7TTfosjoro99mVWH0k7An8BvgPcD3QlyQV/0bPO6PiIeCLfQdSxNzAr30GYtSUPV2hb3wBeBO4ExtYulLStpGskvS3pfUn/kLRtuu5wSc9L+lf6U9K4dPnTkr6ZsY1xkv6R8Tgk/Zek+cD8dNkN6TbWSnpF0hcy2helP1+9KemDdH1vSTdJuibzICRNlnR+W/yBrGD1B4iIeyNiU0R8HBGPR8QbAJLOkjRb0hpJUyTtXfvE9LV8jqT5aR7cJEnpur6S/p7mzSpJ99V5Xl9J44EzgIvTn1YfTtcvknS0pD0kfSxpl4znfi7dXklmbkl6Jm3yerqtUyXNlHR8xnNL0ud+rs3+mlZwsngtnydpYbruV5K6ZKxvLH8GS/qbpNWSVkq6LF1+haS7JXWTtA4oInldv5muXyTp6PR+vZ8PGbHVm2eS/lvSg3WO80ZJN7TdX9KsYS5y29Y3gD+mt2Ml9UyX/xo4GPg8sAtwMVCTvlH9FfgNUAocCLzWjP39J3AIMCh9PC3dxi7APcADkrZJ110AnAZ8GdgROAv4CLgLOK32DVVSD+Do9Plm2ZoHbJJ0l6TjJO1cu0LSaOAy4ESS1/mzwL11nj8SGAoMAU4Bjk2X/wR4HNgZ2IskV7YQEbeS5NwvI+IzEXF8nfXvAC8AJ2UsPh2YFBGf1Gn7xfTuAem27gN+D3wto9mXgeUR8c9G/h5mdTX1Wj4BqAAOAkaTvEc3mj+SdgCeAB4D9gD6Ak9mbjQiNkTEZ9KHB0TEZ+uJraHPh8zt1JdndwMjJO2UxlMMjCHJGbN25yK3jSgZj7g3cH9EvAK8CZyeFo9nAd+LiGVpL9fz6Xjd04En0t6vTyLivYhoTpH784hYHREfA0TE3ek2qiPiGqAbMCBt+03ghxExNxKvp21fJhlecVTabgzwdESsbOWfxDqRiFgLHA4EcBtQlf4i0BM4h+S1OjsdVvN/gAMze6OAqyPiXxGxGJhK8mUN4BOSvNojItZHxD9omXtIPsRJe4nHkP0XubuBLysZkgHwdeAPLYzDOoeH0l8lam/founX8i/S9/PFwPWkr1caz5+RwIqIuCbd5gcR8VIL4q3386GpJ0XEcuAZ4OR00QhgVfoZaNbuXOS2nbHA4xGxKn18T7qsB7ANSdFbV+8GlmdrSeYDSRelP2m9L+lfQPd0/03t6y7+3VP1NfwBbi2QfgiPi4i9gP1IepauJ/lgv6H2Ax9YDQjYM+PpKzLufwTU9jxdnLZ9WcnZ4Ge1MLwHgcMk9QK+CNSQ9Ihlc1zvAM8BJ6U9VseR9GiZNeQ/I2KnjNttNP1aznw/f5skf6Dx/GntZ0it1mzHnx/WYfjEszagZHztKUCRpNoP627ATkAvYD3wWeD1Ok9dAgxrYLMfAttlPN69njabp8pQMv72YpIe2VkRUSNpDcmbYe2+PgvMrGc7dwMzJR0A7As81EBMZlmJiDlKzsT+Nslr72cR0ezCMCJWAN+Czb+WPCHpmXpmPmh02piIWKNkmrBTSV7jE6N5U83cRdLbVQy8EBHLmvFcs2xey73594lhZcA76f0G8yftzR2Tg/Aa+3zIVF/OPAT8TtJ+JD3LF+cgHrMWcU9u2/hPkuliBpH8zHogyQfpsyTjdG8Hrk1PgCmSdJikbiS9QUdLOkVSsaRdJdX+TPsacKKk7ST1Bc5uIoYdgGqgCiiWdDnJ2KpaE4CfSOqnxBBJuwJExFKS8bx/AB6sHf5gli1JAyVdKGmv9HFvkp9bXwRuBi6VNDhd113SyQ1vbYvtnly7TWANyYdsTT1NVwJNzeV5D0k+fpXGhyrUt62HSMZKfg+PN7QWyOK1/N+Sdk5z53tA7YlpjeXPX4Bekr6fnmC2g6RDWhBeg58PdXwqNyJiPTCJJKdeTodbmOWFi9y2MRa4IyIWR8SK2hvwW5KzUS8BZpAUkquBXwBd0jeDLwMXpstfI5ljF+A6YCPJm8pdNP3z6BSSkw/mkfzUtZ4tf/66lmRqp8eBtcD/ANtmrL8L2B//1GQt8wHJSZAvSfqQpLidCVwYEX8mec1PlLQ2XX5cltsdmm5zHTCZZGz7wnra/Q8wKP1Jt6FfIiYD/UjGMNb9VSXTFcBd6bZOAUi/+D0I9AH+lGXs1nk9nM5AUHv7M02/lv8f8ArJ58AjJK9pGsufiPgAOAY4nmTIz3zgyBbE29TnQ62G8syfH9Yh+GIQVi9JXyQZtrB3M3/GNesU0l9H+kfE15psbNYM2sovQCKpDJhDchGktfmOxzovj8m1T5FUQvLz2AQXuGafpmSO3bNJZlYws1Q6g9AFJOPcXeBaXnm4gm1B0r7Av0hOkLs+z+GYdTjp9E9LgL9GxDNNtTfrLCRtTzK84Rjgx3kOx8zDFczMzMzy4ZVXXtmtuLh4Ask0i+54bJ4aYGZ1dfU3Dz744Hfra+DhCmZm1iqSbieZLurdiNivnvUCbiA5sfYjYFxEvNq+UZp1PMXFxRN23333fUtLS9d06dLFvY7NUFNTo6qqqkErVqyYAIyqr42/NZiZWWvdSXJ1q4YcRzKTRT9gPPC7dojJbGuwX2lp6VoXuM3XpUuXKC0tfZ+kF7xeeevJ7dGjR5SXl+dr92ZbeOWVV1ZFRGk+Y3BOWEfSnJyIiGcklTfSZDTw+/RE1hcl7SSpV3oZ2AY5J6wjaaPPiS4ucFsu/ds12GGbtyK3vLyc6dOn52v3ZluQ9Ha+Y3BOWEeS45zYky3n6V6aLvtUkStpPElvL2VlZc4J6zA6wudErn300Uc65JBDBm7cuFGbNm3S8ccfv+a66657B2DUqFF93njjje1LSkriwAMP/PDuu+9+u1u3bq0qyE866aTykSNHvn/mmWeuGTZs2IBf//rXS774xS9+lJuj+TSPyTUzsw4jIm4FbgWoqKhwD5d1KhIH53J7EbzS2Pptttkm/vGPf8zt3r17zYYNGzR06NABTz755PtHHXXUh2ecccbqhx566C2A0aNH97n++ut7/OAHP6jKZXxtzWNyzcysrS0Demc83itdZmZ51KVLF7p3714DsHHjRlVXV6fnicKpp576fpcuXejSpQsVFRUfLl26tGvd51dXVzN+/Pi9+vXrN7h///6Dfvazn+0G8Oyzz243dOjQAYMHD9738MMP7/f222+XNBRDdXU1J510UnntNq688srdcnV87sk1M7O2Nhk4V9JEkss9v9/UeFwzax/V1dXst99+gxYvXtxt7Nix7w4fPvzDzPUbNmzQfffdt+u11167pO5zr7nmmtLFixd3raysnFVSUsLKlSuLNmzYoPPOO6/skUceWbDHHntU33bbbTtfdNFFez7wwAOL6tv/Cy+8sN3y5ctL5s+fPwtg1apVRbk6Nhe5ZmbWKpLuBY4AekhaSnIhgBKAiLgZeJRk+rAFJFOInZmfSM2sruLiYubMmVO5atWqoq985SufnTZt2jZDhw5dX7t+7NixZYceeui6ESNGrKv73KeeemrHc845p6qkJOmo7dmz56Zp06ZtM3/+/G2HDx/eH6CmpobS0tJPGtr/wIEDNyxZsqTb2LFjex9//PHvn3DCCTm7Up6LXDMza5WIOK2J9QH8VzuFY2Yt0KNHj01f+MIXPnj44Ye71xa5F154Ya9Vq1YVT5ky5c1stxMR6tu378evvfbanGzal5aWbpo5c2bln//85x1vvvnm0vvuu2+Xhnp9m8tFLkA6/qRZfKU4M2sDurL570fxY78fWQv5869Te+edd4q7du0aPXr02LRu3TpNnTp1x4suumgFwLXXXtvjqaee6v7ss8/OLSqqfwTBUUcdtfaWW27pMXLkyLW1wxWGDBmyfvXq1cVPPPHE9kcfffSHGzZs0IwZM7pVVFSsr28by5cvL+7WrVvNuHHj/jV48OD1X//61/fJ1fG5yG1nfj/JgZb8EcF/yObwC9Usb5x+1l6WLFlSMm7cuD6bNm0iIjR69OjVp5122vsAF1988d69evXaUFFRsS/AyJEj1/z617/eYiz9+eefXzVv3rxuAwcOHFxcXBxjx46tuuyyy6omTpz45nnnnVf2wQcfFG3atEnf+c53VjZU5C5atKjk7LPPLq+pqRHAVVddtTRXx9dhi1wn+b+1pGcHIK5oyZNa9kdsad3JFS3otWrhrnJJ0giSy5QWARMi4uo6668DjkwfbgfsFhE7tW+UZpYzHfxDqcWfEzmOozEd/E/YITQ15VeuHXLIIR/Pnj27sr511dXVTcZSUlLChAkTlpLMfb3Z5z//+Y+nT58+t277Bx98cFHt/Zdffnnz+srKytnNiTtbHbbIbYmtIclt6yepCLgJOIYksadJmhwRm98oIuL8jPbfBT7X7oFa59EJf91ozy/W4M+JrU4nzAn7tIIqcs3ayTBgQUQsBEinRRoN1PttGDiN5GxzMzNrBndeWWv4YhBmzdfQJUo/RdLeQB/gqXaIy8zMzFLuyTVrW2OASRGxqb6VksYD4wHKysoa3Egh//LmcXpmZtYW3JNr1nzNuUTpGODehjYUEbdGREVEVJSWluYwRMs3qWU3MzPLDffkmjXfNKCfpD4kxe0Y4PS6jSQNBHYGXmjf8Apfi8fpeT5ZM7NOwz25Zs0UEdXAucAUYDZwf0TMknSVpFEZTccAE9OrPZmZmXU4q1atKhoxYsQ+ffr0GbzPPvsMfuKJJ7bPXP/jH/+4p6SDly9f3uqO0ZNOOqn8jjvu2Blg2LBhA5555pntWrvNxrgn16wFIuJR4NE6yy6v8/iK9ozJzMy2brpSB+dye/HjaHKu2/Hjx/f+0pe+tPaxxx5buH79eq1bt25zB+iCBQtKnnzyyR179eq1MZdxtRf35JqZmZl1Qu+9917RSy+9tMP3v//9VQDbbLNN9OjRY/OJ0ueee27vX/3qV0vVwAkD1dXVjB8/fq9+/foN7t+//6Cf/exnuwE8++yz2w0dOnTA4MGD9z388MP7vf322yUNxVBdXc1JJ51UXruNK6+8crdcHZ97cs3MzMw6oblz53bdZZddqk8++eTyysrK7YYMGfLhbbfdtmTHHXesufvuu3fq1avXJ4cddtjHDT3/mmuuKV28eHHXysrKWSUlJaxcubJow4YNOu+888oeeeSRBXvssUf1bbfdtvNFF1205wMPPLCovm288MIL2y1fvrxk/vz5syAZPpGr43ORa1bAPJG6mZk1pLq6WrNnz97uhhtuWDx8+PAPzzzzzN4/+tGPdv/pT3+64pe//OXuU6dOnd/Y85966qkdzznnnKqSkqSjtmfPnpumTZu2zfz587cdPnx4f4CamhpKS0s/aWgbAwcO3LBkyZJuY8eO7X388ce/f8IJJ6zN1fF5uIKZmZlZJ1ReXr6xZ8+eG4cPH/4hwKmnnrrm9ddf32727Nndli5d2m3IkCGD9txzz/1XrlzZ9aCDDtp38eLFTXaORoT69u378Zw5cyrnzJlTOW/evMrnnnuuwWK5tLR008yZMyuPPPLID26++ebSMWPGlOfq+LIqciWNkDRX0gJJl9SzvkzSVEn/lPSGpC/nKkAzs5zxxLVmZpuVlZVV77777htff/31bgCPP/74jgMGDFg/bNiwj1evXv36smXLZixbtmxGz549N7766quzy8rKqjOff9RRR6295ZZbenzySdJRu3LlyqIhQ4asX716dXHtLA0bNmzQ9OnTt2kohuXLlxdv2rSJcePG/evnP//5shkzZuRsxoUmK3JJRcBNwDEkly+dJmlyRFRmNPshyTRKv5M0iOSs8/JcBWlmZmZmufeb3/xm8RlnnLHPxo0bVVZWtuHee+9dlO1zzz///Kp58+Z1Gzhw4ODi4uIYO3Zs1WWXXVY1ceLEN88777yyDz74oGjTpk36zne+s7KiomJ9fdtYtGhRydlnn11eU1MjgKuuumppbo4suzG5w4AFEbEQQNJEYDSQWeQGsGN6vzvwTq4CNDMzM+sMspnyK9c+//nPfzxz5szZjbVZtmzZjPqWl5SUMGHChKUknaBbbHP69Olz67Z/8MEHF9Xef/nllzevr6ysbHT/LZXNcIU9gSUZj5emyzJdAXxN0lKSXtzv1rchSeMlTZc0vaqqqgXhmpmZmZk1LVcnnp0G3BkRewFfBv4g6VPbjohbI6IiIipKS0tztGszMzMzsy1lU+QuA3pnPN4rXZbpbOB+gIh4AdgG6JGLAM3MzMzMmiubInca0E9SH0ldgTHA5DptFgNHAUjal6TI9XgEMzMzM8uLJovciKgGzgWmALNJZlGYJekqSaPSZhcC35L0OnAvMC4iPJ+8mZmZmeVFVlc8i4hHSU4oy1x2ecb9SuA/chuamZltLSSNAG4AioAJEXF1nfVlwF3ATmmbS9LPFjOzNuErnpm1QFMXSEnbnCKpUtIsSfe0d4xm7SVjPvXjgEHAaemc6Zlq51P/HMmwt//bvlGaWX1OPvnk8l122eWAfv36Dc5c/u1vf3uvPn36DO7fv/+gY4455rOrVq0qguTiDieeeGJ5//79B+2zzz6DL7300t1bG8Nf/vKXHY488si+ADfeeOOu3/jGN8pau01wkWvWbNl8oEvqB1wK/EdEDAa+3+6BmrWfzfOpR8RGoHY+9UyeT92sKdLBOb1l4ayzzlo1efLkT11299hjj107b968WfPmzavs27fv+h/96Ee7A9xxxx07b9y4scu8efMqX3/99dm///3vS+fOnds113+KXHCRa9Z82Xygfwu4KSLWAETEu+0co1l7ytl86mbWvo477rh1paWl1XWXn3jiiWtLSkoAOOywwz5ctmxZVwBJfPTRR10++eQTPvzwQ5WUlMROO+20qe7zJ02atOOgQYP2HTBgwKDDDjusP8DatWu7nHzyyeX777//vvvuu++gu+++e6fGYrv99tt37tev3+ABAwYMqqioGNDcY8tqTK6ZbaG+D/RD6rTpDyDpOZLxh1dExGN1NyRpPDAeoKwsJ7/OmHVUtfOpXyPpMJL51PeLiJrMRs4Js47nzjvv7PHVr351NcC4cePWPPzwwzvttttuB6xfv77LT37ykyU9e/bcosh95513is8999zyp59+es7AgQM3rly5sgjgsssu63XkkUeufeCBBxatWrWqqKKiYt9Ro0atbWi/V199da/HH398Xp8+fT6pHS7RHO7JNWsbxUA/4AiSD/fbJH3qG6svkGIFImfzqTsnzDqWH/zgB7sXFRXFOeecsxrg73//+3ZdunSJFStWvLFgwYIZv/3tb3evrKzcYrjC008/vf2wYcM+GDhw4EaA2iL46aef3vG6667rNXDgwEGHH374gA0bNmjBggUNDnWoqKhYd8YZZ5Rfc801PaqrP9XZ3CQXuWbNl80H+lJgckR8EhFvAfNIil6zQuT51M0K0I033rjrlClTdvrTn/70VpcuScn4hz/8Yddjjz32/W7dusWee+5ZPXTo0HXPP//89tlsLyKYNGnSgjlz5lTOmTOncvny5TMOOuig9Q21v+eeexb/9Kc/fWfJkiVdDz744EErVqxoVm+ui1yz5svmA/0hkl5cJPUgGb6wsD2DNGsvnk/drPBMmjRpxxtuuGH3Rx99dMEOO+yweVhRWVnZxqlTp+4IyRjbV199dfv9999/i0L1iCOO+PDll1/eYc6cOV0BaocrHHnkkWuvueaanjU1yeaee+65bRuLYdasWd2GDx/+4fXXX//OzjvvXL1w4cJmneDmMblmzRQR1ZJqP9CLgNtrP9CB6RExOV33JUmVwCbgvyPivfxFbda2PJ+62dbp+OOP7/Piiy/usGbNmuKePXsOueSSS945//zzV11wwQVlGzdu7DJ8+PD+AAcddNC6e+65Z/HFF1/87pgxY8r79u07OCI4/fTTVx1yyCEfZ25zjz32qL7xxhsXnXDCCX1ramrYddddP3n++efnX3311e+MHz++bODAgYNqamrUu3fvDVOnTl3QUGznn3/+XosWLeoWETr88MPXHnrooR831LY+LnLNWiCLD/QALkhvZmZmTYt4pb13+fDDD79V3/LFixfPrG959+7da/761782+cvkKaecsvaUU06pzFz2mc98Ju65556367YdOXLkByNHjvwA4LzzznsPeA/g8ccffzOLQ2iQhyuYmZmZWcFxkWtmZmZmBcdFrpmZmZkVHBe5ZmZmZvlRU1NTo3wHsbVK/3Y1Da13kWtmZmaWHzOrqqq6u9BtvpqaGlVVVXUH6j1BDjy7gpmZmVleVFdXf3PFihUTVqxYsR/ueGyuGmBmdXX1Nxtq4CLXzMzMLA8OPvjgd4FRTTa0FvG3BjMzMzMrOC5yzczMzKzguMg1MzMzs4LjItfMzMzMCo6LXDMzMzMrOC5yzVpA0ghJcyUtkHRJPevHSaqS9Fp6a3CKEzMzM8s9TyFm1kySioCbgGOApcA0SZMjorJO0/si4tx2D9DMzMzck2vWAsOABRGxMCI2AhOB0XmOyczMzDK4yDVrvj2BJRmPl6bL6jpJ0huSJknq3T6hmZmZGWRZ5DY1/jBtc4qkSkmzJN2T2zDNtjoPA+URMQT4G3BXfY0kjZc0XdL0qqqqdg3QzMyskDVZ5GaMPzwOGAScJmlQnTb9gEuB/4iIwcD32yBWs45iGZDZM7tXumyziHgvIjakDycAB9e3oYi4NSIqIqKitLS0TYI1MzPrjLLpyc1m/OG3gJsiYg1ARLyb2zDNOpRpQD9JfSR1BcYAkzMbSOqV8XAUMLsd4zMzM+v0spldob7xh4fUadMfQNJzQBFwRUQ8lpMIzTqYiKiWdC4wheT1fntEzJJ0FTA9IiYD50kaBVQDq4FxeQvYzMysE8rVFGLFQD/gCJKfbp+RtH9E/CuzkaTxwHiAsrKyHO3arP1FxKPAo3WWXZ5x/1KSITxmZmaWB9kMV2hy/CFJ7+7kiPgkIt4C5pEUvVvw+EMzMzMzaw/ZFLlNjj8EHiLpxUVSD5LhCwtzGKeZmXVgnoXHzDqaJocrZDn+cArwJUmVwCbgvyPivbYM3MzMOoZsrgJYZxaeNZJ2y0+0ZtZZZDUmN4vxhwFckN7MzKxz2TwLD4Ck2ll4Mi917Vl4zKxd+YpnZmbWWtlcBbA/0F/Sc5JelDSi3aIzs04pV7MrmJmZNcaz8JhZu3JPrpmZtZZn4TGzDsdFrpmZtZZn4TGzDsdFrpmZtUpEVAO1s/DMBu6vnYUnvfIf6br30ll4puJZeMysjXlMrpmZtZpn4TGzjsY9uWZmZmZWcFzkmpmZmVnBcZFrZmZmZgXHRa5ZC0gaIWmupAWSLmmk3UmSQlJFe8ZnZmbW2bnINWsmSUXATcBxwCDgNEmD6mm3A/A94KX2jdDMzMxc5Jo13zBgQUQsjIiNwERgdD3tfgL8AljfnsGZmZmZi1yzltgTWJLxeGm6bDNJBwG9I+KRxjYkabyk6ZKmV1VV5T5SMzOzTspFrlmOSeoCXAtc2FRbX8LUzMysbbjINWu+ZUDvjMd7pctq7QDsBzwtaRFwKDDZJ5+ZmZm1Hxe5Zs03DegnqY+krsAYYHLtyoh4PyJ6RER5RJQDLwKjImJ6fsI1MzPrfFzkmjVTRFQD5wJTgNnA/RExS9JVkkblNzozMzMDKM53AGZbo4h4FHi0zrLLG2h7RHvEZGZmZv/mnlwzMzMzKzgucs3MzMys4LjINTMzM7OC4yLXzMzMzAqOi1wzMzMzKzgucs3MzMys4LjINTMzM7OC4yLXzMzMzApOVkWupBGS5kpaIOmSRtqdJCkkVeQuRDMzMzOz5mmyyJVUBNwEHAcMAk6TNKiedjsA3wNeynWQZmZmZmbNkU1P7jBgQUQsjIiNwERgdD3tfgL8Alifw/jMzMzMzJotmyJ3T2BJxuOl6bLNJB0E9I6IRxrbkKTxkqZLml5VVdXsYM3MzMzMstHqE88kdQGuBS5sqm1E3BoRFRFRUVpa2tpdm+VNU+PUJZ0jaYak1yT9o74hPmaFxOdumFlHk02RuwzonfF4r3RZrR2A/YCnJS0CDgUm+w3MClWW49TviYj9I+JA4JckXwTNCpLP3TCzjiibInca0E9SH0ldgTHA5NqVEfF+RPSIiPKIKAdeBEZFxPQ2idgs/5ocpx4RazMebg9EO8Zn1t587oaZdThNFrkRUQ2cC0wBZgP3R8QsSVdJGtXWAZp1QE2OUweQ9F+S3iTpyT2vnWIzywefu2FmHU5xNo0i4lHg0TrLLm+g7RGtD8ts6xcRNwE3STod+CEwtm4bSeOB8QBlZWXtG6BZO8k4d2NcU20j4lbgVoCKigr/AmJmLeYrnpk1X1Pj1OuaCPxnfSt8MqYVCJ+7YWYdjotcs+ZrdJw6gKR+GQ+/Asxvx/jM2pvP3TCzDier4Qpm9m8RUS2pdpx6EXB77Th1YHpETAbOlXQ08AmwhnqGKpgViixzwsysXbnINWuBpsapR8T32j0oszzyuRtm1tF4uIKZmZmZFRwXuWZmZmZWcFzkmpmZmVnBcZFrZmZmZlCuwcQAAA0ISURBVAXHRa6ZmZmZFRwXuWZmZmZWcFzkmpmZmVnBcZFrZmZmZgXHRa6ZmZmZFRwXuWZmZmZWcFzkmpmZmVnBcZFrZmZmZgXHRa5ZC0gaIWmupAWSLqln/QWSKiW9IelJSXvnI04zM7POykWuWTNJKgJuAo4DBgGnSRpUp9k/gYqIGAJMAn7ZvlGamZl1bi5yzZpvGLAgIhZGxEZgIjA6s0FETI2Ij9KHLwJ7tXOMZmZmnZqLXLPm2xNYkvF4abqsIWcDf23TiMzMzGwLxfkOwKyQSfoaUAH8fw2sHw+MBygrK2vHyMzMzAqbe3LNmm8Z0Dvj8V7psi1IOhr438CoiNhQ34Yi4taIqIiIitLS0jYJ1szMrDNykWvWfNOAfpL6SOoKjAEmZzaQ9DngFpIC9908xGhmZtapucg1a6aIqAbOBaYAs4H7I2KWpKskjUqb/Qr4DPCApNckTW5gc2ZmZtYGPCbXrAUi4lHg0TrLLs+4f3S7B2VmZmabZdWT64nvzczMzGxr0mSR64nvzczMzGxrk01Prie+NzOzRvkXPzPraLIpcnM28b2k8ZKmS5peVVWVfZRmZtZh+Rc/M+uIcjq7QsbE97+qb73nBDUzK0j+xc/MOpxsitycTXxvZmYFyZe6NrMOJ5spxDZPfE9S3I4BTs9skDHx/QhPfG9mZg3xpa7NrL002ZPrie/NzKwJvtS1mXU4WV0MwhPfm5lZI/yLn5l1OL6sr5mZtYp/8TOzjsiX9TUzs1bzL35m1tG4J9fMzMzMCo6LXDMzMzMrOC5yzVogi0uYflHSq5KqJX01HzGamZl1Zi5yzZopy0uYLgbGAfe0b3RmZmYGPvHMrCU2X8IUQFLtJUwraxtExKJ0XU0+AjQzM+vs3JNr1nzNvYRpgySNlzRd0vSqqqqcBGdmZmYucs3yyld3MjMzaxsucs2aL6tLmJqZmVn+uMg1a77NlzCV1JXkEqa+epOZmVkH4iLXrJmyuYSppKGSlgInA7dImpW/iM3MzDofz65g1gJZXMJ0GskwBjMzM8sD9+SamZmZWcFxkWtmZmZmBcdFrpmZmZkVHBe5ZmZmZlZwXOSamZmZWcFxkWtmZmZmBcdFrpmZmZkVHBe5ZmZmZlZwXOSamZmZWcFxkWtmZmZmBcdFrpmZmZkVHBe5ZmZmZlZwsipyJY2QNFfSAkmX1LO+m6T70vUvSSrPdaBmHYlzwmxLzgkz62iaLHIlFQE3AccBg4DTJA2q0+xsYE1E9AWuA36R60DNOgrnhNmWnBNm1hFl05M7DFgQEQsjYiMwERhdp81o4K70/iTgKEnKXZhmHYpzwmxLzgkz63CyKXL3BJZkPF6aLqu3TURUA+8Du+YiQLMOyDlhtiXnhJl1OMXtuTNJ44Hx6cN1kubmdAdXNLq2B7Cq3rhasq/27IC4otG1W+9xQWPHltvjgqaObe+WbrY1nBMtdEWja7fe4wLnhHOiZa5odK2PK1sdMCes5bIpcpcBvTMe75Uuq6/NUknFQHfgvbobiohbgVtbFmrrSJoeERX52Hdb8nHlhXOiA/Nx5YVzogPzcVlnlc1whWlAP0l9JHUFxgCT67SZDIxN738VeCoiIndhmnUozgmzLTknzKzDabInNyKqJZ0LTAGKgNsjYpakq4DpETEZ+B/gD5IWAKtJ3uDMCpJzwmxLzgkz64jUWb5ISxqf/gxWUHxc1lKF+jf2cVlLFerf2MdlnVWnKXLNzMzMrPPwZX3NzMzMrOAUXJEraRtJL0t6XdIsSVemy/+YXnJypqTbJZXkO9aWkLSTpEmS5kiaLemwjHUXSgpJPfIZYzbS/4N3Jc3MWPar9LjekPRnSTuly0sk3SVpRnrMl+Yv8q2Pc8I5YVsq5JwolHwA54S1XsEVucAGYHhEHAAcCIyQdCjwR2AgsD+wLfDN/IXYKjcAj0XEQOAAYDaApN7Al4DFeYytOe4ERtRZ9jdgv4gYAswDat+kTga6RcT+wMHAt+Xr3jeHc2LrcCfOifZSyDlRKPkAzglrpYIrciOxLn1Ykt4iIh5N1wXwMsk8jlsVSd2BL5KcpUxEbIyIf6WrrwMuBraKQdYR8QzJGdaZyx5Pr4QE8CL//j8KYHslc2tuC2wE1rZXrFs754RzwrZUqDlRSPkAzglrvYIrcgEkFUl6DXgX+FtEvJSxrgT4OvBYvuJrhT5AFXCHpH9KmiBpe0mjgWUR8Xqe48uls4C/pvcnAR8Cy0l6IX4dEasbeqJ9mnOiIDgncqhAc6Iz5QM4J6wJBVnkRsSmiDiQ5BveMEn7Zaz+v8AzEfFsfqJrlWLgIOB3EfE5koS+ArgMuDyPceWUpP8NVJP8dAgwDNgE7EHyJn6hpH3yFN5WyTmxdXNO5F6B5kSnyAdwTlh2CrLIrZX+TDOVdEyPpB8DpcAF+YyrFZYCSzN6HCaRvKH1AV6XtIjkDftVSbvnJ8TWkTQOGAmckXE1pNNJxph9EhHvAs8BvpRjCzgntj7OibZVYDlR8PkAzgnLXsEVuZJKM8623BY4Bpgj6ZvAscBpEVGTzxhbKiJWAEskDUgXHQW8GhG7RUR5RJSTvMkdlLbdqkgaQTJmbFREfJSxajEwPG2zPXAoMKf9I9w6OSecE7alQs2JQs8HcE5Y8zR5Wd+tUC/gLklFJEX8/RHxF0nVwNvAC5IA/hQRV+Uxzpb6LvBHJdeHXwicmed4WkTSvcARQA9JS4Efk5wl2w34W/p/9GJEnAPcRDLGbBYg4I6IeCMvgW+dnBNbAedEuyrknCiIfADnhLWer3hmZmZmZgWn4IYrmJmZmZm5yDUzMzOzguMi18zMzMwKjotcMzMzMys4LnLNzMzMrOB0iiJX0iZJr2XcLmnGc4+Q9JdW7LvB50taJKlHev/5lu6jif0/Lakivf9o7dyQ7UnSVZKObu/9WsOcE84J25JzwjlhhacQ58mtz8fp5Rs7rIj4fDvs48ttvY8G9ltQl5MsEM4JnBO2BecEzgkrLJ2iJ7ch6Tfkn6ff2qdLOkjSFElvSjono+mOkh6RNFfSzZK6pM//kqQXJL0q6QFJn0mXj5A0R9KrwIkZ+9tV0uOSZkmaQDJhde26dem/R6Tfqiel2/ij0hmvJX05XfaKpBvr++YvaVtJEyXNlvRnYNs6x9tDUnm6nTslzUv3cbSk5yTNlzQsbb+9pNslvSzpn5JGp8vHSfqTpMfS9r9Mlxel25wpaYak89Pld0r6anr/qHRbM9Jtd8uI7cr0bzlD0sDW/w9bczknnBO2JeeEc8K2YhFR8DdgE/Baxu3UdPki4Dvp/euAN4AdSK5bvjJdfgSwHtgHKAL+BnwV6AE8A2yftvsBcDmwDbAE6Efy5nQ/8Je0zY3A5en9rwAB9Egfr8vY3/sk1xfvArwAHJ6x3T5pu3trt1vnWC8Abk/vDwGqgYqM4+0BlKfL90/38QpwexrvaOChtP3/Ab6W3t8JmAdsD4wjuZJO9zSut4HewMHA3zJi2Sn99870b1Z7DP3T5b8Hvp8R23fT+/8LmJDv100h35wTzgnfnBPOCd8K/dZZenI/jogDM273ZaybnP47A3gpIj6IiCpgg/49LunliFgYEZtI3jQOJ7ku9iDgOUmvAWOBvYGBwFsRMT8iArg7Y19frH0cEY8AaxqI9+WIWBrJtdNfI3mzGQgsjIi30jb3NvDczH28QfKGXJ+3ImJGuo9ZwJNpvDPS/QF8CbgkPb6nSd58ytJ1T0bE+xGxHqhMj30hsI+k3yi5vvjaOvsckO53Xvr4rjTeWn9K/30lIwZrG86JT3NOdG7OiU9zTthWrbOMyW3MhvTfmoz7tY9r/z51r30cJN9m/xYRp2WukJSLMV2ZcWyibf6f6h5r5t+hdn8CToqIuZlPlHRIfTFGxBpJBwDHAucApwBntSCmtjpmy45zwjlhW3JOOCdsK9RZenJba5ikPukYq1OBfwAvAv8hqS9sHpfUH5gDlEv6bPrczDe3Z4DT0/bHATs3I4a5JN9+y9PHpzbQLnMf+5H8FNVSU4DvZoz1+lxjjZWcAdwlIh4EfggcVKfJXJK/Td/08deBv7ciPssf5wTOCduCcwLnhHUsneVb0LbpTym1HouIrKeHAaYBvwX6AlOBP0dEjaRxwL21g+KBH0bEPEnjgUckfQQ8SzJ+C+DKtP0s4HlgcbYBRMTHkv4X8JikD9OY6vM74A5Js4HZJD/ptNRPgOuBN9I37reAkY203zPdd+2Xp0vrHMN6SWcCD0gqTo/h5lbEZy3nnGgZ50Thck60jHPCOiwlw2tsayDpMxGxLv3GfBMwPyKuy3dcZvninDDbknPC7N88XGHr8q20p2EWyRmrt+Q5HrN8c06Ybck5YZZyT66ZmZmZFRz35JqZmZlZwXGRa2ZmZmYFx0WumZmZmRUcF7lmZmZmVnBc5JqZmZlZwXGRa2ZmZmYF5/8H0Y1owfJZS5UAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 720x216 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best accuracy= 0.9034213945430922\n"
     ]
    }
   ],
   "source": [
    "fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(10,3))\n",
    "X = np.arange(3)\n",
    "ax1.bar(X + 0.00, accuracy[0,:], color = 'b', width = 0.25)\n",
    "ax1.bar(X + 0.25, accuracy[1,:], color = 'g', width = 0.25)\n",
    "ax1.bar(X + 0.50, accuracy[2,:], color = 'r', width = 0.25)\n",
    "ax1.set_xticks([0.25, 1.25, 2.25])\n",
    "ax1.set_xticklabels(['32','64', '128'])\n",
    "ax1.set_title('Accuracy')\n",
    "ax1.set_xlabel('Embedding dimension')\n",
    "ax2.bar(X + 0.00, sensitivity[0,:], color = 'b', width = 0.25)\n",
    "ax2.bar(X + 0.25, sensitivity[1,:], color = 'g', width = 0.25)\n",
    "ax2.bar(X + 0.50, sensitivity[2,:], color = 'r', width = 0.25)\n",
    "ax2.set_xticks([0.25, 1.25, 2.25])\n",
    "ax2.set_xticklabels(['32','64', '128'])\n",
    "ax2.set_title('Sensitivity')\n",
    "ax2.set_xlabel('Embedding dimension')\n",
    "ax3.bar(X + 0.00, especificity[0,:], color = 'b', width = 0.25)\n",
    "ax3.bar(X + 0.25, especificity[1,:], color = 'g', width = 0.25)\n",
    "ax3.bar(X + 0.50, especificity[2,:], color = 'r', width = 0.25)\n",
    "ax3.set_xticks([0.25, 1.25, 2.25])\n",
    "ax3.set_xticklabels(['32','64', '128'])\n",
    "ax3.set_title('Especificity')\n",
    "ax3.set_xlabel('Embedding dimension')\n",
    "ax3.legend(labels=['32 cells','64 cells','128 cells'],bbox_to_anchor=(1.1, 1.05))\n",
    "plt.show()\n",
    "print('Best accuracy= {}'.format(np.max(accuracy)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prueba entrenando GloVe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_sentences2 = []\n",
    "for i in range(len(all_words)):\n",
    "    temp = all_words[i]\n",
    "    sen = ''\n",
    "    for j in range(len(temp)):\n",
    "        sen = sen + ' ' +temp[j]\n",
    "    all_sentences2.append(sen)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from local.lib.glove import evaluate\n",
    "from local.lib.glove import glove\n",
    "\n",
    "glove.logger.setLevel(logging.ERROR)\n",
    "\n",
    "vocab = glove.build_vocab(all_sentences2)    \n",
    "#Coocurrence matrix\n",
    "cooccur = glove.build_cooccur(vocab, all_sentences2, window_size=10)\n",
    "id2word = evaluate.make_id2word(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7724 samples, validate on 859 samples\n",
      "Epoch 1/30\n",
      "7724/7724 [==============================] - 3s 404us/sample - loss: 0.5264 - accuracy: 0.7916 - val_loss: 0.4953 - val_accuracy: 0.7905\n",
      "Epoch 2/30\n",
      "7724/7724 [==============================] - 1s 176us/sample - loss: 0.4920 - accuracy: 0.7938 - val_loss: 0.4924 - val_accuracy: 0.7963\n",
      "Epoch 3/30\n",
      "7724/7724 [==============================] - 1s 174us/sample - loss: 0.4805 - accuracy: 0.7947 - val_loss: 0.4847 - val_accuracy: 0.7835\n",
      "Epoch 4/30\n",
      "7724/7724 [==============================] - 1s 172us/sample - loss: 0.4734 - accuracy: 0.7956 - val_loss: 0.4971 - val_accuracy: 0.7905\n",
      "Epoch 5/30\n",
      "7724/7724 [==============================] - 1s 174us/sample - loss: 0.4683 - accuracy: 0.7958 - val_loss: 0.4684 - val_accuracy: 0.7963\n",
      "Epoch 6/30\n",
      "7724/7724 [==============================] - 1s 173us/sample - loss: 0.4588 - accuracy: 0.7982 - val_loss: 0.4619 - val_accuracy: 0.8079\n",
      "Epoch 7/30\n",
      "7724/7724 [==============================] - 1s 173us/sample - loss: 0.4526 - accuracy: 0.8071 - val_loss: 0.4546 - val_accuracy: 0.8091\n",
      "Epoch 8/30\n",
      "7724/7724 [==============================] - 1s 173us/sample - loss: 0.4519 - accuracy: 0.8071 - val_loss: 0.4595 - val_accuracy: 0.8033\n",
      "Epoch 9/30\n",
      "7724/7724 [==============================] - 1s 173us/sample - loss: 0.4458 - accuracy: 0.8116 - val_loss: 0.4444 - val_accuracy: 0.8219\n",
      "Epoch 10/30\n",
      "7724/7724 [==============================] - 1s 173us/sample - loss: 0.4430 - accuracy: 0.8115 - val_loss: 0.4474 - val_accuracy: 0.8219\n",
      "Epoch 11/30\n",
      "7724/7724 [==============================] - 1s 174us/sample - loss: 0.4374 - accuracy: 0.8150 - val_loss: 0.4403 - val_accuracy: 0.8161\n",
      "Epoch 12/30\n",
      "7724/7724 [==============================] - 1s 173us/sample - loss: 0.4363 - accuracy: 0.8132 - val_loss: 0.4328 - val_accuracy: 0.8219\n",
      "Epoch 13/30\n",
      "7724/7724 [==============================] - 1s 173us/sample - loss: 0.4323 - accuracy: 0.8146 - val_loss: 0.4316 - val_accuracy: 0.8231\n",
      "Epoch 14/30\n",
      "7724/7724 [==============================] - 1s 174us/sample - loss: 0.4304 - accuracy: 0.8146 - val_loss: 0.4407 - val_accuracy: 0.8254\n",
      "Epoch 15/30\n",
      "7724/7724 [==============================] - 1s 173us/sample - loss: 0.4272 - accuracy: 0.8160 - val_loss: 0.4276 - val_accuracy: 0.8242\n",
      "Epoch 16/30\n",
      "7724/7724 [==============================] - 1s 173us/sample - loss: 0.4209 - accuracy: 0.8190 - val_loss: 0.4173 - val_accuracy: 0.8265\n",
      "Epoch 17/30\n",
      "7724/7724 [==============================] - 1s 167us/sample - loss: 0.4201 - accuracy: 0.8193 - val_loss: 0.4173 - val_accuracy: 0.8265\n",
      "Epoch 18/30\n",
      "7724/7724 [==============================] - 1s 167us/sample - loss: 0.4148 - accuracy: 0.8197 - val_loss: 0.4302 - val_accuracy: 0.8207\n",
      "Epoch 19/30\n",
      "7724/7724 [==============================] - 1s 167us/sample - loss: 0.4135 - accuracy: 0.8213 - val_loss: 0.4322 - val_accuracy: 0.8254\n",
      "Epoch 20/30\n",
      "7724/7724 [==============================] - 1s 167us/sample - loss: 0.4121 - accuracy: 0.8206 - val_loss: 0.4154 - val_accuracy: 0.8312\n",
      "Epoch 21/30\n",
      "7724/7724 [==============================] - 1s 166us/sample - loss: 0.4086 - accuracy: 0.8230 - val_loss: 0.4166 - val_accuracy: 0.8289\n",
      "Epoch 22/30\n",
      "7724/7724 [==============================] - 1s 165us/sample - loss: 0.4063 - accuracy: 0.8224 - val_loss: 0.4185 - val_accuracy: 0.8324\n",
      "Epoch 23/30\n",
      "7724/7724 [==============================] - 1s 167us/sample - loss: 0.4041 - accuracy: 0.8243 - val_loss: 0.4231 - val_accuracy: 0.8335\n",
      "Epoch 24/30\n",
      "7724/7724 [==============================] - 1s 166us/sample - loss: 0.4052 - accuracy: 0.8215 - val_loss: 0.4115 - val_accuracy: 0.8324\n",
      "Epoch 25/30\n",
      "7724/7724 [==============================] - 1s 168us/sample - loss: 0.4002 - accuracy: 0.8229 - val_loss: 0.4201 - val_accuracy: 0.8335\n",
      "Epoch 26/30\n",
      "7724/7724 [==============================] - 1s 168us/sample - loss: 0.3988 - accuracy: 0.8235 - val_loss: 0.4088 - val_accuracy: 0.8324\n",
      "Epoch 27/30\n",
      "7724/7724 [==============================] - 1s 168us/sample - loss: 0.3956 - accuracy: 0.8247 - val_loss: 0.4701 - val_accuracy: 0.8254\n",
      "Epoch 28/30\n",
      "7724/7724 [==============================] - 1s 168us/sample - loss: 0.3927 - accuracy: 0.8268 - val_loss: 0.4020 - val_accuracy: 0.8324\n",
      "Epoch 29/30\n",
      "7724/7724 [==============================] - 1s 167us/sample - loss: 0.3922 - accuracy: 0.8272 - val_loss: 0.4358 - val_accuracy: 0.8312\n",
      "Epoch 30/30\n",
      "7724/7724 [==============================] - 1s 167us/sample - loss: 0.3914 - accuracy: 0.8263 - val_loss: 0.4181 - val_accuracy: 0.8289\n",
      "Train on 7724 samples, validate on 859 samples\n",
      "Epoch 1/30\n",
      "7724/7724 [==============================] - 2s 303us/sample - loss: 0.5192 - accuracy: 0.7929 - val_loss: 0.5045 - val_accuracy: 0.7905\n",
      "Epoch 2/30\n",
      "7724/7724 [==============================] - 2s 201us/sample - loss: 0.4849 - accuracy: 0.7931 - val_loss: 0.5071 - val_accuracy: 0.7905\n",
      "Epoch 3/30\n",
      "7724/7724 [==============================] - 2s 202us/sample - loss: 0.4740 - accuracy: 0.7931 - val_loss: 0.5121 - val_accuracy: 0.7905\n",
      "Epoch 4/30\n",
      "7724/7724 [==============================] - 2s 203us/sample - loss: 0.4743 - accuracy: 0.7935 - val_loss: 0.5215 - val_accuracy: 0.7905\n",
      "Epoch 5/30\n",
      "7724/7724 [==============================] - 2s 202us/sample - loss: 0.4677 - accuracy: 0.7953 - val_loss: 0.4816 - val_accuracy: 0.7986\n",
      "Epoch 6/30\n",
      "7724/7724 [==============================] - 2s 201us/sample - loss: 0.4572 - accuracy: 0.7983 - val_loss: 0.4939 - val_accuracy: 0.7963\n",
      "Epoch 7/30\n",
      "7724/7724 [==============================] - 2s 199us/sample - loss: 0.4493 - accuracy: 0.8053 - val_loss: 0.4500 - val_accuracy: 0.8172\n",
      "Epoch 8/30\n",
      "7724/7724 [==============================] - 2s 200us/sample - loss: 0.4416 - accuracy: 0.8105 - val_loss: 0.4581 - val_accuracy: 0.8184\n",
      "Epoch 9/30\n",
      "7724/7724 [==============================] - 2s 201us/sample - loss: 0.4319 - accuracy: 0.8129 - val_loss: 0.4462 - val_accuracy: 0.8219\n",
      "Epoch 10/30\n",
      "7724/7724 [==============================] - 2s 201us/sample - loss: 0.4290 - accuracy: 0.8176 - val_loss: 0.4294 - val_accuracy: 0.8219\n",
      "Epoch 11/30\n",
      "7724/7724 [==============================] - 2s 201us/sample - loss: 0.4249 - accuracy: 0.8153 - val_loss: 0.4291 - val_accuracy: 0.8242\n",
      "Epoch 12/30\n",
      "7724/7724 [==============================] - 2s 201us/sample - loss: 0.4151 - accuracy: 0.8198 - val_loss: 0.4364 - val_accuracy: 0.8137\n",
      "Epoch 13/30\n",
      "7724/7724 [==============================] - 2s 201us/sample - loss: 0.4123 - accuracy: 0.8230 - val_loss: 0.4430 - val_accuracy: 0.8265\n",
      "Epoch 14/30\n",
      "7724/7724 [==============================] - 2s 200us/sample - loss: 0.4058 - accuracy: 0.8244 - val_loss: 0.4440 - val_accuracy: 0.8254\n",
      "Epoch 15/30\n",
      "7724/7724 [==============================] - 2s 199us/sample - loss: 0.4048 - accuracy: 0.8225 - val_loss: 0.4238 - val_accuracy: 0.8277\n",
      "Epoch 16/30\n",
      "7724/7724 [==============================] - 2s 201us/sample - loss: 0.3996 - accuracy: 0.8244 - val_loss: 0.4330 - val_accuracy: 0.8289\n",
      "Epoch 17/30\n",
      "7724/7724 [==============================] - 2s 200us/sample - loss: 0.3952 - accuracy: 0.8251 - val_loss: 0.4499 - val_accuracy: 0.8254\n",
      "Epoch 18/30\n",
      "7724/7724 [==============================] - 2s 201us/sample - loss: 0.3917 - accuracy: 0.8287 - val_loss: 0.4547 - val_accuracy: 0.8289\n",
      "Epoch 19/30\n",
      "7724/7724 [==============================] - 2s 200us/sample - loss: 0.3902 - accuracy: 0.8269 - val_loss: 0.4449 - val_accuracy: 0.8207\n",
      "Epoch 20/30\n",
      "7724/7724 [==============================] - 2s 200us/sample - loss: 0.3851 - accuracy: 0.8282 - val_loss: 0.4392 - val_accuracy: 0.8359\n",
      "Epoch 21/30\n",
      "7724/7724 [==============================] - 2s 198us/sample - loss: 0.3833 - accuracy: 0.8288 - val_loss: 0.4629 - val_accuracy: 0.8068\n",
      "Epoch 22/30\n",
      "7724/7724 [==============================] - 2s 199us/sample - loss: 0.3833 - accuracy: 0.8288 - val_loss: 0.4430 - val_accuracy: 0.8300\n",
      "Epoch 23/30\n",
      "7724/7724 [==============================] - 2s 200us/sample - loss: 0.3758 - accuracy: 0.8322 - val_loss: 0.4446 - val_accuracy: 0.8335\n",
      "Epoch 24/30\n",
      "7724/7724 [==============================] - 2s 199us/sample - loss: 0.3741 - accuracy: 0.8294 - val_loss: 0.4457 - val_accuracy: 0.8079\n",
      "Epoch 25/30\n",
      "7724/7724 [==============================] - 2s 199us/sample - loss: 0.3731 - accuracy: 0.8334 - val_loss: 0.5074 - val_accuracy: 0.8312\n",
      "Epoch 26/30\n",
      "7724/7724 [==============================] - 2s 198us/sample - loss: 0.3777 - accuracy: 0.8277 - val_loss: 0.4393 - val_accuracy: 0.8289\n",
      "Epoch 27/30\n",
      "7724/7724 [==============================] - 2s 199us/sample - loss: 0.3662 - accuracy: 0.8327 - val_loss: 0.4495 - val_accuracy: 0.8056\n",
      "Epoch 28/30\n",
      "7724/7724 [==============================] - 2s 198us/sample - loss: 0.3619 - accuracy: 0.8348 - val_loss: 0.4560 - val_accuracy: 0.8161\n",
      "Epoch 29/30\n",
      "7724/7724 [==============================] - 2s 198us/sample - loss: 0.3600 - accuracy: 0.8376 - val_loss: 0.4437 - val_accuracy: 0.8161\n",
      "Epoch 30/30\n",
      "7724/7724 [==============================] - 2s 197us/sample - loss: 0.3546 - accuracy: 0.8364 - val_loss: 0.4733 - val_accuracy: 0.8231\n",
      "Train on 7724 samples, validate on 859 samples\n",
      "Epoch 1/30\n",
      "7724/7724 [==============================] - 3s 375us/sample - loss: 0.5149 - accuracy: 0.7903 - val_loss: 0.4928 - val_accuracy: 0.7905\n",
      "Epoch 2/30\n",
      "7724/7724 [==============================] - 2s 273us/sample - loss: 0.4892 - accuracy: 0.7931 - val_loss: 0.5087 - val_accuracy: 0.7905\n",
      "Epoch 3/30\n",
      "7724/7724 [==============================] - 2s 274us/sample - loss: 0.4777 - accuracy: 0.7944 - val_loss: 0.4743 - val_accuracy: 0.7963\n",
      "Epoch 4/30\n",
      "7724/7724 [==============================] - 2s 272us/sample - loss: 0.4749 - accuracy: 0.7949 - val_loss: 0.4809 - val_accuracy: 0.7905\n",
      "Epoch 5/30\n",
      "7724/7724 [==============================] - 2s 272us/sample - loss: 0.4631 - accuracy: 0.7947 - val_loss: 0.4667 - val_accuracy: 0.7963\n",
      "Epoch 6/30\n",
      "7724/7724 [==============================] - 2s 272us/sample - loss: 0.4568 - accuracy: 0.7976 - val_loss: 0.4717 - val_accuracy: 0.7963\n",
      "Epoch 7/30\n",
      "7724/7724 [==============================] - 2s 273us/sample - loss: 0.4497 - accuracy: 0.7996 - val_loss: 0.4704 - val_accuracy: 0.8033\n",
      "Epoch 8/30\n",
      "7724/7724 [==============================] - 2s 273us/sample - loss: 0.4445 - accuracy: 0.8039 - val_loss: 0.4441 - val_accuracy: 0.8149\n",
      "Epoch 9/30\n",
      "7724/7724 [==============================] - 2s 271us/sample - loss: 0.4346 - accuracy: 0.8133 - val_loss: 0.4370 - val_accuracy: 0.8161\n",
      "Epoch 10/30\n",
      "7724/7724 [==============================] - 2s 271us/sample - loss: 0.4284 - accuracy: 0.8164 - val_loss: 0.4276 - val_accuracy: 0.8254\n",
      "Epoch 11/30\n",
      "7724/7724 [==============================] - 2s 272us/sample - loss: 0.4208 - accuracy: 0.8165 - val_loss: 0.4256 - val_accuracy: 0.8277\n",
      "Epoch 12/30\n",
      "7724/7724 [==============================] - 2s 272us/sample - loss: 0.4198 - accuracy: 0.8186 - val_loss: 0.4416 - val_accuracy: 0.8196\n",
      "Epoch 13/30\n",
      "7724/7724 [==============================] - 2s 272us/sample - loss: 0.4100 - accuracy: 0.8209 - val_loss: 0.4263 - val_accuracy: 0.8231\n",
      "Epoch 14/30\n",
      "7724/7724 [==============================] - 2s 272us/sample - loss: 0.4179 - accuracy: 0.8165 - val_loss: 0.4216 - val_accuracy: 0.8265\n",
      "Epoch 15/30\n",
      "7724/7724 [==============================] - 2s 272us/sample - loss: 0.4086 - accuracy: 0.8242 - val_loss: 0.4273 - val_accuracy: 0.8300\n",
      "Epoch 16/30\n",
      "7724/7724 [==============================] - 2s 273us/sample - loss: 0.4020 - accuracy: 0.8229 - val_loss: 0.4273 - val_accuracy: 0.8231\n",
      "Epoch 17/30\n",
      "7724/7724 [==============================] - 2s 274us/sample - loss: 0.3969 - accuracy: 0.8242 - val_loss: 0.4101 - val_accuracy: 0.8231\n",
      "Epoch 18/30\n",
      "7724/7724 [==============================] - 2s 272us/sample - loss: 0.3927 - accuracy: 0.8256 - val_loss: 0.4132 - val_accuracy: 0.8300\n",
      "Epoch 19/30\n",
      "7724/7724 [==============================] - 2s 272us/sample - loss: 0.4300 - accuracy: 0.8230 - val_loss: 0.4274 - val_accuracy: 0.8254\n",
      "Epoch 20/30\n",
      "7724/7724 [==============================] - 2s 272us/sample - loss: 0.3924 - accuracy: 0.8281 - val_loss: 0.4281 - val_accuracy: 0.8300\n",
      "Epoch 21/30\n",
      "7724/7724 [==============================] - 2s 272us/sample - loss: 0.3913 - accuracy: 0.8298 - val_loss: 0.4328 - val_accuracy: 0.8254\n",
      "Epoch 22/30\n",
      "7724/7724 [==============================] - 2s 272us/sample - loss: 0.3859 - accuracy: 0.8290 - val_loss: 0.4219 - val_accuracy: 0.8324\n",
      "Epoch 23/30\n",
      "7724/7724 [==============================] - 2s 272us/sample - loss: 0.3782 - accuracy: 0.8305 - val_loss: 0.4166 - val_accuracy: 0.8265\n",
      "Epoch 24/30\n",
      "7724/7724 [==============================] - 2s 272us/sample - loss: 0.3775 - accuracy: 0.8308 - val_loss: 0.4582 - val_accuracy: 0.8359\n",
      "Epoch 25/30\n",
      "7724/7724 [==============================] - 2s 272us/sample - loss: 0.3703 - accuracy: 0.8348 - val_loss: 0.4471 - val_accuracy: 0.8161\n",
      "Epoch 26/30\n",
      "7724/7724 [==============================] - 2s 272us/sample - loss: 0.3698 - accuracy: 0.8322 - val_loss: 0.4308 - val_accuracy: 0.8265\n",
      "Epoch 27/30\n",
      "7724/7724 [==============================] - 2s 273us/sample - loss: 0.3689 - accuracy: 0.8352 - val_loss: 0.4475 - val_accuracy: 0.8184\n",
      "Epoch 28/30\n",
      "7724/7724 [==============================] - 2s 272us/sample - loss: 0.3615 - accuracy: 0.8375 - val_loss: 0.4262 - val_accuracy: 0.8207\n",
      "Epoch 29/30\n",
      "7724/7724 [==============================] - 2s 272us/sample - loss: 0.3635 - accuracy: 0.8379 - val_loss: 0.4559 - val_accuracy: 0.8265\n",
      "Epoch 30/30\n",
      "7724/7724 [==============================] - 2s 272us/sample - loss: 0.3605 - accuracy: 0.8380 - val_loss: 0.4808 - val_accuracy: 0.8219\n",
      "Train on 7724 samples, validate on 859 samples\n",
      "Epoch 1/30\n",
      "7724/7724 [==============================] - 2s 279us/sample - loss: 0.5303 - accuracy: 0.7829 - val_loss: 0.5022 - val_accuracy: 0.7905\n",
      "Epoch 2/30\n",
      "7724/7724 [==============================] - 1s 172us/sample - loss: 0.4893 - accuracy: 0.7935 - val_loss: 0.4933 - val_accuracy: 0.7905\n",
      "Epoch 3/30\n",
      "7724/7724 [==============================] - 1s 174us/sample - loss: 0.4767 - accuracy: 0.7965 - val_loss: 0.6199 - val_accuracy: 0.7905\n",
      "Epoch 4/30\n",
      "7724/7724 [==============================] - 1s 173us/sample - loss: 0.4706 - accuracy: 0.7961 - val_loss: 0.7062 - val_accuracy: 0.7963\n",
      "Epoch 5/30\n",
      "7724/7724 [==============================] - 1s 174us/sample - loss: 0.4672 - accuracy: 0.7970 - val_loss: 0.5718 - val_accuracy: 0.7986\n",
      "Epoch 6/30\n",
      "7724/7724 [==============================] - 1s 174us/sample - loss: 0.4594 - accuracy: 0.7973 - val_loss: 0.5472 - val_accuracy: 0.8009\n",
      "Epoch 7/30\n",
      "7724/7724 [==============================] - 1s 173us/sample - loss: 0.4505 - accuracy: 0.7980 - val_loss: 0.5106 - val_accuracy: 0.8009\n",
      "Epoch 8/30\n",
      "7724/7724 [==============================] - 1s 173us/sample - loss: 0.4446 - accuracy: 0.8000 - val_loss: 0.4619 - val_accuracy: 0.8009\n",
      "Epoch 9/30\n",
      "7724/7724 [==============================] - 1s 173us/sample - loss: 0.4449 - accuracy: 0.8005 - val_loss: 0.4501 - val_accuracy: 0.8149\n",
      "Epoch 10/30\n",
      "7724/7724 [==============================] - 1s 173us/sample - loss: 0.4335 - accuracy: 0.8086 - val_loss: 0.4675 - val_accuracy: 0.8184\n",
      "Epoch 11/30\n",
      "7724/7724 [==============================] - 1s 172us/sample - loss: 0.4301 - accuracy: 0.8118 - val_loss: 0.4387 - val_accuracy: 0.8242\n",
      "Epoch 12/30\n",
      "7724/7724 [==============================] - 1s 173us/sample - loss: 0.4291 - accuracy: 0.8108 - val_loss: 0.4417 - val_accuracy: 0.8207\n",
      "Epoch 13/30\n",
      "7724/7724 [==============================] - 1s 169us/sample - loss: 0.4217 - accuracy: 0.8133 - val_loss: 0.4453 - val_accuracy: 0.8196\n",
      "Epoch 14/30\n",
      "7724/7724 [==============================] - 1s 169us/sample - loss: 0.4163 - accuracy: 0.8187 - val_loss: 0.4370 - val_accuracy: 0.8231\n",
      "Epoch 15/30\n",
      "7724/7724 [==============================] - 1s 168us/sample - loss: 0.4115 - accuracy: 0.8260 - val_loss: 0.4418 - val_accuracy: 0.8324\n",
      "Epoch 16/30\n",
      "7724/7724 [==============================] - 1s 171us/sample - loss: 0.4114 - accuracy: 0.8244 - val_loss: 0.4364 - val_accuracy: 0.8137\n",
      "Epoch 17/30\n",
      "7724/7724 [==============================] - 1s 170us/sample - loss: 0.4076 - accuracy: 0.8226 - val_loss: 0.4503 - val_accuracy: 0.8172\n",
      "Epoch 18/30\n",
      "7724/7724 [==============================] - 1s 169us/sample - loss: 0.4040 - accuracy: 0.8266 - val_loss: 0.4305 - val_accuracy: 0.8254\n",
      "Epoch 19/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7724/7724 [==============================] - 1s 168us/sample - loss: 0.4005 - accuracy: 0.8246 - val_loss: 0.4417 - val_accuracy: 0.8149\n",
      "Epoch 20/30\n",
      "7724/7724 [==============================] - 1s 168us/sample - loss: 0.3979 - accuracy: 0.8272 - val_loss: 0.4470 - val_accuracy: 0.8207\n",
      "Epoch 21/30\n",
      "7724/7724 [==============================] - 1s 168us/sample - loss: 0.3952 - accuracy: 0.8291 - val_loss: 0.4390 - val_accuracy: 0.8265\n",
      "Epoch 22/30\n",
      "7724/7724 [==============================] - 1s 168us/sample - loss: 0.3922 - accuracy: 0.8285 - val_loss: 0.4421 - val_accuracy: 0.8056\n",
      "Epoch 23/30\n",
      "7724/7724 [==============================] - 1s 168us/sample - loss: 0.3906 - accuracy: 0.8314 - val_loss: 0.4376 - val_accuracy: 0.8184\n",
      "Epoch 24/30\n",
      "7724/7724 [==============================] - 1s 168us/sample - loss: 0.3859 - accuracy: 0.8334 - val_loss: 0.4635 - val_accuracy: 0.8102\n",
      "Epoch 25/30\n",
      "7724/7724 [==============================] - 1s 168us/sample - loss: 0.3851 - accuracy: 0.8336 - val_loss: 0.4253 - val_accuracy: 0.8172\n",
      "Epoch 26/30\n",
      "7724/7724 [==============================] - 1s 168us/sample - loss: 0.3853 - accuracy: 0.8323 - val_loss: 0.4276 - val_accuracy: 0.8207\n",
      "Epoch 27/30\n",
      "7724/7724 [==============================] - 1s 168us/sample - loss: 0.3804 - accuracy: 0.8344 - val_loss: 0.4508 - val_accuracy: 0.8312\n",
      "Epoch 28/30\n",
      "7724/7724 [==============================] - 1s 168us/sample - loss: 0.3799 - accuracy: 0.8351 - val_loss: 0.4339 - val_accuracy: 0.8149\n",
      "Epoch 29/30\n",
      "7724/7724 [==============================] - 1s 167us/sample - loss: 0.3786 - accuracy: 0.8352 - val_loss: 0.4410 - val_accuracy: 0.8265\n",
      "Epoch 30/30\n",
      "7724/7724 [==============================] - 1s 168us/sample - loss: 0.3741 - accuracy: 0.8378 - val_loss: 0.4464 - val_accuracy: 0.8289\n",
      "Train on 7724 samples, validate on 859 samples\n",
      "Epoch 1/30\n",
      "7724/7724 [==============================] - 3s 336us/sample - loss: 0.5098 - accuracy: 0.7931 - val_loss: 0.4922 - val_accuracy: 0.7905\n",
      "Epoch 2/30\n",
      "7724/7724 [==============================] - 2s 203us/sample - loss: 0.4878 - accuracy: 0.7954 - val_loss: 0.4830 - val_accuracy: 0.7963\n",
      "Epoch 3/30\n",
      "7724/7724 [==============================] - 2s 207us/sample - loss: 0.4895 - accuracy: 0.7965 - val_loss: 0.4925 - val_accuracy: 0.7963\n",
      "Epoch 4/30\n",
      "7724/7724 [==============================] - 2s 204us/sample - loss: 0.4817 - accuracy: 0.7963 - val_loss: 0.4799 - val_accuracy: 0.7963\n",
      "Epoch 5/30\n",
      "7724/7724 [==============================] - 2s 204us/sample - loss: 0.4866 - accuracy: 0.7953 - val_loss: 0.4752 - val_accuracy: 0.7986\n",
      "Epoch 6/30\n",
      "7724/7724 [==============================] - 2s 206us/sample - loss: 0.4658 - accuracy: 0.7973 - val_loss: 0.4722 - val_accuracy: 0.7986\n",
      "Epoch 7/30\n",
      "7724/7724 [==============================] - 2s 203us/sample - loss: 0.4550 - accuracy: 0.8010 - val_loss: 0.4550 - val_accuracy: 0.8068\n",
      "Epoch 8/30\n",
      "7724/7724 [==============================] - 2s 203us/sample - loss: 0.4485 - accuracy: 0.8032 - val_loss: 0.4550 - val_accuracy: 0.8149\n",
      "Epoch 9/30\n",
      "7724/7724 [==============================] - 2s 205us/sample - loss: 0.4404 - accuracy: 0.8074 - val_loss: 0.4489 - val_accuracy: 0.8161\n",
      "Epoch 10/30\n",
      "7724/7724 [==============================] - 2s 205us/sample - loss: 0.4284 - accuracy: 0.8112 - val_loss: 0.4491 - val_accuracy: 0.8161\n",
      "Epoch 11/30\n",
      "7724/7724 [==============================] - 2s 204us/sample - loss: 0.4230 - accuracy: 0.8114 - val_loss: 0.4359 - val_accuracy: 0.8184\n",
      "Epoch 12/30\n",
      "7724/7724 [==============================] - 2s 204us/sample - loss: 0.4229 - accuracy: 0.8162 - val_loss: 0.4365 - val_accuracy: 0.8137\n",
      "Epoch 13/30\n",
      "7724/7724 [==============================] - 2s 204us/sample - loss: 0.4151 - accuracy: 0.8160 - val_loss: 0.4300 - val_accuracy: 0.8265\n",
      "Epoch 14/30\n",
      "7724/7724 [==============================] - 2s 204us/sample - loss: 0.4084 - accuracy: 0.8208 - val_loss: 0.4350 - val_accuracy: 0.8161\n",
      "Epoch 15/30\n",
      "7724/7724 [==============================] - 2s 203us/sample - loss: 0.4076 - accuracy: 0.8199 - val_loss: 0.4392 - val_accuracy: 0.8207\n",
      "Epoch 16/30\n",
      "7724/7724 [==============================] - 2s 205us/sample - loss: 0.4023 - accuracy: 0.8200 - val_loss: 0.4477 - val_accuracy: 0.8091\n",
      "Epoch 17/30\n",
      "7724/7724 [==============================] - 2s 205us/sample - loss: 0.4008 - accuracy: 0.8216 - val_loss: 0.4247 - val_accuracy: 0.8219\n",
      "Epoch 18/30\n",
      "7724/7724 [==============================] - 2s 204us/sample - loss: 0.3994 - accuracy: 0.8230 - val_loss: 0.4258 - val_accuracy: 0.8277\n",
      "Epoch 19/30\n",
      "7724/7724 [==============================] - 2s 204us/sample - loss: 0.3959 - accuracy: 0.8242 - val_loss: 0.4223 - val_accuracy: 0.8242\n",
      "Epoch 20/30\n",
      "7724/7724 [==============================] - 2s 205us/sample - loss: 0.3914 - accuracy: 0.8234 - val_loss: 0.4334 - val_accuracy: 0.8219\n",
      "Epoch 21/30\n",
      "7724/7724 [==============================] - 2s 205us/sample - loss: 0.3903 - accuracy: 0.8273 - val_loss: 0.4295 - val_accuracy: 0.8289\n",
      "Epoch 22/30\n",
      "7724/7724 [==============================] - 2s 206us/sample - loss: 0.3874 - accuracy: 0.8277 - val_loss: 0.4503 - val_accuracy: 0.8184\n",
      "Epoch 23/30\n",
      "7724/7724 [==============================] - 2s 205us/sample - loss: 0.4070 - accuracy: 0.8195 - val_loss: 0.4360 - val_accuracy: 0.8254\n",
      "Epoch 24/30\n",
      "7724/7724 [==============================] - 2s 205us/sample - loss: 0.3995 - accuracy: 0.8225 - val_loss: 0.4254 - val_accuracy: 0.8324\n",
      "Epoch 25/30\n",
      "7724/7724 [==============================] - 2s 204us/sample - loss: 0.3869 - accuracy: 0.8270 - val_loss: 0.4352 - val_accuracy: 0.8219\n",
      "Epoch 26/30\n",
      "7724/7724 [==============================] - 2s 205us/sample - loss: 0.3881 - accuracy: 0.8265 - val_loss: 0.4437 - val_accuracy: 0.8265\n",
      "Epoch 27/30\n",
      "7724/7724 [==============================] - 2s 204us/sample - loss: 0.3796 - accuracy: 0.8299 - val_loss: 0.4478 - val_accuracy: 0.8324\n",
      "Epoch 28/30\n",
      "7724/7724 [==============================] - 2s 204us/sample - loss: 0.3750 - accuracy: 0.8301 - val_loss: 0.4339 - val_accuracy: 0.8289\n",
      "Epoch 29/30\n",
      "7724/7724 [==============================] - 2s 204us/sample - loss: 0.3723 - accuracy: 0.8330 - val_loss: 0.4552 - val_accuracy: 0.8126\n",
      "Epoch 30/30\n",
      "7724/7724 [==============================] - 2s 205us/sample - loss: 0.3714 - accuracy: 0.8321 - val_loss: 0.4331 - val_accuracy: 0.8265\n",
      "Train on 7724 samples, validate on 859 samples\n",
      "Epoch 1/30\n",
      "7724/7724 [==============================] - 3s 381us/sample - loss: 0.5084 - accuracy: 0.7925 - val_loss: 0.4918 - val_accuracy: 0.7905\n",
      "Epoch 2/30\n",
      "7724/7724 [==============================] - 2s 277us/sample - loss: 0.4813 - accuracy: 0.7931 - val_loss: 0.7217 - val_accuracy: 0.7905\n",
      "Epoch 3/30\n",
      "7724/7724 [==============================] - 2s 277us/sample - loss: 0.4973 - accuracy: 0.7931 - val_loss: 0.4896 - val_accuracy: 0.7905\n",
      "Epoch 4/30\n",
      "7724/7724 [==============================] - 2s 278us/sample - loss: 0.4708 - accuracy: 0.7931 - val_loss: 0.4783 - val_accuracy: 0.7905\n",
      "Epoch 5/30\n",
      "7724/7724 [==============================] - 2s 277us/sample - loss: 0.4628 - accuracy: 0.7931 - val_loss: 0.4740 - val_accuracy: 0.7905\n",
      "Epoch 6/30\n",
      "7724/7724 [==============================] - 2s 277us/sample - loss: 0.4555 - accuracy: 0.7991 - val_loss: 0.4575 - val_accuracy: 0.7974\n",
      "Epoch 7/30\n",
      "7724/7724 [==============================] - 2s 279us/sample - loss: 0.4524 - accuracy: 0.8039 - val_loss: 0.4746 - val_accuracy: 0.8091\n",
      "Epoch 8/30\n",
      "7724/7724 [==============================] - 2s 276us/sample - loss: 0.4426 - accuracy: 0.8090 - val_loss: 0.5168 - val_accuracy: 0.7974\n",
      "Epoch 9/30\n",
      "7724/7724 [==============================] - 2s 277us/sample - loss: 0.4344 - accuracy: 0.8115 - val_loss: 0.4419 - val_accuracy: 0.8137\n",
      "Epoch 10/30\n",
      "7724/7724 [==============================] - 2s 276us/sample - loss: 0.4265 - accuracy: 0.8156 - val_loss: 0.4413 - val_accuracy: 0.8184\n",
      "Epoch 11/30\n",
      "7724/7724 [==============================] - 2s 275us/sample - loss: 0.4194 - accuracy: 0.8189 - val_loss: 0.4369 - val_accuracy: 0.8126\n",
      "Epoch 12/30\n",
      "7724/7724 [==============================] - 2s 277us/sample - loss: 0.4131 - accuracy: 0.8216 - val_loss: 0.4364 - val_accuracy: 0.8289\n",
      "Epoch 13/30\n",
      "7724/7724 [==============================] - 2s 277us/sample - loss: 0.4070 - accuracy: 0.8215 - val_loss: 0.4411 - val_accuracy: 0.8231\n",
      "Epoch 14/30\n",
      "7724/7724 [==============================] - 2s 275us/sample - loss: 0.4066 - accuracy: 0.8226 - val_loss: 0.4396 - val_accuracy: 0.8242\n",
      "Epoch 15/30\n",
      "7724/7724 [==============================] - 2s 275us/sample - loss: 0.3990 - accuracy: 0.8265 - val_loss: 0.4371 - val_accuracy: 0.8300\n",
      "Epoch 16/30\n",
      "7724/7724 [==============================] - 2s 275us/sample - loss: 0.3945 - accuracy: 0.8239 - val_loss: 0.4677 - val_accuracy: 0.8277\n",
      "Epoch 17/30\n",
      "7724/7724 [==============================] - 2s 275us/sample - loss: 0.3928 - accuracy: 0.8247 - val_loss: 0.4844 - val_accuracy: 0.8254\n",
      "Epoch 18/30\n",
      "7724/7724 [==============================] - 2s 275us/sample - loss: 0.3824 - accuracy: 0.8283 - val_loss: 0.4426 - val_accuracy: 0.8277\n",
      "Epoch 19/30\n",
      "7724/7724 [==============================] - 2s 276us/sample - loss: 0.3808 - accuracy: 0.8310 - val_loss: 0.4382 - val_accuracy: 0.8265\n",
      "Epoch 20/30\n",
      "7724/7724 [==============================] - 2s 275us/sample - loss: 0.3743 - accuracy: 0.8314 - val_loss: 0.4928 - val_accuracy: 0.8254\n",
      "Epoch 21/30\n",
      "7724/7724 [==============================] - 2s 275us/sample - loss: 0.3733 - accuracy: 0.8330 - val_loss: 0.4230 - val_accuracy: 0.8219\n",
      "Epoch 22/30\n",
      "7724/7724 [==============================] - 2s 275us/sample - loss: 0.3693 - accuracy: 0.8307 - val_loss: 0.4700 - val_accuracy: 0.8300\n",
      "Epoch 23/30\n",
      "7724/7724 [==============================] - 2s 275us/sample - loss: 0.3636 - accuracy: 0.8351 - val_loss: 0.4553 - val_accuracy: 0.8184\n",
      "Epoch 24/30\n",
      "7724/7724 [==============================] - 2s 276us/sample - loss: 0.3605 - accuracy: 0.8364 - val_loss: 0.4520 - val_accuracy: 0.8254\n",
      "Epoch 25/30\n",
      "7724/7724 [==============================] - 2s 275us/sample - loss: 0.3598 - accuracy: 0.8383 - val_loss: 0.4397 - val_accuracy: 0.8149\n",
      "Epoch 26/30\n",
      "7724/7724 [==============================] - 2s 276us/sample - loss: 0.3483 - accuracy: 0.8391 - val_loss: 0.4792 - val_accuracy: 0.8242\n",
      "Epoch 27/30\n",
      "7724/7724 [==============================] - 2s 275us/sample - loss: 0.3418 - accuracy: 0.8419 - val_loss: 0.4585 - val_accuracy: 0.8242\n",
      "Epoch 28/30\n",
      "7724/7724 [==============================] - 2s 275us/sample - loss: 0.3397 - accuracy: 0.8422 - val_loss: 0.4581 - val_accuracy: 0.8149\n",
      "Epoch 29/30\n",
      "7724/7724 [==============================] - 2s 277us/sample - loss: 0.3345 - accuracy: 0.8437 - val_loss: 0.4708 - val_accuracy: 0.8161\n",
      "Epoch 30/30\n",
      "7724/7724 [==============================] - 2s 276us/sample - loss: 0.3285 - accuracy: 0.8493 - val_loss: 0.4696 - val_accuracy: 0.8196\n",
      "Train on 7724 samples, validate on 859 samples\n",
      "Epoch 1/30\n",
      "7724/7724 [==============================] - 2s 283us/sample - loss: 0.5113 - accuracy: 0.7929 - val_loss: 0.4966 - val_accuracy: 0.7905\n",
      "Epoch 2/30\n",
      "7724/7724 [==============================] - 1s 175us/sample - loss: 0.4778 - accuracy: 0.7961 - val_loss: 0.4906 - val_accuracy: 0.7974\n",
      "Epoch 3/30\n",
      "7724/7724 [==============================] - 1s 174us/sample - loss: 0.4675 - accuracy: 0.7965 - val_loss: 0.4992 - val_accuracy: 0.7974\n",
      "Epoch 4/30\n",
      "7724/7724 [==============================] - 1s 174us/sample - loss: 0.4636 - accuracy: 0.7973 - val_loss: 0.4933 - val_accuracy: 0.8079\n",
      "Epoch 5/30\n",
      "7724/7724 [==============================] - 1s 175us/sample - loss: 0.4561 - accuracy: 0.8022 - val_loss: 0.4657 - val_accuracy: 0.8126\n",
      "Epoch 6/30\n",
      "7724/7724 [==============================] - 1s 175us/sample - loss: 0.4504 - accuracy: 0.8050 - val_loss: 0.4563 - val_accuracy: 0.8114\n",
      "Epoch 7/30\n",
      "7724/7724 [==============================] - 1s 175us/sample - loss: 0.4408 - accuracy: 0.8099 - val_loss: 0.4471 - val_accuracy: 0.8172\n",
      "Epoch 8/30\n",
      "7724/7724 [==============================] - 1s 175us/sample - loss: 0.4331 - accuracy: 0.8163 - val_loss: 0.4400 - val_accuracy: 0.8231\n",
      "Epoch 9/30\n",
      "7724/7724 [==============================] - 1s 174us/sample - loss: 0.4298 - accuracy: 0.8150 - val_loss: 0.4276 - val_accuracy: 0.8242\n",
      "Epoch 10/30\n",
      "7724/7724 [==============================] - 1s 174us/sample - loss: 0.4226 - accuracy: 0.8208 - val_loss: 0.4247 - val_accuracy: 0.8242\n",
      "Epoch 11/30\n",
      "7724/7724 [==============================] - 1s 174us/sample - loss: 0.4246 - accuracy: 0.8172 - val_loss: 0.4334 - val_accuracy: 0.8265\n",
      "Epoch 12/30\n",
      "7724/7724 [==============================] - 1s 174us/sample - loss: 0.4201 - accuracy: 0.8203 - val_loss: 0.4243 - val_accuracy: 0.8289\n",
      "Epoch 13/30\n",
      "7724/7724 [==============================] - 1s 175us/sample - loss: 0.4167 - accuracy: 0.8195 - val_loss: 0.4262 - val_accuracy: 0.8231\n",
      "Epoch 14/30\n",
      "7724/7724 [==============================] - 1s 172us/sample - loss: 0.4144 - accuracy: 0.8213 - val_loss: 0.4226 - val_accuracy: 0.8242\n",
      "Epoch 15/30\n",
      "7724/7724 [==============================] - 1s 175us/sample - loss: 0.4123 - accuracy: 0.8221 - val_loss: 0.4360 - val_accuracy: 0.8149\n",
      "Epoch 16/30\n",
      "7724/7724 [==============================] - 1s 174us/sample - loss: 0.4085 - accuracy: 0.8225 - val_loss: 0.4297 - val_accuracy: 0.8207\n",
      "Epoch 17/30\n",
      "7724/7724 [==============================] - 1s 174us/sample - loss: 0.4085 - accuracy: 0.8243 - val_loss: 0.4278 - val_accuracy: 0.8254\n",
      "Epoch 18/30\n",
      "7724/7724 [==============================] - 1s 174us/sample - loss: 0.4040 - accuracy: 0.8220 - val_loss: 0.4273 - val_accuracy: 0.8324\n",
      "Epoch 19/30\n",
      "7724/7724 [==============================] - 1s 174us/sample - loss: 0.4029 - accuracy: 0.8246 - val_loss: 0.4238 - val_accuracy: 0.8312\n",
      "Epoch 20/30\n",
      "7724/7724 [==============================] - 1s 175us/sample - loss: 0.4000 - accuracy: 0.8273 - val_loss: 0.4211 - val_accuracy: 0.8207\n",
      "Epoch 21/30\n",
      "7724/7724 [==============================] - 1s 174us/sample - loss: 0.3984 - accuracy: 0.8243 - val_loss: 0.4188 - val_accuracy: 0.8219\n",
      "Epoch 22/30\n",
      "7724/7724 [==============================] - 1s 173us/sample - loss: 0.3941 - accuracy: 0.8259 - val_loss: 0.4236 - val_accuracy: 0.8254\n",
      "Epoch 23/30\n",
      "7724/7724 [==============================] - 1s 174us/sample - loss: 0.3902 - accuracy: 0.8243 - val_loss: 0.4294 - val_accuracy: 0.8254\n",
      "Epoch 24/30\n",
      "7724/7724 [==============================] - 1s 174us/sample - loss: 0.3896 - accuracy: 0.8261 - val_loss: 0.4344 - val_accuracy: 0.8324\n",
      "Epoch 25/30\n",
      "7724/7724 [==============================] - 1s 175us/sample - loss: 0.3899 - accuracy: 0.8294 - val_loss: 0.4277 - val_accuracy: 0.8161\n",
      "Epoch 26/30\n",
      "7724/7724 [==============================] - 1s 175us/sample - loss: 0.3850 - accuracy: 0.8304 - val_loss: 0.4457 - val_accuracy: 0.8231\n",
      "Epoch 27/30\n",
      "7724/7724 [==============================] - 1s 174us/sample - loss: 0.3870 - accuracy: 0.8277 - val_loss: 0.4532 - val_accuracy: 0.8207\n",
      "Epoch 28/30\n",
      "7724/7724 [==============================] - 1s 174us/sample - loss: 0.3824 - accuracy: 0.8299 - val_loss: 0.4337 - val_accuracy: 0.8277\n",
      "Epoch 29/30\n",
      "7724/7724 [==============================] - 1s 174us/sample - loss: 0.3793 - accuracy: 0.8307 - val_loss: 0.4213 - val_accuracy: 0.8254\n",
      "Epoch 30/30\n",
      "7724/7724 [==============================] - 1s 176us/sample - loss: 0.3783 - accuracy: 0.8321 - val_loss: 0.4281 - val_accuracy: 0.8219\n",
      "Train on 7724 samples, validate on 859 samples\n",
      "Epoch 1/30\n",
      "7724/7724 [==============================] - 2s 310us/sample - loss: 0.5081 - accuracy: 0.7947 - val_loss: 0.4904 - val_accuracy: 0.7963\n",
      "Epoch 2/30\n",
      "7724/7724 [==============================] - 2s 208us/sample - loss: 0.4728 - accuracy: 0.7960 - val_loss: 0.7797 - val_accuracy: 0.7963\n",
      "Epoch 3/30\n",
      "7724/7724 [==============================] - 2s 207us/sample - loss: 0.4833 - accuracy: 0.7961 - val_loss: 0.4794 - val_accuracy: 0.7974\n",
      "Epoch 4/30\n",
      "7724/7724 [==============================] - 2s 205us/sample - loss: 0.4612 - accuracy: 0.8006 - val_loss: 0.4998 - val_accuracy: 0.7963\n",
      "Epoch 5/30\n",
      "7724/7724 [==============================] - 2s 207us/sample - loss: 0.4517 - accuracy: 0.8050 - val_loss: 0.4695 - val_accuracy: 0.8091\n",
      "Epoch 6/30\n",
      "7724/7724 [==============================] - 2s 208us/sample - loss: 0.4451 - accuracy: 0.8077 - val_loss: 0.4603 - val_accuracy: 0.8184\n",
      "Epoch 7/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7724/7724 [==============================] - 2s 207us/sample - loss: 0.4421 - accuracy: 0.8107 - val_loss: 0.4609 - val_accuracy: 0.8056\n",
      "Epoch 8/30\n",
      "7724/7724 [==============================] - 2s 206us/sample - loss: 0.4308 - accuracy: 0.8128 - val_loss: 0.4363 - val_accuracy: 0.8254\n",
      "Epoch 9/30\n",
      "7724/7724 [==============================] - 2s 207us/sample - loss: 0.4241 - accuracy: 0.8140 - val_loss: 0.4334 - val_accuracy: 0.8231\n",
      "Epoch 10/30\n",
      "7724/7724 [==============================] - 2s 206us/sample - loss: 0.4194 - accuracy: 0.8185 - val_loss: 0.4230 - val_accuracy: 0.8312\n",
      "Epoch 11/30\n",
      "7724/7724 [==============================] - 2s 207us/sample - loss: 0.4139 - accuracy: 0.8228 - val_loss: 0.4313 - val_accuracy: 0.8254\n",
      "Epoch 12/30\n",
      "7724/7724 [==============================] - 2s 206us/sample - loss: 0.4111 - accuracy: 0.8226 - val_loss: 0.4256 - val_accuracy: 0.8254\n",
      "Epoch 13/30\n",
      "7724/7724 [==============================] - 2s 207us/sample - loss: 0.4078 - accuracy: 0.8202 - val_loss: 0.4275 - val_accuracy: 0.8219\n",
      "Epoch 14/30\n",
      "7724/7724 [==============================] - 2s 205us/sample - loss: 0.4030 - accuracy: 0.8234 - val_loss: 0.4278 - val_accuracy: 0.8300\n",
      "Epoch 15/30\n",
      "7724/7724 [==============================] - 2s 207us/sample - loss: 0.4059 - accuracy: 0.8219 - val_loss: 0.4304 - val_accuracy: 0.8219\n",
      "Epoch 16/30\n",
      "7724/7724 [==============================] - 2s 205us/sample - loss: 0.4030 - accuracy: 0.8243 - val_loss: 0.4491 - val_accuracy: 0.8196\n",
      "Epoch 17/30\n",
      "7724/7724 [==============================] - 2s 206us/sample - loss: 0.3964 - accuracy: 0.8257 - val_loss: 0.4383 - val_accuracy: 0.8335\n",
      "Epoch 18/30\n",
      "7724/7724 [==============================] - 2s 208us/sample - loss: 0.3962 - accuracy: 0.8255 - val_loss: 0.4251 - val_accuracy: 0.8254\n",
      "Epoch 19/30\n",
      "7724/7724 [==============================] - 2s 207us/sample - loss: 0.3877 - accuracy: 0.8276 - val_loss: 0.4327 - val_accuracy: 0.8265\n",
      "Epoch 20/30\n",
      "7724/7724 [==============================] - 2s 207us/sample - loss: 0.3862 - accuracy: 0.8272 - val_loss: 0.4434 - val_accuracy: 0.8207\n",
      "Epoch 21/30\n",
      "7724/7724 [==============================] - 2s 207us/sample - loss: 0.3808 - accuracy: 0.8298 - val_loss: 0.4516 - val_accuracy: 0.8277\n",
      "Epoch 22/30\n",
      "7724/7724 [==============================] - 2s 207us/sample - loss: 0.3767 - accuracy: 0.8334 - val_loss: 0.4412 - val_accuracy: 0.8231\n",
      "Epoch 23/30\n",
      "7724/7724 [==============================] - 2s 206us/sample - loss: 0.3761 - accuracy: 0.8327 - val_loss: 0.4386 - val_accuracy: 0.8324\n",
      "Epoch 24/30\n",
      "7724/7724 [==============================] - 2s 206us/sample - loss: 0.3736 - accuracy: 0.8326 - val_loss: 0.4458 - val_accuracy: 0.8335\n",
      "Epoch 25/30\n",
      "7724/7724 [==============================] - 2s 208us/sample - loss: 0.3695 - accuracy: 0.8354 - val_loss: 0.4609 - val_accuracy: 0.8300\n",
      "Epoch 26/30\n",
      "7724/7724 [==============================] - 2s 206us/sample - loss: 0.3630 - accuracy: 0.8365 - val_loss: 0.5187 - val_accuracy: 0.8300\n",
      "Epoch 27/30\n",
      "7724/7724 [==============================] - 2s 207us/sample - loss: 0.3583 - accuracy: 0.8364 - val_loss: 0.5793 - val_accuracy: 0.8300\n",
      "Epoch 28/30\n",
      "7724/7724 [==============================] - 2s 207us/sample - loss: 0.3554 - accuracy: 0.8396 - val_loss: 0.5591 - val_accuracy: 0.8126\n",
      "Epoch 29/30\n",
      "7724/7724 [==============================] - 2s 206us/sample - loss: 0.3541 - accuracy: 0.8378 - val_loss: 0.5260 - val_accuracy: 0.8359\n",
      "Epoch 30/30\n",
      "7724/7724 [==============================] - 2s 207us/sample - loss: 0.3516 - accuracy: 0.8426 - val_loss: 0.5727 - val_accuracy: 0.8207\n",
      "Train on 7724 samples, validate on 859 samples\n",
      "Epoch 1/30\n",
      "7724/7724 [==============================] - 3s 398us/sample - loss: 0.5071 - accuracy: 0.7931 - val_loss: 0.4858 - val_accuracy: 0.7905\n",
      "Epoch 2/30\n",
      "7724/7724 [==============================] - 2s 291us/sample - loss: 0.4917 - accuracy: 0.7931 - val_loss: 0.4847 - val_accuracy: 0.7905\n",
      "Epoch 3/30\n",
      "7724/7724 [==============================] - 2s 291us/sample - loss: 0.4957 - accuracy: 0.7931 - val_loss: 0.5019 - val_accuracy: 0.7905\n",
      "Epoch 4/30\n",
      "7724/7724 [==============================] - 2s 290us/sample - loss: 0.4835 - accuracy: 0.7953 - val_loss: 0.4851 - val_accuracy: 0.7963\n",
      "Epoch 5/30\n",
      "7724/7724 [==============================] - 2s 293us/sample - loss: 0.4724 - accuracy: 0.7957 - val_loss: 0.4761 - val_accuracy: 0.7963\n",
      "Epoch 6/30\n",
      "7724/7724 [==============================] - 2s 291us/sample - loss: 0.4624 - accuracy: 0.7958 - val_loss: 0.4920 - val_accuracy: 0.7963\n",
      "Epoch 7/30\n",
      "7724/7724 [==============================] - 2s 290us/sample - loss: 0.4531 - accuracy: 0.8006 - val_loss: 0.4826 - val_accuracy: 0.7963\n",
      "Epoch 8/30\n",
      "7724/7724 [==============================] - 2s 289us/sample - loss: 0.4473 - accuracy: 0.8074 - val_loss: 0.4725 - val_accuracy: 0.8184\n",
      "Epoch 9/30\n",
      "7724/7724 [==============================] - 2s 291us/sample - loss: 0.4405 - accuracy: 0.8123 - val_loss: 0.4827 - val_accuracy: 0.7870\n",
      "Epoch 10/30\n",
      "7724/7724 [==============================] - 2s 290us/sample - loss: 0.4355 - accuracy: 0.8149 - val_loss: 0.4439 - val_accuracy: 0.8289\n",
      "Epoch 11/30\n",
      "7724/7724 [==============================] - 2s 290us/sample - loss: 0.4261 - accuracy: 0.8175 - val_loss: 0.4381 - val_accuracy: 0.8300\n",
      "Epoch 12/30\n",
      "7724/7724 [==============================] - 2s 290us/sample - loss: 0.4204 - accuracy: 0.8209 - val_loss: 0.4294 - val_accuracy: 0.8289\n",
      "Epoch 13/30\n",
      "7724/7724 [==============================] - 2s 290us/sample - loss: 0.4207 - accuracy: 0.8189 - val_loss: 0.4392 - val_accuracy: 0.8300\n",
      "Epoch 14/30\n",
      "7724/7724 [==============================] - 2s 291us/sample - loss: 0.4103 - accuracy: 0.8230 - val_loss: 0.4330 - val_accuracy: 0.8277\n",
      "Epoch 15/30\n",
      "7724/7724 [==============================] - 2s 290us/sample - loss: 0.4071 - accuracy: 0.8226 - val_loss: 0.4502 - val_accuracy: 0.8312\n",
      "Epoch 16/30\n",
      "7724/7724 [==============================] - 2s 290us/sample - loss: 0.4035 - accuracy: 0.8247 - val_loss: 0.4269 - val_accuracy: 0.8289\n",
      "Epoch 17/30\n",
      "7724/7724 [==============================] - 2s 290us/sample - loss: 0.4020 - accuracy: 0.8222 - val_loss: 0.4523 - val_accuracy: 0.8114\n",
      "Epoch 18/30\n",
      "7724/7724 [==============================] - 2s 290us/sample - loss: 0.3924 - accuracy: 0.8274 - val_loss: 0.4497 - val_accuracy: 0.8231\n",
      "Epoch 19/30\n",
      "7724/7724 [==============================] - 2s 291us/sample - loss: 0.3894 - accuracy: 0.8246 - val_loss: 0.4512 - val_accuracy: 0.8231\n",
      "Epoch 20/30\n",
      "7724/7724 [==============================] - 2s 289us/sample - loss: 0.3874 - accuracy: 0.8256 - val_loss: 0.4372 - val_accuracy: 0.8254\n",
      "Epoch 21/30\n",
      "7724/7724 [==============================] - 2s 289us/sample - loss: 0.3808 - accuracy: 0.8282 - val_loss: 0.4422 - val_accuracy: 0.8300\n",
      "Epoch 22/30\n",
      "7724/7724 [==============================] - 2s 289us/sample - loss: 0.3759 - accuracy: 0.8292 - val_loss: 0.5035 - val_accuracy: 0.8347\n",
      "Epoch 23/30\n",
      "7724/7724 [==============================] - 2s 289us/sample - loss: 0.3717 - accuracy: 0.8322 - val_loss: 0.4557 - val_accuracy: 0.8277\n",
      "Epoch 24/30\n",
      "7724/7724 [==============================] - 2s 288us/sample - loss: 0.3671 - accuracy: 0.8318 - val_loss: 0.4423 - val_accuracy: 0.8289\n",
      "Epoch 25/30\n",
      "7724/7724 [==============================] - 2s 290us/sample - loss: 0.3592 - accuracy: 0.8384 - val_loss: 0.4719 - val_accuracy: 0.8324\n",
      "Epoch 26/30\n",
      "7724/7724 [==============================] - 2s 288us/sample - loss: 0.3546 - accuracy: 0.8366 - val_loss: 0.5057 - val_accuracy: 0.8324\n",
      "Epoch 27/30\n",
      "7724/7724 [==============================] - 2s 290us/sample - loss: 0.3494 - accuracy: 0.8410 - val_loss: 0.4644 - val_accuracy: 0.8312\n",
      "Epoch 28/30\n",
      "7724/7724 [==============================] - 2s 290us/sample - loss: 0.3421 - accuracy: 0.8462 - val_loss: 0.5061 - val_accuracy: 0.8312\n",
      "Epoch 29/30\n",
      "7724/7724 [==============================] - 2s 289us/sample - loss: 0.3378 - accuracy: 0.8444 - val_loss: 0.4919 - val_accuracy: 0.8184\n",
      "Epoch 30/30\n",
      "7724/7724 [==============================] - 2s 289us/sample - loss: 0.3328 - accuracy: 0.8476 - val_loss: 0.5713 - val_accuracy: 0.8056\n"
     ]
    }
   ],
   "source": [
    "sensitivity = np.zeros((3,3))\n",
    "especificity = np.zeros((3,3))\n",
    "accuracy = np.zeros((3,3))\n",
    "for i, embed_dim in enumerate([32,64,128]):\n",
    "    for j,cells in enumerate([32,64,128]):\n",
    "        #---------------------------------------------------------------------------------\n",
    "        W = glove.train_glove(vocab, cooccur, vector_size=embed_dim, iterations=15)\n",
    "        # Merge and normalize word vectors\n",
    "        W = evaluate.merge_main_context(W)\n",
    "        indice = np.zeros(2000, dtype=int)\n",
    "        for k in range(2000):\n",
    "            indice[k] = vocab.get(words[k])[0]\n",
    "        wordsmatrix = W[indice,:]\n",
    "        #-------------------------------------------------------------------------------------\n",
    "        model = Model_Sentimen(embed_dim,cells,wordsmatrix)\n",
    "        opt = optimizers.Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999, amsgrad=False)\n",
    "        model.compile(optimizer=opt, loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "        model.fit(X_tr, y_tr, validation_split=0.1,batch_size=32, epochs=10, verbose=1)\n",
    "        y_pred = np.round(model.predict(X_te))\n",
    "        sensitivity[i,j] = recall_score(y_te,y_pred)\n",
    "        accuracy[i,j] = accuracy_score(y_te,y_pred)\n",
    "        especificity[i,j] = especi_score(y_te,y_pred.flatten())     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x216 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(10,3))\n",
    "X = np.arange(3)\n",
    "ax1.bar(X + 0.00, accuracy[0,:], color = 'b', width = 0.25)\n",
    "ax1.bar(X + 0.25, accuracy[1,:], color = 'g', width = 0.25)\n",
    "ax1.bar(X + 0.50, accuracy[2,:], color = 'r', width = 0.25)\n",
    "ax1.set_xticks([0.25, 1.25, 2.25])\n",
    "ax1.set_xticklabels(['32','64', '128'])\n",
    "ax1.set_title('Accuracy')\n",
    "ax1.set_xlabel('Embedding dimension')\n",
    "ax2.bar(X + 0.00, sensitivity[0,:], color = 'b', width = 0.25)\n",
    "ax2.bar(X + 0.25, sensitivity[1,:], color = 'g', width = 0.25)\n",
    "ax2.bar(X + 0.50, sensitivity[2,:], color = 'r', width = 0.25)\n",
    "ax2.set_xticks([0.25, 1.25, 2.25])\n",
    "ax2.set_xticklabels(['32','64', '128'])\n",
    "ax2.set_title('Sensitivity')\n",
    "ax2.set_xlabel('Embedding dimension')\n",
    "ax3.bar(X + 0.00, especificity[0,:], color = 'b', width = 0.25)\n",
    "ax3.bar(X + 0.25, especificity[1,:], color = 'g', width = 0.25)\n",
    "ax3.bar(X + 0.50, especificity[2,:], color = 'r', width = 0.25)\n",
    "ax3.set_xticks([0.25, 1.25, 2.25])\n",
    "ax3.set_xticklabels(['32','64', '128'])\n",
    "ax3.set_title('Especificity')\n",
    "ax3.set_xlabel('Embedding dimension')\n",
    "ax3.legend(labels=['32 cells','64 cells','128 cells'],bbox_to_anchor=(1.1, 1.05))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cargando GloVe pre-entrenados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_index = tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Model_Sentimen(Embeb,cells,wordsmatrix):\n",
    "    model = Sequential([\n",
    "        Embedding(input_dim=max_fatures, output_dim=Embeb, weights = [wordsmatrix], trainable = False, mask_zero=True),\n",
    "        LSTM(cells,activation='relu'),\n",
    "        Dense(10,activation='relu'),\n",
    "        Dropout(0.3),\n",
    "        Dense(1,activation='sigmoid')\n",
    "    ])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "GLOVE_DIR = '/home/julian/Documents/Datasets/glove.twitter.27B/'\n",
    "def load_embeddings(dim):\n",
    "    embeddings_index = {}\n",
    "    f = open(os.path.join(GLOVE_DIR, 'glove.twitter.27B.'+ str(dim)+'d.txt'))\n",
    "    for line in f:\n",
    "        values = line.split()\n",
    "        word_g = values[0]\n",
    "        coefs = np.asarray(values[1:], dtype='float32')\n",
    "        embeddings_index[word_g] = coefs\n",
    "    f.close()\n",
    "    print('Found %s word vectors.' % len(embeddings_index))\n",
    "    return embeddings_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_embedding_matrix(embeddings_index,EMBEDDING_DIM):\n",
    "    #EMBEDDING_DIM = 25\n",
    "    embedding_matrix = np.zeros((len(word_index) + 1, EMBEDDING_DIM))\n",
    "    for word, i in word_index.items():\n",
    "        embedding_vector = embeddings_index.get(word)\n",
    "        if embedding_vector is not None:\n",
    "            # words not found in embedding index will be all-zeros.\n",
    "            embedding_matrix[i] = embedding_vector\n",
    "    return embedding_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1193514 word vectors.\n",
      "Train on 8308 samples, validate on 924 samples\n",
      "Epoch 1/10\n",
      "8308/8308 [==============================] - 2s 299us/sample - loss: 0.3930 - accuracy: 0.8316 - val_loss: 0.3240 - val_accuracy: 0.8788\n",
      "Epoch 2/10\n",
      "8308/8308 [==============================] - 1s 172us/sample - loss: 0.2992 - accuracy: 0.8823 - val_loss: 0.2969 - val_accuracy: 0.8842\n",
      "Epoch 3/10\n",
      "8308/8308 [==============================] - 1s 172us/sample - loss: 0.2787 - accuracy: 0.8871 - val_loss: 0.2871 - val_accuracy: 0.8842\n",
      "Epoch 4/10\n",
      "8308/8308 [==============================] - 1s 170us/sample - loss: 0.2681 - accuracy: 0.8917 - val_loss: 0.2838 - val_accuracy: 0.8842\n",
      "Epoch 5/10\n",
      "8308/8308 [==============================] - 1s 172us/sample - loss: 0.2550 - accuracy: 0.8965 - val_loss: 0.2867 - val_accuracy: 0.8929\n",
      "Epoch 6/10\n",
      "8308/8308 [==============================] - 1s 170us/sample - loss: 0.2527 - accuracy: 0.8988 - val_loss: 0.2809 - val_accuracy: 0.8896\n",
      "Epoch 7/10\n",
      "8308/8308 [==============================] - 1s 172us/sample - loss: 0.2430 - accuracy: 0.9007 - val_loss: 0.2819 - val_accuracy: 0.8929\n",
      "Epoch 8/10\n",
      "8308/8308 [==============================] - 1s 171us/sample - loss: 0.2401 - accuracy: 0.9011 - val_loss: 0.2763 - val_accuracy: 0.8907\n",
      "Epoch 9/10\n",
      "8308/8308 [==============================] - 1s 171us/sample - loss: 0.2311 - accuracy: 0.9044 - val_loss: 0.2803 - val_accuracy: 0.8939\n",
      "Epoch 10/10\n",
      "8308/8308 [==============================] - 1s 172us/sample - loss: 0.2267 - accuracy: 0.9047 - val_loss: 0.2786 - val_accuracy: 0.8929\n",
      "Found 1193514 word vectors.\n",
      "Train on 8308 samples, validate on 924 samples\n",
      "Epoch 1/10\n",
      "8308/8308 [==============================] - 2s 296us/sample - loss: 0.3871 - accuracy: 0.8145 - val_loss: 0.3356 - val_accuracy: 0.8723\n",
      "Epoch 2/10\n",
      "8308/8308 [==============================] - 2s 194us/sample - loss: 0.3157 - accuracy: 0.8837 - val_loss: 0.3191 - val_accuracy: 0.8896\n",
      "Epoch 3/10\n",
      "8308/8308 [==============================] - 2s 195us/sample - loss: 0.2958 - accuracy: 0.8956 - val_loss: 0.3144 - val_accuracy: 0.8918\n",
      "Epoch 4/10\n",
      "8308/8308 [==============================] - 2s 194us/sample - loss: 0.2823 - accuracy: 0.8989 - val_loss: 0.2973 - val_accuracy: 0.8961\n",
      "Epoch 5/10\n",
      "8308/8308 [==============================] - 2s 196us/sample - loss: 0.2690 - accuracy: 0.9053 - val_loss: 0.3091 - val_accuracy: 0.8799\n",
      "Epoch 6/10\n",
      "8308/8308 [==============================] - 2s 195us/sample - loss: 0.2557 - accuracy: 0.9070 - val_loss: 0.3000 - val_accuracy: 0.8918\n",
      "Epoch 7/10\n",
      "8308/8308 [==============================] - 2s 196us/sample - loss: 0.2503 - accuracy: 0.9095 - val_loss: 0.2924 - val_accuracy: 0.8983\n",
      "Epoch 8/10\n",
      "8308/8308 [==============================] - 2s 195us/sample - loss: 0.2393 - accuracy: 0.9145 - val_loss: 0.3052 - val_accuracy: 0.8918\n",
      "Epoch 9/10\n",
      "8308/8308 [==============================] - 2s 195us/sample - loss: 0.2312 - accuracy: 0.9133 - val_loss: 0.2968 - val_accuracy: 0.8994\n",
      "Epoch 10/10\n",
      "8308/8308 [==============================] - 2s 195us/sample - loss: 0.2215 - accuracy: 0.9153 - val_loss: 0.2989 - val_accuracy: 0.8918\n",
      "Found 1193514 word vectors.\n",
      "Train on 8308 samples, validate on 924 samples\n",
      "Epoch 1/10\n",
      "8308/8308 [==============================] - 3s 373us/sample - loss: 0.6613 - accuracy: 0.7897 - val_loss: 0.6300 - val_accuracy: 0.7976\n",
      "Epoch 2/10\n",
      "8308/8308 [==============================] - 2s 271us/sample - loss: 0.4554 - accuracy: 0.8584 - val_loss: 0.3090 - val_accuracy: 0.8788\n",
      "Epoch 3/10\n",
      "8308/8308 [==============================] - 2s 271us/sample - loss: 0.3180 - accuracy: 0.8950 - val_loss: 0.2866 - val_accuracy: 0.8929\n",
      "Epoch 4/10\n",
      "8308/8308 [==============================] - 2s 270us/sample - loss: 0.2889 - accuracy: 0.9025 - val_loss: 0.2862 - val_accuracy: 0.8950\n",
      "Epoch 5/10\n",
      "8308/8308 [==============================] - 2s 273us/sample - loss: 0.2713 - accuracy: 0.9048 - val_loss: 0.2750 - val_accuracy: 0.8874\n",
      "Epoch 6/10\n",
      "8308/8308 [==============================] - 2s 273us/sample - loss: 0.2609 - accuracy: 0.9101 - val_loss: 0.2802 - val_accuracy: 0.8896\n",
      "Epoch 7/10\n",
      "8308/8308 [==============================] - 2s 271us/sample - loss: 0.2462 - accuracy: 0.9135 - val_loss: 0.2816 - val_accuracy: 0.8831\n",
      "Epoch 8/10\n",
      "8308/8308 [==============================] - 2s 272us/sample - loss: 0.2330 - accuracy: 0.9156 - val_loss: 0.2832 - val_accuracy: 0.8907\n",
      "Epoch 9/10\n",
      "8308/8308 [==============================] - 2s 272us/sample - loss: 0.2208 - accuracy: 0.9227 - val_loss: 0.2957 - val_accuracy: 0.8896\n",
      "Epoch 10/10\n",
      "8308/8308 [==============================] - 2s 273us/sample - loss: 0.2068 - accuracy: 0.9279 - val_loss: 0.3105 - val_accuracy: 0.8907\n",
      "Found 1193514 word vectors.\n",
      "Train on 8308 samples, validate on 924 samples\n",
      "Epoch 1/10\n",
      "8308/8308 [==============================] - 2s 283us/sample - loss: 0.3670 - accuracy: 0.8436 - val_loss: 0.2895 - val_accuracy: 0.8918\n",
      "Epoch 2/10\n",
      "8308/8308 [==============================] - 1s 177us/sample - loss: 0.2790 - accuracy: 0.8882 - val_loss: 0.2850 - val_accuracy: 0.8939\n",
      "Epoch 3/10\n",
      "8308/8308 [==============================] - 1s 177us/sample - loss: 0.2556 - accuracy: 0.9021 - val_loss: 0.2572 - val_accuracy: 0.9048\n",
      "Epoch 4/10\n",
      "8308/8308 [==============================] - 1s 175us/sample - loss: 0.2396 - accuracy: 0.9072 - val_loss: 0.2522 - val_accuracy: 0.9037\n",
      "Epoch 5/10\n",
      "8308/8308 [==============================] - 1s 173us/sample - loss: 0.2246 - accuracy: 0.9138 - val_loss: 0.2516 - val_accuracy: 0.9037\n",
      "Epoch 6/10\n",
      "8308/8308 [==============================] - 1s 174us/sample - loss: 0.2118 - accuracy: 0.9178 - val_loss: 0.2532 - val_accuracy: 0.9048\n",
      "Epoch 7/10\n",
      "8308/8308 [==============================] - 1s 173us/sample - loss: 0.2058 - accuracy: 0.9226 - val_loss: 0.2581 - val_accuracy: 0.9015\n",
      "Epoch 8/10\n",
      "8308/8308 [==============================] - 1s 174us/sample - loss: 0.1964 - accuracy: 0.9245 - val_loss: 0.2664 - val_accuracy: 0.9058\n",
      "Epoch 9/10\n",
      "8308/8308 [==============================] - 1s 174us/sample - loss: 0.1870 - accuracy: 0.9310 - val_loss: 0.2453 - val_accuracy: 0.9026\n",
      "Epoch 10/10\n",
      "8308/8308 [==============================] - 1s 173us/sample - loss: 0.1791 - accuracy: 0.9334 - val_loss: 0.2598 - val_accuracy: 0.9048\n",
      "Found 1193514 word vectors.\n",
      "Train on 8308 samples, validate on 924 samples\n",
      "Epoch 1/10\n",
      "8308/8308 [==============================] - 3s 303us/sample - loss: 0.3489 - accuracy: 0.8580 - val_loss: 0.2869 - val_accuracy: 0.8939\n",
      "Epoch 2/10\n",
      "8308/8308 [==============================] - 2s 197us/sample - loss: 0.2712 - accuracy: 0.8942 - val_loss: 0.2669 - val_accuracy: 0.8929\n",
      "Epoch 3/10\n",
      "8308/8308 [==============================] - 2s 196us/sample - loss: 0.2554 - accuracy: 0.9043 - val_loss: 0.2580 - val_accuracy: 0.8972\n",
      "Epoch 4/10\n",
      "8308/8308 [==============================] - 2s 196us/sample - loss: 0.2358 - accuracy: 0.9141 - val_loss: 0.2638 - val_accuracy: 0.8994\n",
      "Epoch 5/10\n",
      "8308/8308 [==============================] - 2s 196us/sample - loss: 0.2206 - accuracy: 0.9171 - val_loss: 0.2616 - val_accuracy: 0.9004\n",
      "Epoch 6/10\n",
      "8308/8308 [==============================] - 2s 196us/sample - loss: 0.2064 - accuracy: 0.9261 - val_loss: 0.2607 - val_accuracy: 0.8961\n",
      "Epoch 7/10\n",
      "8308/8308 [==============================] - 2s 197us/sample - loss: 0.1961 - accuracy: 0.9265 - val_loss: 0.2676 - val_accuracy: 0.8983\n",
      "Epoch 8/10\n",
      "8308/8308 [==============================] - 2s 198us/sample - loss: 0.1822 - accuracy: 0.9367 - val_loss: 0.3059 - val_accuracy: 0.9026\n",
      "Epoch 9/10\n",
      "8308/8308 [==============================] - 2s 197us/sample - loss: 0.1680 - accuracy: 0.9396 - val_loss: 0.2778 - val_accuracy: 0.8994\n",
      "Epoch 10/10\n",
      "8308/8308 [==============================] - 2s 196us/sample - loss: 0.1543 - accuracy: 0.9427 - val_loss: 0.3181 - val_accuracy: 0.9004\n",
      "Found 1193514 word vectors.\n",
      "Train on 8308 samples, validate on 924 samples\n",
      "Epoch 1/10\n",
      "8308/8308 [==============================] - 3s 377us/sample - loss: 0.3607 - accuracy: 0.8426 - val_loss: 0.2723 - val_accuracy: 0.8972\n",
      "Epoch 2/10\n",
      "8308/8308 [==============================] - 2s 272us/sample - loss: 0.2860 - accuracy: 0.8997 - val_loss: 0.2579 - val_accuracy: 0.8972\n",
      "Epoch 3/10\n",
      "8308/8308 [==============================] - 2s 271us/sample - loss: 0.2452 - accuracy: 0.9095 - val_loss: 0.2545 - val_accuracy: 0.8983\n",
      "Epoch 4/10\n",
      "8308/8308 [==============================] - 2s 270us/sample - loss: 0.2228 - accuracy: 0.9167 - val_loss: 0.2484 - val_accuracy: 0.8972\n",
      "Epoch 5/10\n",
      "8308/8308 [==============================] - 2s 271us/sample - loss: 0.2179 - accuracy: 0.9188 - val_loss: 0.2571 - val_accuracy: 0.9026\n",
      "Epoch 6/10\n",
      "8308/8308 [==============================] - 2s 270us/sample - loss: 0.2058 - accuracy: 0.9239 - val_loss: 0.2612 - val_accuracy: 0.8994\n",
      "Epoch 7/10\n",
      "8308/8308 [==============================] - 2s 271us/sample - loss: 0.1847 - accuracy: 0.9310 - val_loss: 0.2490 - val_accuracy: 0.9048\n",
      "Epoch 8/10\n",
      "8308/8308 [==============================] - 2s 272us/sample - loss: 0.1678 - accuracy: 0.9369 - val_loss: 0.2802 - val_accuracy: 0.9015\n",
      "Epoch 9/10\n",
      "8308/8308 [==============================] - 2s 273us/sample - loss: 0.1607 - accuracy: 0.9393 - val_loss: 0.2831 - val_accuracy: 0.9015\n",
      "Epoch 10/10\n",
      "8308/8308 [==============================] - 2s 274us/sample - loss: 0.1419 - accuracy: 0.9468 - val_loss: 0.3975 - val_accuracy: 0.8961\n",
      "Found 1193514 word vectors.\n",
      "Train on 8308 samples, validate on 924 samples\n",
      "Epoch 1/10\n",
      "8308/8308 [==============================] - 2s 279us/sample - loss: 0.3614 - accuracy: 0.8471 - val_loss: 0.3064 - val_accuracy: 0.8874\n",
      "Epoch 2/10\n",
      "8308/8308 [==============================] - 1s 173us/sample - loss: 0.2617 - accuracy: 0.8938 - val_loss: 0.2561 - val_accuracy: 0.8950\n",
      "Epoch 3/10\n",
      "8308/8308 [==============================] - 1s 172us/sample - loss: 0.2345 - accuracy: 0.9008 - val_loss: 0.2557 - val_accuracy: 0.8961\n",
      "Epoch 4/10\n",
      "8308/8308 [==============================] - 1s 171us/sample - loss: 0.2161 - accuracy: 0.9083 - val_loss: 0.2764 - val_accuracy: 0.8950\n",
      "Epoch 5/10\n",
      "8308/8308 [==============================] - 1s 171us/sample - loss: 0.2023 - accuracy: 0.9097 - val_loss: 0.2684 - val_accuracy: 0.9026\n",
      "Epoch 6/10\n",
      "8308/8308 [==============================] - 1s 171us/sample - loss: 0.1897 - accuracy: 0.9231 - val_loss: 0.2553 - val_accuracy: 0.8994\n",
      "Epoch 7/10\n",
      "8308/8308 [==============================] - 1s 170us/sample - loss: 0.1785 - accuracy: 0.9320 - val_loss: 0.3025 - val_accuracy: 0.9069\n",
      "Epoch 8/10\n",
      "8308/8308 [==============================] - 1s 171us/sample - loss: 0.1636 - accuracy: 0.9356 - val_loss: 0.2942 - val_accuracy: 0.9015\n",
      "Epoch 9/10\n",
      "8308/8308 [==============================] - 1s 171us/sample - loss: 0.1507 - accuracy: 0.9417 - val_loss: 0.2959 - val_accuracy: 0.8972\n",
      "Epoch 10/10\n",
      "8308/8308 [==============================] - 1s 175us/sample - loss: 0.1360 - accuracy: 0.9478 - val_loss: 0.3359 - val_accuracy: 0.8950\n",
      "Found 1193514 word vectors.\n",
      "Train on 8308 samples, validate on 924 samples\n",
      "Epoch 1/10\n",
      "8308/8308 [==============================] - 3s 319us/sample - loss: 0.3339 - accuracy: 0.8656 - val_loss: 0.2702 - val_accuracy: 0.8950\n",
      "Epoch 2/10\n",
      "8308/8308 [==============================] - 2s 197us/sample - loss: 0.2358 - accuracy: 0.9090 - val_loss: 0.2876 - val_accuracy: 0.8885\n",
      "Epoch 3/10\n",
      "8308/8308 [==============================] - 2s 197us/sample - loss: 0.2149 - accuracy: 0.9135 - val_loss: 0.2669 - val_accuracy: 0.8950\n",
      "Epoch 4/10\n",
      "8308/8308 [==============================] - 2s 197us/sample - loss: 0.1969 - accuracy: 0.9192 - val_loss: 0.2693 - val_accuracy: 0.8961\n",
      "Epoch 5/10\n",
      "8308/8308 [==============================] - 2s 197us/sample - loss: 0.1845 - accuracy: 0.9271 - val_loss: 0.2692 - val_accuracy: 0.8994\n",
      "Epoch 6/10\n",
      "8308/8308 [==============================] - 2s 198us/sample - loss: 0.1700 - accuracy: 0.9339 - val_loss: 0.2884 - val_accuracy: 0.8983\n",
      "Epoch 7/10\n",
      "8308/8308 [==============================] - 2s 197us/sample - loss: 0.1548 - accuracy: 0.9370 - val_loss: 0.3637 - val_accuracy: 0.8939\n",
      "Epoch 8/10\n",
      "8308/8308 [==============================] - 2s 199us/sample - loss: 0.1405 - accuracy: 0.9442 - val_loss: 0.3375 - val_accuracy: 0.8842\n",
      "Epoch 9/10\n",
      "8308/8308 [==============================] - 2s 200us/sample - loss: 0.1252 - accuracy: 0.9496 - val_loss: 0.4892 - val_accuracy: 0.8950\n",
      "Epoch 10/10\n",
      "8308/8308 [==============================] - 2s 198us/sample - loss: 0.1126 - accuracy: 0.9578 - val_loss: 0.5413 - val_accuracy: 0.8950\n",
      "Found 1193514 word vectors.\n",
      "Train on 8308 samples, validate on 924 samples\n",
      "Epoch 1/10\n",
      "8308/8308 [==============================] - 3s 380us/sample - loss: 0.3700 - accuracy: 0.8624 - val_loss: 0.2864 - val_accuracy: 0.8885\n",
      "Epoch 2/10\n",
      "8308/8308 [==============================] - 2s 281us/sample - loss: 0.2565 - accuracy: 0.9072 - val_loss: 0.2565 - val_accuracy: 0.8950\n",
      "Epoch 3/10\n",
      "8308/8308 [==============================] - 2s 283us/sample - loss: 0.2226 - accuracy: 0.9194 - val_loss: 0.2581 - val_accuracy: 0.9004\n",
      "Epoch 4/10\n",
      "8308/8308 [==============================] - 2s 278us/sample - loss: 0.2073 - accuracy: 0.9274 - val_loss: 0.2595 - val_accuracy: 0.8994\n",
      "Epoch 5/10\n",
      "8308/8308 [==============================] - 2s 280us/sample - loss: 0.1872 - accuracy: 0.9312 - val_loss: 0.3262 - val_accuracy: 0.8972\n",
      "Epoch 6/10\n",
      "8308/8308 [==============================] - 2s 278us/sample - loss: 0.1780 - accuracy: 0.9380 - val_loss: 0.2411 - val_accuracy: 0.9058\n",
      "Epoch 7/10\n",
      "8308/8308 [==============================] - 2s 286us/sample - loss: 0.1765 - accuracy: 0.9408 - val_loss: 0.2841 - val_accuracy: 0.9015\n",
      "Epoch 8/10\n",
      "8308/8308 [==============================] - 2s 292us/sample - loss: 0.1437 - accuracy: 0.9514 - val_loss: 0.3131 - val_accuracy: 0.8983\n",
      "Epoch 9/10\n",
      "8308/8308 [==============================] - 2s 282us/sample - loss: 0.1265 - accuracy: 0.9578 - val_loss: 0.3730 - val_accuracy: 0.9058\n",
      "Epoch 10/10\n",
      "8308/8308 [==============================] - 2s 277us/sample - loss: 0.1099 - accuracy: 0.9635 - val_loss: 0.4473 - val_accuracy: 0.9004\n"
     ]
    }
   ],
   "source": [
    "sensitivity = np.zeros((3,3))\n",
    "especificity = np.zeros((3,3))\n",
    "accuracy = np.zeros((3,3))\n",
    "for i, embed_dim in enumerate([25,50,100]):\n",
    "    for j,cells in enumerate([32,64,128]):\n",
    "        #---------------------------------------------------------------------------------\n",
    "        embeddings_index = load_embeddings(embed_dim)\n",
    "        embedding_matrix = load_embedding_matrix(embeddings_index,embed_dim)\n",
    "        wordsmatrix = embedding_matrix[:2001,:]\n",
    "        #-------------------------------------------------------------------------------------\n",
    "        model = Model_Sentimen(embed_dim,cells,wordsmatrix)\n",
    "        opt = optimizers.Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999, amsgrad=False)\n",
    "        model.compile(optimizer=opt, loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "        model.fit(X_tr, y_tr, validation_split=0.1,batch_size=32, epochs=10, verbose=1)\n",
    "        y_pred = np.round(model.predict(X_te))\n",
    "        sensitivity[i,j] = recall_score(y_te,y_pred)\n",
    "        accuracy[i,j] = accuracy_score(y_te,y_pred)\n",
    "        especificity[i,j] = especi_score(y_te,y_pred.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x216 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best accuracy= 0.9081853616284106\n"
     ]
    }
   ],
   "source": [
    "fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(10,3))\n",
    "X = np.arange(3)\n",
    "ax1.bar(X + 0.00, accuracy[0,:], color = 'b', width = 0.25)\n",
    "ax1.bar(X + 0.25, accuracy[1,:], color = 'g', width = 0.25)\n",
    "ax1.bar(X + 0.50, accuracy[2,:], color = 'r', width = 0.25)\n",
    "ax1.set_xticks([0.25, 1.25, 2.25])\n",
    "ax1.set_xticklabels(['25','50', '100'])\n",
    "ax1.set_title('Accuracy')\n",
    "ax1.set_xlabel('Embedding dimension')\n",
    "ax2.bar(X + 0.00, sensitivity[0,:], color = 'b', width = 0.25)\n",
    "ax2.bar(X + 0.25, sensitivity[1,:], color = 'g', width = 0.25)\n",
    "ax2.bar(X + 0.50, sensitivity[2,:], color = 'r', width = 0.25)\n",
    "ax2.set_xticks([0.25, 1.25, 2.25])\n",
    "ax2.set_xticklabels(['25','50', '100'])\n",
    "ax2.set_title('Sensitivity')\n",
    "ax2.set_xlabel('Embedding dimension')\n",
    "ax3.bar(X + 0.00, especificity[0,:], color = 'b', width = 0.25)\n",
    "ax3.bar(X + 0.25, especificity[1,:], color = 'g', width = 0.25)\n",
    "ax3.bar(X + 0.50, especificity[2,:], color = 'r', width = 0.25)\n",
    "ax3.set_xticks([0.25, 1.25, 2.25])\n",
    "ax3.set_xticklabels(['25','50', '100'])\n",
    "ax3.set_title('Especificity')\n",
    "ax3.set_xlabel('Embedding dimension')\n",
    "ax3.legend(labels=['32 cells','64 cells','128 cells'],bbox_to_anchor=(1.1, 1.05))\n",
    "plt.show()\n",
    "print('Best accuracy= {}'.format(np.max(accuracy)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "GLOVE_DIR = '/home/julian/Documents/Datasets/glove.6B/'\n",
    "def load_embeddings(dim):\n",
    "    embeddings_index = {}\n",
    "    f = open(os.path.join(GLOVE_DIR, 'glove.6B.'+ str(dim)+'d.txt'))\n",
    "    for line in f:\n",
    "        values = line.split()\n",
    "        word_g = values[0]\n",
    "        coefs = np.asarray(values[1:], dtype='float32')\n",
    "        embeddings_index[word_g] = coefs\n",
    "    f.close()\n",
    "    print('Found %s word vectors.' % len(embeddings_index))\n",
    "    return embeddings_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 400000 word vectors.\n",
      "Train on 8308 samples, validate on 924 samples\n",
      "Epoch 1/10\n",
      "8308/8308 [==============================] - 2s 278us/sample - loss: 0.3986 - accuracy: 0.8346 - val_loss: 0.3231 - val_accuracy: 0.8755\n",
      "Epoch 2/10\n",
      "8308/8308 [==============================] - 1s 172us/sample - loss: 0.3000 - accuracy: 0.8805 - val_loss: 0.2968 - val_accuracy: 0.8820\n",
      "Epoch 3/10\n",
      "8308/8308 [==============================] - 1s 169us/sample - loss: 0.2786 - accuracy: 0.8852 - val_loss: 0.2877 - val_accuracy: 0.8939\n",
      "Epoch 4/10\n",
      "8308/8308 [==============================] - 1s 169us/sample - loss: 0.2606 - accuracy: 0.8942 - val_loss: 0.2873 - val_accuracy: 0.8918\n",
      "Epoch 5/10\n",
      "8308/8308 [==============================] - 1s 170us/sample - loss: 0.2489 - accuracy: 0.8987 - val_loss: 0.2820 - val_accuracy: 0.8918\n",
      "Epoch 6/10\n",
      "8308/8308 [==============================] - 1s 170us/sample - loss: 0.2351 - accuracy: 0.9018 - val_loss: 0.2891 - val_accuracy: 0.8929\n",
      "Epoch 7/10\n",
      "8308/8308 [==============================] - 1s 171us/sample - loss: 0.2250 - accuracy: 0.9029 - val_loss: 0.3005 - val_accuracy: 0.8896\n",
      "Epoch 8/10\n",
      "8308/8308 [==============================] - 1s 169us/sample - loss: 0.2100 - accuracy: 0.9149 - val_loss: 0.3121 - val_accuracy: 0.8874\n",
      "Epoch 9/10\n",
      "8308/8308 [==============================] - 1s 169us/sample - loss: 0.1987 - accuracy: 0.9207 - val_loss: 0.3026 - val_accuracy: 0.8885\n",
      "Epoch 10/10\n",
      "8308/8308 [==============================] - 1s 170us/sample - loss: 0.1893 - accuracy: 0.9234 - val_loss: 0.3697 - val_accuracy: 0.8853\n",
      "Found 400000 word vectors.\n",
      "Train on 8308 samples, validate on 924 samples\n",
      "Epoch 1/10\n",
      "8308/8308 [==============================] - 3s 319us/sample - loss: 0.4064 - accuracy: 0.8270 - val_loss: 0.3135 - val_accuracy: 0.8810\n",
      "Epoch 2/10\n",
      "8308/8308 [==============================] - 2s 195us/sample - loss: 0.2848 - accuracy: 0.8887 - val_loss: 0.3084 - val_accuracy: 0.8810\n",
      "Epoch 3/10\n",
      "8308/8308 [==============================] - 2s 195us/sample - loss: 0.2618 - accuracy: 0.8993 - val_loss: 0.2935 - val_accuracy: 0.8874\n",
      "Epoch 4/10\n",
      "8308/8308 [==============================] - 2s 195us/sample - loss: 0.2374 - accuracy: 0.9024 - val_loss: 0.2817 - val_accuracy: 0.8874\n",
      "Epoch 5/10\n",
      "8308/8308 [==============================] - 2s 195us/sample - loss: 0.2228 - accuracy: 0.9090 - val_loss: 0.3002 - val_accuracy: 0.8853\n",
      "Epoch 6/10\n",
      "8308/8308 [==============================] - 2s 197us/sample - loss: 0.2088 - accuracy: 0.9162 - val_loss: 0.3175 - val_accuracy: 0.8896\n",
      "Epoch 7/10\n",
      "8308/8308 [==============================] - 2s 197us/sample - loss: 0.1925 - accuracy: 0.9233 - val_loss: 0.3481 - val_accuracy: 0.8885\n",
      "Epoch 8/10\n",
      "8308/8308 [==============================] - 2s 199us/sample - loss: 0.1838 - accuracy: 0.9271 - val_loss: 0.3014 - val_accuracy: 0.8896\n",
      "Epoch 9/10\n",
      "8308/8308 [==============================] - 2s 197us/sample - loss: 0.1709 - accuracy: 0.9319 - val_loss: 0.3457 - val_accuracy: 0.8907\n",
      "Epoch 10/10\n",
      "8308/8308 [==============================] - 2s 201us/sample - loss: 0.1548 - accuracy: 0.9368 - val_loss: 0.3851 - val_accuracy: 0.8885\n",
      "Found 400000 word vectors.\n",
      "Train on 8308 samples, validate on 924 samples\n",
      "Epoch 1/10\n",
      "8308/8308 [==============================] - 3s 374us/sample - loss: 0.4167 - accuracy: 0.8251 - val_loss: 0.3099 - val_accuracy: 0.8777\n",
      "Epoch 2/10\n",
      "8308/8308 [==============================] - 2s 269us/sample - loss: 0.3062 - accuracy: 0.8835 - val_loss: 0.2979 - val_accuracy: 0.8820\n",
      "Epoch 3/10\n",
      "8308/8308 [==============================] - 2s 269us/sample - loss: 0.2688 - accuracy: 0.9008 - val_loss: 0.2895 - val_accuracy: 0.8896\n",
      "Epoch 4/10\n",
      "8308/8308 [==============================] - 2s 270us/sample - loss: 0.2489 - accuracy: 0.9085 - val_loss: 0.2851 - val_accuracy: 0.8864\n",
      "Epoch 5/10\n",
      "8308/8308 [==============================] - 2s 275us/sample - loss: 0.2303 - accuracy: 0.9148 - val_loss: 0.2952 - val_accuracy: 0.8874\n",
      "Epoch 6/10\n",
      "8308/8308 [==============================] - 2s 274us/sample - loss: 0.2096 - accuracy: 0.9200 - val_loss: 0.3050 - val_accuracy: 0.8896\n",
      "Epoch 7/10\n",
      "8308/8308 [==============================] - 2s 266us/sample - loss: 0.1960 - accuracy: 0.9277 - val_loss: 0.3356 - val_accuracy: 0.8853\n",
      "Epoch 8/10\n",
      "8308/8308 [==============================] - 2s 266us/sample - loss: 0.1747 - accuracy: 0.9356 - val_loss: 0.3122 - val_accuracy: 0.8983\n",
      "Epoch 9/10\n",
      "8308/8308 [==============================] - 2s 267us/sample - loss: 0.1557 - accuracy: 0.9421 - val_loss: 0.3750 - val_accuracy: 0.8896\n",
      "Epoch 10/10\n",
      "8308/8308 [==============================] - 2s 270us/sample - loss: 0.1354 - accuracy: 0.9509 - val_loss: 0.3869 - val_accuracy: 0.8896\n",
      "Found 400000 word vectors.\n",
      "Train on 8308 samples, validate on 924 samples\n",
      "Epoch 1/10\n",
      "8308/8308 [==============================] - 2s 289us/sample - loss: 0.3764 - accuracy: 0.8412 - val_loss: 0.2974 - val_accuracy: 0.8831\n",
      "Epoch 2/10\n",
      "8308/8308 [==============================] - 1s 168us/sample - loss: 0.2710 - accuracy: 0.8923 - val_loss: 0.2782 - val_accuracy: 0.8853\n",
      "Epoch 3/10\n",
      "8308/8308 [==============================] - 1s 170us/sample - loss: 0.2446 - accuracy: 0.9031 - val_loss: 0.2747 - val_accuracy: 0.9015\n",
      "Epoch 4/10\n",
      "8308/8308 [==============================] - 1s 168us/sample - loss: 0.2292 - accuracy: 0.9102 - val_loss: 0.2734 - val_accuracy: 0.9015\n",
      "Epoch 5/10\n",
      "8308/8308 [==============================] - 1s 171us/sample - loss: 0.2150 - accuracy: 0.9180 - val_loss: 0.2720 - val_accuracy: 0.8972\n",
      "Epoch 6/10\n",
      "8308/8308 [==============================] - 1s 168us/sample - loss: 0.1963 - accuracy: 0.9227 - val_loss: 0.2825 - val_accuracy: 0.9004\n",
      "Epoch 7/10\n",
      "8308/8308 [==============================] - 1s 170us/sample - loss: 0.1829 - accuracy: 0.9295 - val_loss: 0.3325 - val_accuracy: 0.8961\n",
      "Epoch 8/10\n",
      "8308/8308 [==============================] - 1s 171us/sample - loss: 0.1705 - accuracy: 0.9351 - val_loss: 0.3106 - val_accuracy: 0.8777\n",
      "Epoch 9/10\n",
      "8308/8308 [==============================] - 1s 168us/sample - loss: 0.1578 - accuracy: 0.9384 - val_loss: 0.3065 - val_accuracy: 0.8950\n",
      "Epoch 10/10\n",
      "8308/8308 [==============================] - 1s 167us/sample - loss: 0.1493 - accuracy: 0.9409 - val_loss: 0.3171 - val_accuracy: 0.9004\n",
      "Found 400000 word vectors.\n",
      "Train on 8308 samples, validate on 924 samples\n",
      "Epoch 1/10\n",
      "8308/8308 [==============================] - 3s 303us/sample - loss: 0.3609 - accuracy: 0.8519 - val_loss: 0.2977 - val_accuracy: 0.8896\n",
      "Epoch 2/10\n",
      "8308/8308 [==============================] - 2s 196us/sample - loss: 0.2626 - accuracy: 0.9021 - val_loss: 0.2749 - val_accuracy: 0.8950\n",
      "Epoch 3/10\n",
      "8308/8308 [==============================] - 2s 195us/sample - loss: 0.2380 - accuracy: 0.9100 - val_loss: 0.2699 - val_accuracy: 0.9004\n",
      "Epoch 4/10\n",
      "8308/8308 [==============================] - 2s 198us/sample - loss: 0.2181 - accuracy: 0.9189 - val_loss: 0.2731 - val_accuracy: 0.9037\n",
      "Epoch 5/10\n",
      "8308/8308 [==============================] - 2s 196us/sample - loss: 0.1983 - accuracy: 0.9244 - val_loss: 0.2902 - val_accuracy: 0.9037\n",
      "Epoch 6/10\n",
      "8308/8308 [==============================] - 2s 193us/sample - loss: 0.1772 - accuracy: 0.9302 - val_loss: 0.2687 - val_accuracy: 0.9037\n",
      "Epoch 7/10\n",
      "8308/8308 [==============================] - 2s 204us/sample - loss: 0.1619 - accuracy: 0.9405 - val_loss: 0.2827 - val_accuracy: 0.9015\n",
      "Epoch 8/10\n",
      "8308/8308 [==============================] - 2s 201us/sample - loss: 0.1444 - accuracy: 0.9466 - val_loss: 0.3160 - val_accuracy: 0.8939\n",
      "Epoch 9/10\n",
      "8308/8308 [==============================] - 2s 196us/sample - loss: 0.1343 - accuracy: 0.9505 - val_loss: 0.3784 - val_accuracy: 0.9048\n",
      "Epoch 10/10\n",
      "8308/8308 [==============================] - 2s 195us/sample - loss: 0.1396 - accuracy: 0.9476 - val_loss: 0.3325 - val_accuracy: 0.9015\n",
      "Found 400000 word vectors.\n",
      "Train on 8308 samples, validate on 924 samples\n",
      "Epoch 1/10\n",
      "8308/8308 [==============================] - 3s 403us/sample - loss: 0.3688 - accuracy: 0.8615 - val_loss: 0.2903 - val_accuracy: 0.8918\n",
      "Epoch 2/10\n",
      "8308/8308 [==============================] - 2s 276us/sample - loss: 0.2704 - accuracy: 0.9041 - val_loss: 0.2656 - val_accuracy: 0.8864\n",
      "Epoch 3/10\n",
      "8308/8308 [==============================] - 2s 276us/sample - loss: 0.2355 - accuracy: 0.9123 - val_loss: 0.2673 - val_accuracy: 0.8939\n",
      "Epoch 4/10\n",
      "8308/8308 [==============================] - 2s 275us/sample - loss: 0.2139 - accuracy: 0.9231 - val_loss: 0.2824 - val_accuracy: 0.8907\n",
      "Epoch 5/10\n",
      "8308/8308 [==============================] - 2s 276us/sample - loss: 0.1920 - accuracy: 0.9313 - val_loss: 0.2672 - val_accuracy: 0.8994\n",
      "Epoch 6/10\n",
      "8308/8308 [==============================] - 2s 284us/sample - loss: 0.1747 - accuracy: 0.9387 - val_loss: 0.3165 - val_accuracy: 0.8994\n",
      "Epoch 7/10\n",
      "8308/8308 [==============================] - 2s 282us/sample - loss: 0.1650 - accuracy: 0.9425 - val_loss: 0.2842 - val_accuracy: 0.8929\n",
      "Epoch 8/10\n",
      "8308/8308 [==============================] - 2s 279us/sample - loss: 0.1459 - accuracy: 0.9496 - val_loss: 0.3445 - val_accuracy: 0.8972\n",
      "Epoch 9/10\n",
      "8308/8308 [==============================] - 2s 279us/sample - loss: 0.1297 - accuracy: 0.9549 - val_loss: 0.3672 - val_accuracy: 0.8950\n",
      "Epoch 10/10\n",
      "8308/8308 [==============================] - 2s 275us/sample - loss: 0.1178 - accuracy: 0.9634 - val_loss: 0.2982 - val_accuracy: 0.8831\n",
      "Found 400000 word vectors.\n",
      "Train on 8308 samples, validate on 924 samples\n",
      "Epoch 1/10\n",
      "8308/8308 [==============================] - 2s 282us/sample - loss: 0.3811 - accuracy: 0.8493 - val_loss: 0.2746 - val_accuracy: 0.8961\n",
      "Epoch 2/10\n",
      "8308/8308 [==============================] - 1s 177us/sample - loss: 0.2652 - accuracy: 0.9037 - val_loss: 0.2702 - val_accuracy: 0.9015\n",
      "Epoch 3/10\n",
      "8308/8308 [==============================] - 1s 180us/sample - loss: 0.2428 - accuracy: 0.9102 - val_loss: 0.2714 - val_accuracy: 0.9004\n",
      "Epoch 4/10\n",
      "8308/8308 [==============================] - 1s 178us/sample - loss: 0.2196 - accuracy: 0.9194 - val_loss: 0.2598 - val_accuracy: 0.9026\n",
      "Epoch 5/10\n",
      "8308/8308 [==============================] - 1s 178us/sample - loss: 0.2019 - accuracy: 0.9249 - val_loss: 0.2624 - val_accuracy: 0.9004\n",
      "Epoch 6/10\n",
      "8308/8308 [==============================] - 1s 177us/sample - loss: 0.1856 - accuracy: 0.9331 - val_loss: 0.2817 - val_accuracy: 0.9091\n",
      "Epoch 7/10\n",
      "8308/8308 [==============================] - 1s 175us/sample - loss: 0.1686 - accuracy: 0.9374 - val_loss: 0.2931 - val_accuracy: 0.9037\n",
      "Epoch 8/10\n",
      "8308/8308 [==============================] - 1s 178us/sample - loss: 0.1560 - accuracy: 0.9415 - val_loss: 0.3037 - val_accuracy: 0.8972\n",
      "Epoch 9/10\n",
      "8308/8308 [==============================] - 1s 177us/sample - loss: 0.1341 - accuracy: 0.9491 - val_loss: 0.3479 - val_accuracy: 0.8972\n",
      "Epoch 10/10\n",
      "8308/8308 [==============================] - 1s 179us/sample - loss: 0.1256 - accuracy: 0.9550 - val_loss: 0.4226 - val_accuracy: 0.8983\n",
      "Found 400000 word vectors.\n",
      "Train on 8308 samples, validate on 924 samples\n",
      "Epoch 1/10\n",
      "8308/8308 [==============================] - 3s 314us/sample - loss: 0.3357 - accuracy: 0.8640 - val_loss: 0.2802 - val_accuracy: 0.8939\n",
      "Epoch 2/10\n",
      "8308/8308 [==============================] - 2s 208us/sample - loss: 0.2431 - accuracy: 0.9065 - val_loss: 0.2908 - val_accuracy: 0.8896\n",
      "Epoch 3/10\n",
      "8308/8308 [==============================] - 2s 209us/sample - loss: 0.2145 - accuracy: 0.9169 - val_loss: 0.2551 - val_accuracy: 0.9037\n",
      "Epoch 4/10\n",
      "8308/8308 [==============================] - 2s 211us/sample - loss: 0.1914 - accuracy: 0.9247 - val_loss: 0.2610 - val_accuracy: 0.8972\n",
      "Epoch 5/10\n",
      "8308/8308 [==============================] - 2s 209us/sample - loss: 0.1708 - accuracy: 0.9324 - val_loss: 0.2879 - val_accuracy: 0.8994\n",
      "Epoch 6/10\n",
      "8308/8308 [==============================] - 2s 207us/sample - loss: 0.1594 - accuracy: 0.9375 - val_loss: 0.2865 - val_accuracy: 0.9037\n",
      "Epoch 7/10\n",
      "8308/8308 [==============================] - 2s 206us/sample - loss: 0.1365 - accuracy: 0.9463 - val_loss: 0.3078 - val_accuracy: 0.8961\n",
      "Epoch 8/10\n",
      "8308/8308 [==============================] - 2s 208us/sample - loss: 0.1208 - accuracy: 0.9529 - val_loss: 0.3344 - val_accuracy: 0.8929\n",
      "Epoch 9/10\n",
      "8308/8308 [==============================] - 2s 213us/sample - loss: 0.1010 - accuracy: 0.9596 - val_loss: 0.4064 - val_accuracy: 0.8994\n",
      "Epoch 10/10\n",
      "8308/8308 [==============================] - 2s 211us/sample - loss: 0.0834 - accuracy: 0.9658 - val_loss: 0.3715 - val_accuracy: 0.8939\n",
      "Found 400000 word vectors.\n",
      "Train on 8308 samples, validate on 924 samples\n",
      "Epoch 1/10\n",
      "8308/8308 [==============================] - 4s 444us/sample - loss: 0.3296 - accuracy: 0.8729 - val_loss: 0.2714 - val_accuracy: 0.8918\n",
      "Epoch 2/10\n",
      "8308/8308 [==============================] - 2s 299us/sample - loss: 0.2370 - accuracy: 0.9108 - val_loss: 0.2610 - val_accuracy: 0.8983\n",
      "Epoch 3/10\n",
      "8308/8308 [==============================] - 3s 302us/sample - loss: 0.2009 - accuracy: 0.9228 - val_loss: 0.2764 - val_accuracy: 0.9026\n",
      "Epoch 4/10\n",
      "8308/8308 [==============================] - 3s 305us/sample - loss: 0.1782 - accuracy: 0.9339 - val_loss: 0.2588 - val_accuracy: 0.9015\n",
      "Epoch 5/10\n",
      "8308/8308 [==============================] - 3s 307us/sample - loss: 0.1521 - accuracy: 0.9434 - val_loss: 0.2947 - val_accuracy: 0.8961\n",
      "Epoch 6/10\n",
      "8308/8308 [==============================] - 2s 298us/sample - loss: 0.1379 - accuracy: 0.9496 - val_loss: 0.3760 - val_accuracy: 0.9004\n",
      "Epoch 7/10\n",
      "8308/8308 [==============================] - 3s 307us/sample - loss: 0.1095 - accuracy: 0.9597 - val_loss: 0.3259 - val_accuracy: 0.8907\n",
      "Epoch 8/10\n",
      "8308/8308 [==============================] - 3s 309us/sample - loss: 0.0887 - accuracy: 0.9668 - val_loss: 0.4102 - val_accuracy: 0.8918\n",
      "Epoch 9/10\n",
      "8308/8308 [==============================] - 2s 300us/sample - loss: 0.0786 - accuracy: 0.9714 - val_loss: 0.4792 - val_accuracy: 0.8874\n",
      "Epoch 10/10\n",
      "8308/8308 [==============================] - 3s 304us/sample - loss: 0.0636 - accuracy: 0.9776 - val_loss: 0.3750 - val_accuracy: 0.8864\n"
     ]
    }
   ],
   "source": [
    "sensitivity = np.zeros((3,3))\n",
    "especificity = np.zeros((3,3))\n",
    "accuracy = np.zeros((3,3))\n",
    "for i, embed_dim in enumerate([50,100,200]):\n",
    "    for j,cells in enumerate([32,64,128]):\n",
    "        #---------------------------------------------------------------------------------\n",
    "        embeddings_index = load_embeddings(embed_dim)\n",
    "        embedding_matrix = load_embedding_matrix(embeddings_index,embed_dim)\n",
    "        wordsmatrix = embedding_matrix[:2001,:]\n",
    "        #-------------------------------------------------------------------------------------\n",
    "        model = Model_Sentimen(embed_dim,cells,wordsmatrix)\n",
    "        opt = optimizers.Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999, amsgrad=False)\n",
    "        model.compile(optimizer=opt, loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "        model.fit(X_tr, y_tr, validation_split=0.1,batch_size=32, epochs=10, verbose=1)\n",
    "        y_pred = np.round(model.predict(X_te))\n",
    "        sensitivity[i,j] = recall_score(y_te,y_pred)\n",
    "        accuracy[i,j] = accuracy_score(y_te,y_pred)\n",
    "        especificity[i,j] = especi_score(y_te,y_pred.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x216 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best accuracy= 0.9086184495452577\n"
     ]
    }
   ],
   "source": [
    "fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(10,3))\n",
    "X = np.arange(3)\n",
    "ax1.bar(X + 0.00, accuracy[0,:], color = 'b', width = 0.25)\n",
    "ax1.bar(X + 0.25, accuracy[1,:], color = 'g', width = 0.25)\n",
    "ax1.bar(X + 0.50, accuracy[2,:], color = 'r', width = 0.25)\n",
    "ax1.set_xticks([0.25, 1.25, 2.25])\n",
    "ax1.set_xticklabels(['50', '100', '200'])\n",
    "ax1.set_title('Accuracy')\n",
    "ax1.set_xlabel('Embedding dimension')\n",
    "ax2.bar(X + 0.00, sensitivity[0,:], color = 'b', width = 0.25)\n",
    "ax2.bar(X + 0.25, sensitivity[1,:], color = 'g', width = 0.25)\n",
    "ax2.bar(X + 0.50, sensitivity[2,:], color = 'r', width = 0.25)\n",
    "ax2.set_xticks([0.25, 1.25, 2.25])\n",
    "ax2.set_xticklabels(['50', '100', '200'])\n",
    "ax2.set_title('Sensitivity')\n",
    "ax2.set_xlabel('Embedding dimension')\n",
    "ax3.bar(X + 0.00, especificity[0,:], color = 'b', width = 0.25)\n",
    "ax3.bar(X + 0.25, especificity[1,:], color = 'g', width = 0.25)\n",
    "ax3.bar(X + 0.50, especificity[2,:], color = 'r', width = 0.25)\n",
    "ax3.set_xticks([0.25, 1.25, 2.25])\n",
    "ax3.set_xticklabels(['50', '100', '200'])\n",
    "ax3.set_title('Especificity')\n",
    "ax3.set_xlabel('Embedding dimension')\n",
    "ax3.legend(labels=['32 cells','64 cells','128 cells'],bbox_to_anchor=(1.1, 1.05))\n",
    "plt.show()\n",
    "print('Best accuracy= {}'.format(np.max(accuracy)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 4\n",
    "\n",
    "Use a CNN architeture instead of the LSTM one, combine CNN layers for bigrams and trigrams. You can also use either the keras Embedding Layer or the CBOW embedding matrix. Compare the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "GLOVE_DIR = '/home/julian/Documents/Datasets/glove.twitter.27B/'\n",
    "def load_embeddings(dim):\n",
    "    embeddings_index = {}\n",
    "    f = open(os.path.join(GLOVE_DIR, 'glove.twitter.27B.'+ str(dim)+'d.txt'))\n",
    "    for line in f:\n",
    "        values = line.split()\n",
    "        word_g = values[0]\n",
    "        coefs = np.asarray(values[1:], dtype='float32')\n",
    "        embeddings_index[word_g] = coefs\n",
    "    f.close()\n",
    "    print('Found %s word vectors.' % len(embeddings_index))\n",
    "    return embeddings_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Model_Sentimen(Embeb,filters):\n",
    "    model = Sequential([\n",
    "        #Embedding(input_dim=max_fatures, output_dim=Embeb, weights = [np.r_[np.zeros((1,Embeb)),wordsmatrix]], trainable = False, mask_zero=True),\n",
    "        Embedding(input_dim=max_fatures, output_dim=Embeb, weights = [wordsmatrix], trainable = False, mask_zero=True),\n",
    "        Conv1D(filters,kernel_size=3,activation='relu',padding='same'),\n",
    "        GlobalMaxPooling1D(),\n",
    "        Flatten(),\n",
    "        Dense(128,activation='sigmoid'),\n",
    "        Dropout(0.3),\n",
    "        Dense(1,activation='sigmoid')\n",
    "    ])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1193514 word vectors.\n",
      "Train on 8308 samples, validate on 924 samples\n",
      "Epoch 1/10\n",
      "8308/8308 [==============================] - 1s 69us/sample - loss: 0.4596 - accuracy: 0.8067 - val_loss: 0.3438 - val_accuracy: 0.8690\n",
      "Epoch 2/10\n",
      "8308/8308 [==============================] - 0s 31us/sample - loss: 0.3176 - accuracy: 0.8742 - val_loss: 0.3125 - val_accuracy: 0.8734\n",
      "Epoch 3/10\n",
      "8308/8308 [==============================] - 0s 32us/sample - loss: 0.2846 - accuracy: 0.8852 - val_loss: 0.3197 - val_accuracy: 0.8669\n",
      "Epoch 4/10\n",
      "8308/8308 [==============================] - 0s 29us/sample - loss: 0.2741 - accuracy: 0.8907 - val_loss: 0.3025 - val_accuracy: 0.8777\n",
      "Epoch 5/10\n",
      "8308/8308 [==============================] - 0s 33us/sample - loss: 0.2629 - accuracy: 0.8943 - val_loss: 0.3024 - val_accuracy: 0.8745\n",
      "Epoch 6/10\n",
      "8308/8308 [==============================] - 0s 35us/sample - loss: 0.2625 - accuracy: 0.8956 - val_loss: 0.2982 - val_accuracy: 0.8831\n",
      "Epoch 7/10\n",
      "8308/8308 [==============================] - 0s 34us/sample - loss: 0.2547 - accuracy: 0.8995 - val_loss: 0.3003 - val_accuracy: 0.8788\n",
      "Epoch 8/10\n",
      "8308/8308 [==============================] - 0s 33us/sample - loss: 0.2538 - accuracy: 0.8985 - val_loss: 0.3012 - val_accuracy: 0.8755\n",
      "Epoch 9/10\n",
      "8308/8308 [==============================] - 0s 46us/sample - loss: 0.2478 - accuracy: 0.9029 - val_loss: 0.3028 - val_accuracy: 0.8745\n",
      "Epoch 10/10\n",
      "8308/8308 [==============================] - 0s 43us/sample - loss: 0.2464 - accuracy: 0.9030 - val_loss: 0.3056 - val_accuracy: 0.8701\n",
      "Found 1193514 word vectors.\n",
      "Train on 8308 samples, validate on 924 samples\n",
      "Epoch 1/10\n",
      "8308/8308 [==============================] - 1s 64us/sample - loss: 0.4223 - accuracy: 0.8232 - val_loss: 0.3232 - val_accuracy: 0.8745\n",
      "Epoch 2/10\n",
      "8308/8308 [==============================] - 0s 29us/sample - loss: 0.2940 - accuracy: 0.8800 - val_loss: 0.3064 - val_accuracy: 0.8723\n",
      "Epoch 3/10\n",
      "8308/8308 [==============================] - 0s 29us/sample - loss: 0.2694 - accuracy: 0.8908 - val_loss: 0.3001 - val_accuracy: 0.8766\n",
      "Epoch 4/10\n",
      "8308/8308 [==============================] - 0s 29us/sample - loss: 0.2605 - accuracy: 0.8965 - val_loss: 0.3013 - val_accuracy: 0.8755\n",
      "Epoch 5/10\n",
      "8308/8308 [==============================] - 0s 29us/sample - loss: 0.2491 - accuracy: 0.9008 - val_loss: 0.2953 - val_accuracy: 0.8777\n",
      "Epoch 6/10\n",
      "8308/8308 [==============================] - 0s 29us/sample - loss: 0.2425 - accuracy: 0.9023 - val_loss: 0.2989 - val_accuracy: 0.8766\n",
      "Epoch 7/10\n",
      "8308/8308 [==============================] - 0s 29us/sample - loss: 0.2370 - accuracy: 0.9068 - val_loss: 0.2974 - val_accuracy: 0.8777\n",
      "Epoch 8/10\n",
      "8308/8308 [==============================] - 0s 30us/sample - loss: 0.2306 - accuracy: 0.9091 - val_loss: 0.3045 - val_accuracy: 0.8799\n",
      "Epoch 9/10\n",
      "8308/8308 [==============================] - 0s 30us/sample - loss: 0.2279 - accuracy: 0.9086 - val_loss: 0.3028 - val_accuracy: 0.8734\n",
      "Epoch 10/10\n",
      "8308/8308 [==============================] - 0s 29us/sample - loss: 0.2255 - accuracy: 0.9123 - val_loss: 0.3072 - val_accuracy: 0.8766\n",
      "Found 1193514 word vectors.\n",
      "Train on 8308 samples, validate on 924 samples\n",
      "Epoch 1/10\n",
      "8308/8308 [==============================] - 1s 66us/sample - loss: 0.3910 - accuracy: 0.8411 - val_loss: 0.3093 - val_accuracy: 0.8734\n",
      "Epoch 2/10\n",
      "8308/8308 [==============================] - 0s 29us/sample - loss: 0.2758 - accuracy: 0.8891 - val_loss: 0.2991 - val_accuracy: 0.8745\n",
      "Epoch 3/10\n",
      "8308/8308 [==============================] - 0s 28us/sample - loss: 0.2580 - accuracy: 0.8952 - val_loss: 0.2921 - val_accuracy: 0.8799\n",
      "Epoch 4/10\n",
      "8308/8308 [==============================] - 0s 29us/sample - loss: 0.2443 - accuracy: 0.9015 - val_loss: 0.2945 - val_accuracy: 0.8788\n",
      "Epoch 5/10\n",
      "8308/8308 [==============================] - 0s 29us/sample - loss: 0.2335 - accuracy: 0.9091 - val_loss: 0.3005 - val_accuracy: 0.8799\n",
      "Epoch 6/10\n",
      "8308/8308 [==============================] - 0s 29us/sample - loss: 0.2257 - accuracy: 0.9117 - val_loss: 0.2924 - val_accuracy: 0.8820\n",
      "Epoch 7/10\n",
      "8308/8308 [==============================] - 0s 29us/sample - loss: 0.2171 - accuracy: 0.9151 - val_loss: 0.3017 - val_accuracy: 0.8690\n",
      "Epoch 8/10\n",
      "8308/8308 [==============================] - 0s 29us/sample - loss: 0.2105 - accuracy: 0.9177 - val_loss: 0.3064 - val_accuracy: 0.8842\n",
      "Epoch 9/10\n",
      "8308/8308 [==============================] - 0s 29us/sample - loss: 0.2067 - accuracy: 0.9180 - val_loss: 0.3099 - val_accuracy: 0.8647\n",
      "Epoch 10/10\n",
      "8308/8308 [==============================] - 0s 29us/sample - loss: 0.2007 - accuracy: 0.9230 - val_loss: 0.3141 - val_accuracy: 0.8669\n",
      "Found 1193514 word vectors.\n",
      "Train on 8308 samples, validate on 924 samples\n",
      "Epoch 1/10\n",
      "8308/8308 [==============================] - 1s 64us/sample - loss: 0.4605 - accuracy: 0.7959 - val_loss: 0.3703 - val_accuracy: 0.8496\n",
      "Epoch 2/10\n",
      "8308/8308 [==============================] - 0s 29us/sample - loss: 0.3429 - accuracy: 0.8639 - val_loss: 0.3455 - val_accuracy: 0.8571\n",
      "Epoch 3/10\n",
      "8308/8308 [==============================] - 0s 29us/sample - loss: 0.3162 - accuracy: 0.8741 - val_loss: 0.3389 - val_accuracy: 0.8615\n",
      "Epoch 4/10\n",
      "8308/8308 [==============================] - 0s 30us/sample - loss: 0.2978 - accuracy: 0.8814 - val_loss: 0.3365 - val_accuracy: 0.8561\n",
      "Epoch 5/10\n",
      "8308/8308 [==============================] - 0s 29us/sample - loss: 0.2898 - accuracy: 0.8873 - val_loss: 0.3351 - val_accuracy: 0.8571\n",
      "Epoch 6/10\n",
      "8308/8308 [==============================] - 0s 30us/sample - loss: 0.2816 - accuracy: 0.8877 - val_loss: 0.3334 - val_accuracy: 0.8604\n",
      "Epoch 7/10\n",
      "8308/8308 [==============================] - 0s 36us/sample - loss: 0.2739 - accuracy: 0.8903 - val_loss: 0.3326 - val_accuracy: 0.8561\n",
      "Epoch 8/10\n",
      "8308/8308 [==============================] - 0s 30us/sample - loss: 0.2697 - accuracy: 0.8970 - val_loss: 0.3345 - val_accuracy: 0.8561\n",
      "Epoch 9/10\n",
      "8308/8308 [==============================] - 0s 30us/sample - loss: 0.2658 - accuracy: 0.8988 - val_loss: 0.3339 - val_accuracy: 0.8582\n",
      "Epoch 10/10\n",
      "8308/8308 [==============================] - 0s 33us/sample - loss: 0.2602 - accuracy: 0.8965 - val_loss: 0.3408 - val_accuracy: 0.8506\n",
      "Found 1193514 word vectors.\n",
      "Train on 8308 samples, validate on 924 samples\n",
      "Epoch 1/10\n",
      "8308/8308 [==============================] - 1s 64us/sample - loss: 0.4374 - accuracy: 0.8063 - val_loss: 0.2950 - val_accuracy: 0.8820\n",
      "Epoch 2/10\n",
      "8308/8308 [==============================] - 0s 30us/sample - loss: 0.2631 - accuracy: 0.8923 - val_loss: 0.2724 - val_accuracy: 0.8907\n",
      "Epoch 3/10\n",
      "8308/8308 [==============================] - 0s 29us/sample - loss: 0.2367 - accuracy: 0.9038 - val_loss: 0.2688 - val_accuracy: 0.8918\n",
      "Epoch 4/10\n",
      "8308/8308 [==============================] - 0s 30us/sample - loss: 0.2181 - accuracy: 0.9119 - val_loss: 0.2703 - val_accuracy: 0.8961\n",
      "Epoch 5/10\n",
      "8308/8308 [==============================] - 0s 30us/sample - loss: 0.2113 - accuracy: 0.9135 - val_loss: 0.2755 - val_accuracy: 0.8961\n",
      "Epoch 6/10\n",
      "8308/8308 [==============================] - 0s 30us/sample - loss: 0.2049 - accuracy: 0.9185 - val_loss: 0.2764 - val_accuracy: 0.8961\n",
      "Epoch 7/10\n",
      "8308/8308 [==============================] - 0s 30us/sample - loss: 0.1965 - accuracy: 0.9233 - val_loss: 0.2797 - val_accuracy: 0.8950\n",
      "Epoch 8/10\n",
      "8308/8308 [==============================] - 0s 30us/sample - loss: 0.1918 - accuracy: 0.9248 - val_loss: 0.2848 - val_accuracy: 0.8907\n",
      "Epoch 9/10\n",
      "8308/8308 [==============================] - 0s 30us/sample - loss: 0.1863 - accuracy: 0.9251 - val_loss: 0.2912 - val_accuracy: 0.8874\n",
      "Epoch 10/10\n",
      "8308/8308 [==============================] - 0s 35us/sample - loss: 0.1771 - accuracy: 0.9298 - val_loss: 0.2931 - val_accuracy: 0.8896\n",
      "Found 1193514 word vectors.\n",
      "Train on 8308 samples, validate on 924 samples\n",
      "Epoch 1/10\n",
      "8308/8308 [==============================] - 1s 65us/sample - loss: 0.3498 - accuracy: 0.8556 - val_loss: 0.2724 - val_accuracy: 0.8918\n",
      "Epoch 2/10\n",
      "8308/8308 [==============================] - 0s 29us/sample - loss: 0.2390 - accuracy: 0.9043 - val_loss: 0.2690 - val_accuracy: 0.8961\n",
      "Epoch 3/10\n",
      "8308/8308 [==============================] - 0s 29us/sample - loss: 0.2172 - accuracy: 0.9145 - val_loss: 0.2671 - val_accuracy: 0.8939\n",
      "Epoch 4/10\n",
      "8308/8308 [==============================] - 0s 29us/sample - loss: 0.2039 - accuracy: 0.9167 - val_loss: 0.2684 - val_accuracy: 0.8929\n",
      "Epoch 5/10\n",
      "8308/8308 [==============================] - 0s 29us/sample - loss: 0.1916 - accuracy: 0.9245 - val_loss: 0.2797 - val_accuracy: 0.8853\n",
      "Epoch 6/10\n",
      "8308/8308 [==============================] - 0s 29us/sample - loss: 0.1795 - accuracy: 0.9301 - val_loss: 0.2823 - val_accuracy: 0.8907\n",
      "Epoch 7/10\n",
      "8308/8308 [==============================] - 0s 29us/sample - loss: 0.1675 - accuracy: 0.9337 - val_loss: 0.2909 - val_accuracy: 0.8810\n",
      "Epoch 8/10\n",
      "8308/8308 [==============================] - 0s 29us/sample - loss: 0.1514 - accuracy: 0.9432 - val_loss: 0.2949 - val_accuracy: 0.8885\n",
      "Epoch 9/10\n",
      "8308/8308 [==============================] - 0s 29us/sample - loss: 0.1443 - accuracy: 0.9456 - val_loss: 0.3078 - val_accuracy: 0.8766\n",
      "Epoch 10/10\n",
      "8308/8308 [==============================] - 0s 29us/sample - loss: 0.1304 - accuracy: 0.9504 - val_loss: 0.3175 - val_accuracy: 0.8896\n",
      "Found 1193514 word vectors.\n",
      "Train on 8308 samples, validate on 924 samples\n",
      "Epoch 1/10\n",
      "8308/8308 [==============================] - 1s 70us/sample - loss: 0.4551 - accuracy: 0.7980 - val_loss: 0.3700 - val_accuracy: 0.8496\n",
      "Epoch 2/10\n",
      "8308/8308 [==============================] - 0s 33us/sample - loss: 0.3396 - accuracy: 0.8631 - val_loss: 0.3417 - val_accuracy: 0.8658\n",
      "Epoch 3/10\n",
      "8308/8308 [==============================] - 0s 33us/sample - loss: 0.3050 - accuracy: 0.8792 - val_loss: 0.3337 - val_accuracy: 0.8669\n",
      "Epoch 4/10\n",
      "8308/8308 [==============================] - 0s 34us/sample - loss: 0.2803 - accuracy: 0.8896 - val_loss: 0.3304 - val_accuracy: 0.8658\n",
      "Epoch 5/10\n",
      "8308/8308 [==============================] - 0s 33us/sample - loss: 0.2664 - accuracy: 0.8916 - val_loss: 0.3317 - val_accuracy: 0.8636\n",
      "Epoch 6/10\n",
      "8308/8308 [==============================] - 0s 35us/sample - loss: 0.2542 - accuracy: 0.9002 - val_loss: 0.3264 - val_accuracy: 0.8604\n",
      "Epoch 7/10\n",
      "8308/8308 [==============================] - 0s 33us/sample - loss: 0.2472 - accuracy: 0.9048 - val_loss: 0.3309 - val_accuracy: 0.8658\n",
      "Epoch 8/10\n",
      "8308/8308 [==============================] - 0s 32us/sample - loss: 0.2378 - accuracy: 0.9083 - val_loss: 0.3275 - val_accuracy: 0.8636\n",
      "Epoch 9/10\n",
      "8308/8308 [==============================] - 0s 34us/sample - loss: 0.2297 - accuracy: 0.9117 - val_loss: 0.3301 - val_accuracy: 0.8712\n",
      "Epoch 10/10\n",
      "8308/8308 [==============================] - 0s 32us/sample - loss: 0.2243 - accuracy: 0.9123 - val_loss: 0.3308 - val_accuracy: 0.8723\n",
      "Found 1193514 word vectors.\n",
      "Train on 8308 samples, validate on 924 samples\n",
      "Epoch 1/10\n",
      "8308/8308 [==============================] - 1s 102us/sample - loss: 0.3451 - accuracy: 0.8565 - val_loss: 0.2679 - val_accuracy: 0.8885\n",
      "Epoch 2/10\n",
      "8308/8308 [==============================] - 0s 32us/sample - loss: 0.2281 - accuracy: 0.9119 - val_loss: 0.2582 - val_accuracy: 0.8950\n",
      "Epoch 3/10\n",
      "8308/8308 [==============================] - 0s 32us/sample - loss: 0.2037 - accuracy: 0.9194 - val_loss: 0.2673 - val_accuracy: 0.8972\n",
      "Epoch 4/10\n",
      "8308/8308 [==============================] - 0s 31us/sample - loss: 0.1884 - accuracy: 0.9280 - val_loss: 0.2630 - val_accuracy: 0.8983\n",
      "Epoch 5/10\n",
      "8308/8308 [==============================] - 0s 31us/sample - loss: 0.1754 - accuracy: 0.9326 - val_loss: 0.2675 - val_accuracy: 0.8961\n",
      "Epoch 6/10\n",
      "8308/8308 [==============================] - 0s 32us/sample - loss: 0.1610 - accuracy: 0.9387 - val_loss: 0.2721 - val_accuracy: 0.8885\n",
      "Epoch 7/10\n",
      "8308/8308 [==============================] - 0s 32us/sample - loss: 0.1517 - accuracy: 0.9417 - val_loss: 0.2794 - val_accuracy: 0.8853\n",
      "Epoch 8/10\n",
      "8308/8308 [==============================] - 0s 31us/sample - loss: 0.1418 - accuracy: 0.9462 - val_loss: 0.2903 - val_accuracy: 0.8874\n",
      "Epoch 9/10\n",
      "8308/8308 [==============================] - 0s 32us/sample - loss: 0.1306 - accuracy: 0.9509 - val_loss: 0.3046 - val_accuracy: 0.8885\n",
      "Epoch 10/10\n",
      "8308/8308 [==============================] - 0s 32us/sample - loss: 0.1226 - accuracy: 0.9537 - val_loss: 0.3072 - val_accuracy: 0.8864\n",
      "Found 1193514 word vectors.\n",
      "Train on 8308 samples, validate on 924 samples\n",
      "Epoch 1/10\n",
      "8308/8308 [==============================] - 1s 73us/sample - loss: 0.3737 - accuracy: 0.8347 - val_loss: 0.2676 - val_accuracy: 0.8874\n",
      "Epoch 2/10\n",
      "8308/8308 [==============================] - 0s 34us/sample - loss: 0.2266 - accuracy: 0.9073 - val_loss: 0.2643 - val_accuracy: 0.8961\n",
      "Epoch 3/10\n",
      "8308/8308 [==============================] - 0s 34us/sample - loss: 0.2003 - accuracy: 0.9208 - val_loss: 0.2651 - val_accuracy: 0.8939\n",
      "Epoch 4/10\n",
      "8308/8308 [==============================] - 0s 34us/sample - loss: 0.1828 - accuracy: 0.9284 - val_loss: 0.2738 - val_accuracy: 0.8907\n",
      "Epoch 5/10\n",
      "8308/8308 [==============================] - 0s 34us/sample - loss: 0.1635 - accuracy: 0.9351 - val_loss: 0.2816 - val_accuracy: 0.8950\n",
      "Epoch 6/10\n",
      "8308/8308 [==============================] - 0s 33us/sample - loss: 0.1476 - accuracy: 0.9411 - val_loss: 0.2804 - val_accuracy: 0.8853\n",
      "Epoch 7/10\n",
      "8308/8308 [==============================] - 0s 34us/sample - loss: 0.1298 - accuracy: 0.9521 - val_loss: 0.2901 - val_accuracy: 0.8950\n",
      "Epoch 8/10\n",
      "8308/8308 [==============================] - 0s 34us/sample - loss: 0.1121 - accuracy: 0.9565 - val_loss: 0.3008 - val_accuracy: 0.8950\n",
      "Epoch 9/10\n",
      "8308/8308 [==============================] - 0s 34us/sample - loss: 0.0964 - accuracy: 0.9652 - val_loss: 0.3358 - val_accuracy: 0.8788\n",
      "Epoch 10/10\n",
      "8308/8308 [==============================] - 0s 34us/sample - loss: 0.0835 - accuracy: 0.9703 - val_loss: 0.3472 - val_accuracy: 0.8874\n"
     ]
    }
   ],
   "source": [
    "sensitivity = np.zeros((3,3))\n",
    "especificity = np.zeros((3,3))\n",
    "accuracy = np.zeros((3,3))\n",
    "for i, embed_dim in enumerate([25,50,100]):\n",
    "    for j,filters in enumerate([6,12,24]):\n",
    "        #---------------------------------------------------------------------------------\n",
    "        embeddings_index = load_embeddings(embed_dim)\n",
    "        embedding_matrix = load_embedding_matrix(embeddings_index,embed_dim)\n",
    "        wordsmatrix = embedding_matrix[:2001,:]\n",
    "        #-------------------------------------------------------------------------------------\n",
    "        #-------------------------------------------------------------------------------------\n",
    "        model = Model_Sentimen(embed_dim,filters)\n",
    "        model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "        model.fit(X_tr, y_tr, validation_split=0.1,batch_size=32, epochs=10, verbose=1)\n",
    "        y_pred = np.round(model.predict(X_te))\n",
    "        sensitivity[i,j] = recall_score(y_te,y_pred)\n",
    "        accuracy[i,j] = accuracy_score(y_te,y_pred)\n",
    "        especificity[i,j] = especi_score(y_te,y_pred.flatten())   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x216 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best accuracy= 0.9047206582936336\n"
     ]
    }
   ],
   "source": [
    "fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(10,3))\n",
    "X = np.arange(3)\n",
    "ax1.bar(X + 0.00, accuracy[0,:], color = 'b', width = 0.25)\n",
    "ax1.bar(X + 0.25, accuracy[1,:], color = 'g', width = 0.25)\n",
    "ax1.bar(X + 0.50, accuracy[2,:], color = 'r', width = 0.25)\n",
    "ax1.set_xticks([0.25, 1.25, 2.25])\n",
    "ax1.set_xticklabels(['25','50', '100'])\n",
    "ax1.set_title('Accuracy')\n",
    "ax1.set_xlabel('Embedding dimension')\n",
    "ax2.bar(X + 0.00, sensitivity[0,:], color = 'b', width = 0.25)\n",
    "ax2.bar(X + 0.25, sensitivity[1,:], color = 'g', width = 0.25)\n",
    "ax2.bar(X + 0.50, sensitivity[2,:], color = 'r', width = 0.25)\n",
    "ax2.set_xticks([0.25, 1.25, 2.25])\n",
    "ax2.set_xticklabels(['25','50', '100'])\n",
    "ax2.set_title('Sensitivity')\n",
    "ax2.set_xlabel('Embedding dimension')\n",
    "ax3.bar(X + 0.00, especificity[0,:], color = 'b', width = 0.25)\n",
    "ax3.bar(X + 0.25, especificity[1,:], color = 'g', width = 0.25)\n",
    "ax3.bar(X + 0.50, especificity[2,:], color = 'r', width = 0.25)\n",
    "ax3.set_xticks([0.25, 1.25, 2.25])\n",
    "ax3.set_xticklabels(['25','50', '100'])\n",
    "ax3.set_title('Especificity')\n",
    "ax3.set_xlabel('Embedding dimension')\n",
    "ax3.legend(labels=['32 cells','64 cells','128 cells'],bbox_to_anchor=(1.1, 1.05))\n",
    "plt.show()\n",
    "print('Best accuracy= {}'.format(np.max(accuracy)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
