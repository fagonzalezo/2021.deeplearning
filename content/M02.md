# 02 - NEURAL NETWORKS

## Autoencoders

**2.1 - Introducción a autoencoders**: [Video 14mins](https://youtu.be/k24X6la0vaU) <br/>Introducimos la noción de autoencoder, como una arquitectura de red neuronal para aprendizaje no supervisado.

**2.2 - Autoencoders en Tensorflow**: [Video 9mins](https://youtu.be/OFcST3ndQ4g) <br/> Mostramos cómo implementar autoencoders con Tensroflow y cómo obtener la representación en el espacio latente de nuevos datos de entrada.

**2.3 - Interpretabilidad de autoencoders**: [Video 13mins](https://youtu.be/o9kUgnxmsfI) <br/>Ilustramos cómo podemos darle significado intuitivo a los pesos _aprendidos_ por un autoencoder.

**2.4 - Interpretabilidad de autoencoders (2)**: [Video 4mins](https://youtu.be/2W27N9iEzek) <br/>Puntualizamos un aspecto del video anterior.

**2.5 - Denoising autoencoders**: [Video 10mins](https://youtu.be/U6QHAX8cx0w) <br/>Explicamos cómo se pueden usar los autoencoders para aplicaciones de eliminación de ruido.

## Arquitecturas multimodales

**3.1 - Problemas multimodales**: [Video 11mins](https://youtu.be/shfKOfA1Cxc) <br/>Describimos el caso de uso en el que tenemos varias fuentes de información de naturaleza distinta de cada objeto de nuestro dataset (p.ej. imágenes y datos vectoriales), y queremos generar modelos que se aprovechen de esa información.

**3.2 - Arquitecturas multimodales en Tensorflow**: [Video 15mins](https://youtu.be/tBiMNVH4yF8) <br/>Explicamos cómo podemos usar el API funcional de Tensorflow para construir redes que solucionen problemas multimodales.

## The Vanishing Gradient

**4.1 - El gradiente desvaneciente**: [Video 15min](https://youtu.be/pkR-D7GwDTY) <br/> Describimos uno de los problemas que impiden que las redes neuronales se puedan entrenar.

**4.2 - Histogramas de pesos**: [Video 8mins](https://youtu.be/9HH8kpEkN8I) <br/>Mostramos cómo podemos hacerle seguimiento a la evolución de los pesos de una red durante el entrenamiento.

**4.3 - Observando el gradiente desvaneciente con TensorBoard**: [Video 15mins](https://youtu.be/jsuYeOGUJng) <br/>Desarrollamos un caso práctico donde mostramos como utilizar TensorBoard para inspeccionar la evolución de los pesos de una red durante el entrenamiento.

## Inicialización de pesos

**5.1 - Estrategias para acelerar el entrenamiento**: [Video 6mins](https://youtu.be/Gv_m-u-G7pI) <br/> Ponemos en perspectiva las distintas aproximaciones que estamos desarrollando para solventar los problemas del gradiente en el entrenamiento de las redes neuronales.

**5.2 - Inicialización de pesos**: [Video 18mins](https://youtu.be/dSsqXY_ypNQ) <br/> Explicamos la intuición y la justificación de las estrategias de inicialización de pesos.

**5.3 - Observando los efectos de la inicialización de pesos**: [Video 18mins](https://youtu.be/-PVjugMJ9No) <br/> Desarrollamos unos experimentos para poder observar en la práctica lo aprendido anteriormente.

## LABORATORIOS

**LAB 2 - Sparse autoencoders**: [Video 9mins](https://youtu.be/6njflcFHjW8)<br/>En este laboratorio crearás un **Sparse Autoencoder** en el que las neuronas de la representación latente adquirirán funciones más especializadas.

**LAB 3 - Pair-wise image classification**: [Video 9mins](https://youtu.be/H6u5ECdNaRA)<br/>En este laboratorio montarás una arquitectura de red con múltiples entradas para una tarea de clasificación de pares de imágenes.

**LAB 4 - Tensorflow callbacks**: [Video 8mins](https://youtu.be/AiUBwWV3tgs)<br/>El objetivo de este laboratorio es que te familiarices con el mecanismos de callbacks de Tensorflow con el cual podrás incluir instrumentación en tu modelo para realizarle seguimiento a lo que necesites durante el entrenamiento del mismo.


