
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>3.2 - TF symbolic engine &#8212; Fundamentos de Deep Learning</title>
    
  <link rel="stylesheet" href="../_static/css/index.73d71520a4ca3b99cfee5594769eaaae.css">

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      
  <link rel="stylesheet"
    href="../_static/vendor/open-sans_all/1.44.1/index.css">
  <link rel="stylesheet"
    href="../_static/vendor/lato_latin-ext/1.44.1/index.css">

    
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="../_static/sphinx-book-theme.40e2e510f6b7d1648584402491bb10fe.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="../_static/js/index.3da636dd464baa7582d2.js">

    <script id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/togglebutton.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script >var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../_static/sphinx-book-theme.d31b09fe5c1d09cb49b26a786de4a05d.js"></script>
    <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["\\(", "\\)"]], "displayMath": [["\\[", "\\]"]], "processRefs": false, "processEnvironments": false}})</script>
    <script async="async" src="https://unpkg.com/thebelab@latest/lib/index.js"></script>
    <script >
        const thebe_selector = ".thebe"
        const thebe_selector_input = "pre"
        const thebe_selector_output = ".output"
    </script>
    <script async="async" src="../_static/sphinx-thebe.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="3.3 - Using tf.function" href="U3.03%20-%20Using%20tf.function.html" />
    <link rel="prev" title="3.1 - Symbolic computing for ML" href="U3.01%20-%20Simbolic%20computing%20for%20ML.html" />

    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en" />



  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
<a class="navbar-brand text-wrap" href="../index.html">
  
  <img src="../_static/fudea.jpg" class="logo" alt="logo">
  
  
  <h1 class="site-logo" id="site-title">Fundamentos de Deep Learning</h1>
  
</a>
</div><form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form>
<nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">
    <ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="../intro.html">
   Welcome
  </a>
 </li>
</ul>
<ul class="current nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="M00.html">
   Información 20211 - UdeA
  </a>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="M01.html">
   01 - INTRODUCTION
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="U1.01%20-%20DL%20Overview.html">
     1.1 - DL Overview
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="U1.02%20-%20Modelos%20derivados%20de%20los%20datos.html">
     1.2 - Models derived from data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="U1.03%20-%20Como%20se%20disena%20un%20algoritmo%20de%20Machine%20Learning.html">
     1.3 - ML algorithm design
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="U1%20LAB%2001%20-%20WARMUP.html">
     LAB 01.01 - WARM UP
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="M02.html">
   02 - NEURAL NETWORKS
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="U2.01%20-%20The%20Perceptron.html">
     2.1 - The Perceptron
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="U2.02%20-%20The%20Multilayer%20Perceptron.html">
     2.2 - The Multilayer Perceptron
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="U2.03%20-%20Overfitting%20and%20regularization.html">
     2.3 - Overfitting and regularization
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="U2.04%20-%20Loss%20functions.html">
     2.4 - Loss functions in Tensorflow
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="U2.05%20-%20Network%20Architectures%20-%20Autoencoders.html">
     2.5 - Autoencoders
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="U2.06%20-%20Network%20Architectures%20-%20Multimodal%20information.html">
     2.6 - Multimodal architectures
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="U2.07%20-%20Vanishing%20gradients.html">
     2.7 - Vanishing gradients
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="U2.08%20-%20Weights%20initialization.html">
     2.8 - Weights initialization
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="U2%20LAB%2001%20-%20Customized%20loss%20functions%20and%20regularization.html">
     LAB 2.1 - Customized loss function
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="U2%20LAB%2002%20-%20Autoencoders.html">
     LAB 2.2 - Sparse Autoencoders
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="U2%20LAB%2003%20-%20Pairwise%20image%20classification.html">
     LAB 2.3 - Parwise classification
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="U2%20LAB%2004%20-%20Model%20instrumentation%20and%20monitoring.html">
     LAB 2.4 - Model instrumentation
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 current active collapsible-parent">
  <a class="reference internal" href="M03.html">
   03 - TENSORFLOW
  </a>
  <ul class="current collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="U3.01%20-%20Simbolic%20computing%20for%20ML.html">
     3.1 - Symbolic computing for ML
    </a>
   </li>
   <li class="toctree-l2 current active">
    <a class="current reference internal" href="#">
     3.2 - TF symbolic engine
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="U3.03%20-%20Using%20tf.function.html">
     3.3 - Using
     <code class="docutils literal notranslate">
      <span class="pre">
       tf.function
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="U3.04%20-%20Batch%20Normalization.html">
     3.4 - Batch normalization
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="U3%20LAB%2001%20-%20Tensorflow%20model%20subclassing.html">
     LAB 3.1 - TF model subclassing
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="U3%20LAB%2002%20-%20Batch%20normalization.html">
     LAB 3.2 - Batch normalization
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
</ul>

</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="row topbar fixed-top container-xl">
    <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show">
    </div>
    <div class="col pl-2 topbar-main">
        
        <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
            data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
            aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
            title="Toggle navigation" data-toggle="tooltip" data-placement="left">
            <i class="fas fa-bars"></i>
            <i class="fas fa-arrow-left"></i>
            <i class="fas fa-arrow-up"></i>
        </button>
        
        
<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="../_sources/content/U3.02 - TF for symbolic computing.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.ipynb</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
            onClick="window.print()" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
</div>

        <!-- Source interaction buttons -->


        <!-- Full screen (wrap in <a> to have style consistency -->
        <a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
                data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
                title="Fullscreen mode"><i
                    class="fas fa-expand"></i></button></a>

        <!-- Launch buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Launch interactive content"><i class="fas fa-rocket"></i></button>
    <div class="dropdown-buttons">
        
        
        
        <a class="colab-button" href="https://colab.research.google.com/github/rramosp/2021.deeplearning/blob/master/content/U3.02 - TF for symbolic computing.ipynb"><button type="button" class="btn btn-secondary topbarbtn"
                title="Launch Colab" data-toggle="tooltip" data-placement="left"><img class="colab-button-logo"
                    src="../_static/images/logo_colab.png"
                    alt="Interact on Colab">Colab</button></a>
        
        
    </div>
</div>

    </div>

    <!-- Table of contents -->
    <div class="d-none d-md-block col-md-2 bd-toc show">
        
        <div class="tocsection onthispage pt-5 pb-3">
            <i class="fas fa-list"></i> Contents
        </div>
        <nav id="bd-toc-nav">
            <ul class="nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#tensorflow-dev-summit">
   Tensorflow Dev Summit
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#tf-is-a-symbolic-computing-optimization-library-for-machine-learning-problems">
   TF is a symbolic computing + optimization library for machine learning problems
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#tensors">
   Tensors
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#implementing-linear-regresion-in-tf">
   Implementing linear regresion in TF
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#version-1-raw-low-level-with-gradient-descent">
   Version 1: raw low level with gradient descent
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#version-2-using-tf-function-to-speed-up">
   Version 2: using
   <code class="docutils literal notranslate">
    <span class="pre">
     tf.function
    </span>
   </code>
   to speed up
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#version-3-using-batches-with-random-shuffling-stochastic-gradient-descent">
   Version 3: using batches with random shuffling (stochastic gradient descent)
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#version-4-packing-up-with-keras-class-api-and-custom-sgd">
   Version 4: packing up with Keras
   <code class="docutils literal notranslate">
    <span class="pre">
     class
    </span>
   </code>
   API  and custom SGD
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#version-5-sequential-keras-model-with-standard-loop">
   Version 5: Sequential Keras model with standard loop
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#version-6-custom-model-with-keras-class-api-and-standard-loop">
   Version 6: Custom model with Keras
   <code class="docutils literal notranslate">
    <span class="pre">
     class
    </span>
   </code>
   API  and standard loop
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#version-7-using-train-step-rightarrow-control-loss-and-gradients-on-a-custom-model">
   Version 7: Using
   <code class="docutils literal notranslate">
    <span class="pre">
     train_step
    </span>
   </code>
   <span class="math notranslate nohighlight">
    \(\rightarrow\)
   </span>
   control loss and gradients on a custom model.
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#version-8-using-train-step-rightarrow-control-loss-and-gradients-on-a-standard-model">
   Version 8: Using
   <code class="docutils literal notranslate">
    <span class="pre">
     train_step
    </span>
   </code>
   <span class="math notranslate nohighlight">
    \(\rightarrow\)
   </span>
   control loss and gradients on a standard model.
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#version-9-using-train-on-batch-rightarrow-control-data">
   Version 9: using
   <code class="docutils literal notranslate">
    <span class="pre">
     train_on_batch
    </span>
   </code>
   <span class="math notranslate nohighlight">
    \(\rightarrow\)
   </span>
   control data
  </a>
 </li>
</ul>

        </nav>
        
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
        
              <div>
                
  <div class="section" id="tf-symbolic-engine">
<h1>3.2 - TF symbolic engine<a class="headerlink" href="#tf-symbolic-engine" title="Permalink to this headline">¶</a></h1>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">!</span>wget -nc --no-cache -O init.py -q https://raw.githubusercontent.com/rramosp/2021.deeplearning/main/content/init.py
<span class="kn">import</span> <span class="nn">init</span><span class="p">;</span> <span class="n">init</span><span class="o">.</span><span class="n">init</span><span class="p">(</span><span class="n">force_download</span><span class="o">=</span><span class="kc">False</span><span class="p">);</span> 
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="o">%</span><span class="k">matplotlib</span> inline
<span class="o">%</span><span class="k">load_ext</span> tensorboard

<span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">local.lib</span> <span class="kn">import</span> <span class="n">mlutils</span>
<span class="kn">from</span> <span class="nn">IPython.display</span> <span class="kn">import</span> <span class="n">Image</span>
<span class="n">tf</span><span class="o">.</span><span class="n">__version__</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&#39;2.2.0&#39;
</pre></div>
</div>
</div>
</div>
<div class="section" id="tensorflow-dev-summit">
<h2>Tensorflow Dev Summit<a class="headerlink" href="#tensorflow-dev-summit" title="Permalink to this headline">¶</a></h2>
<p>the following images are screenshots of the publicly available material from conferences at the <a class="reference external" href="https://www.tensorflow.org/dev-summit">TensorFLow Dev Summit</a></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">Image</span><span class="p">(</span><span class="s2">&quot;local/imgs/tfCycle.png&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/U3.02 - TF for symbolic computing_4_0.png" src="../_images/U3.02 - TF for symbolic computing_4_0.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">Image</span><span class="p">(</span><span class="s2">&quot;local/imgs/tfTrainingWorkflow.png&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/U3.02 - TF for symbolic computing_5_0.png" src="../_images/U3.02 - TF for symbolic computing_5_0.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">Image</span><span class="p">(</span><span class="s2">&quot;local/imgs/tfAPIs.png&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/U3.02 - TF for symbolic computing_6_0.png" src="../_images/U3.02 - TF for symbolic computing_6_0.png" />
</div>
</div>
</div>
<div class="section" id="tf-is-a-symbolic-computing-optimization-library-for-machine-learning-problems">
<h2>TF is a symbolic computing + optimization library for machine learning problems<a class="headerlink" href="#tf-is-a-symbolic-computing-optimization-library-for-machine-learning-problems" title="Permalink to this headline">¶</a></h2>
<p>ML expressions involve:</p>
<ul class="simple">
<li><p>variables representing data as n-dimensional objects</p></li>
<li><p>variables representing parameters as n-dimensional objects</p></li>
<li><p>mostly matrix operations (multiplications, convolutions, etc.)</p></li>
<li><p>some non linear operations (activation functions)</p></li>
</ul>
<p><strong>Recall</strong> that in <code class="docutils literal notranslate"><span class="pre">sympy</span></code> we <strong>FIRST</strong> define expressions (a computational graph) and <strong>THEN</strong> we evaluate them feed concrete values.</p>
<p>Tensorflow <strong>INTEGRATES</strong> both aspects so that building computational graphs <strong>LOOKS LIKE</strong> writing regular Pytohn code as must as possible.</p>
<ul class="simple">
<li><p>a <code class="docutils literal notranslate"><span class="pre">tf.Variable</span></code> represents a <strong>symbolic</strong> variable, that <strong>contains a value</strong></p></li>
</ul>
<p>See:</p>
<ul class="simple">
<li><p>https://www.tensorflow.org/guide/keras/train_and_evaluate</p></li>
<li><p>https://www.tensorflow.org/guide/keras/custom_layers_and_models</p></li>
<li><p>https://www.tensorflow.org/guide/keras/customizing_what_happens_in_fit</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">x</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="n">initial_value</span><span class="o">=</span><span class="p">[</span><span class="mi">7</span><span class="p">],</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;x&quot;</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="n">initial_value</span><span class="o">=</span><span class="p">[</span><span class="mi">9</span><span class="p">],</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;y&quot;</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">f</span> <span class="o">=</span> <span class="n">x</span><span class="o">**</span><span class="mi">2</span><span class="o">+</span><span class="n">y</span><span class="o">**</span><span class="mi">3</span>
<span class="n">f</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;tf.Tensor: shape=(1,), dtype=float32, numpy=array([778.], dtype=float32)&gt;
</pre></div>
</div>
</div>
</div>
<p><code class="docutils literal notranslate"><span class="pre">f</span></code> is <strong>SYMBOLIC EXPRESSION</strong> (a <code class="docutils literal notranslate"><span class="pre">Tensor</span></code> in TF terms) that also contains a value attached to it.</p>
<p>for which TF can obtain gradients automatically. This might seem a rather akward way of obtaining the gradient (with <code class="docutils literal notranslate"><span class="pre">GradientTape</span></code>). The goal is that you <strong>write code as in Python</strong> and TF takes care of building the computational graph with it.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">GradientTape</span><span class="p">(</span><span class="n">persistent</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span> <span class="k">as</span> <span class="n">t</span><span class="p">:</span>
    <span class="n">f</span> <span class="o">=</span> <span class="n">x</span><span class="o">**</span><span class="mi">2</span> <span class="o">+</span> <span class="n">y</span><span class="o">**</span><span class="mi">3</span>
    
<span class="nb">print</span> <span class="p">(</span><span class="n">t</span><span class="o">.</span><span class="n">gradient</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">x</span><span class="p">),</span> <span class="n">t</span><span class="o">.</span><span class="n">gradient</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">y</span><span class="p">))</span>
    
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>tf.Tensor([14.], shape=(1,), dtype=float32) tf.Tensor([243.], shape=(1,), dtype=float32)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span> <span class="p">(</span><span class="n">t</span><span class="o">.</span><span class="n">gradient</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="p">[</span><span class="n">x</span><span class="p">,</span><span class="n">y</span><span class="p">]))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[&lt;tf.Tensor: shape=(1,), dtype=float32, numpy=array([14.], dtype=float32)&gt;, &lt;tf.Tensor: shape=(1,), dtype=float32, numpy=array([243.], dtype=float32)&gt;]
</pre></div>
</div>
</div>
</div>
<p>usually expressions are built within functions decorated with <code class="docutils literal notranslate"><span class="pre">&#64;tf.function</span></code> for performance</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nd">@tf</span><span class="o">.</span><span class="n">function</span>
<span class="k">def</span> <span class="nf">myf</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">y</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">x</span><span class="o">**</span><span class="mi">2</span> <span class="o">+</span> <span class="n">y</span><span class="o">**</span><span class="mi">3</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">GradientTape</span><span class="p">(</span><span class="n">persistent</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span> <span class="k">as</span> <span class="n">t</span><span class="p">:</span>
    <span class="n">f</span> <span class="o">=</span> <span class="n">myf</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">y</span><span class="p">)</span>
    
<span class="nb">print</span> <span class="p">(</span><span class="n">t</span><span class="o">.</span><span class="n">gradient</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">x</span><span class="p">),</span> <span class="n">t</span><span class="o">.</span><span class="n">gradient</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">y</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>tf.Tensor([14.], shape=(1,), dtype=float32) tf.Tensor([243.], shape=(1,), dtype=float32)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">!</span>rm -rf logs
<span class="n">mlutils</span><span class="o">.</span><span class="n">make_graph</span><span class="p">(</span><span class="n">myf</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">logdir</span><span class="o">=</span><span class="s2">&quot;logs&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;tensorflow.python.eager.def_function.Function object at 0x7f82b0317850&gt;
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%</span><span class="k">tensorboard</span> --logdir logs
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="tensors">
<h2>Tensors<a class="headerlink" href="#tensors" title="Permalink to this headline">¶</a></h2>
<p>in <code class="docutils literal notranslate"><span class="pre">Tensorflow</span></code> the notion of a Tensor is just a <strong>symbolic multidimensional array</strong>. Although, this is a recent simplified version of what always has been known as a tensor in differential geometry (see <a class="reference external" href="https://bjlkeng.github.io/posts/tensors-tensors-tensors/">https://bjlkeng.github.io/posts/tensors-tensors-tensors/</a>).</p>
<p>Observe how Tensorflow naturally deals with multidimensional symbolic variables (Tensors)</p>
<div class="math notranslate nohighlight">
\[\frac{1}{m} \sum (X\theta - y)^2\]</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">n</span> <span class="o">=</span> <span class="mi">3</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="n">initial_value</span><span class="o">=</span><span class="p">[[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">6</span><span class="p">],</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">]],</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;X&quot;</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">w</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="n">initial_value</span><span class="o">=</span><span class="p">[[</span><span class="o">-</span><span class="mi">2</span><span class="p">],[</span><span class="mi">1</span><span class="p">]],</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;w&quot;</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="n">initial_value</span><span class="o">=</span><span class="p">[[</span><span class="mi">8</span><span class="p">],[</span><span class="mi">2</span><span class="p">],[</span><span class="mi">3</span><span class="p">]],</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;y&quot;</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>

<span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">GradientTape</span><span class="p">(</span><span class="n">persistent</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span> <span class="k">as</span> <span class="n">t</span><span class="p">:</span>
    <span class="n">f</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_mean</span><span class="p">((</span><span class="n">tf</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">X</span><span class="p">,</span><span class="n">w</span><span class="p">)</span><span class="o">-</span><span class="n">y</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span>
    
<span class="n">g</span> <span class="o">=</span> <span class="n">t</span><span class="o">.</span><span class="n">gradient</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">w</span><span class="p">)</span>
<span class="n">g</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;tf.Tensor: shape=(2, 1), dtype=float32, numpy=
array([[-38.      ],
       [-48.666668]], dtype=float32)&gt;
</pre></div>
</div>
</div>
</div>
<p>But a <code class="docutils literal notranslate"><span class="pre">tf.Tensor</span></code> is always a symbolic variable. In order to reconcile symbolic and execution worlds, <code class="docutils literal notranslate"><span class="pre">Tensorflow</span></code> <strong>attaches</strong> a value to each symbolic variable, and carries it forward when making derivations.</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">X</span></code>, <code class="docutils literal notranslate"><span class="pre">y</span></code> and <code class="docutils literal notranslate"><span class="pre">w</span></code> are Tensors that we define with a specific value</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">g</span></code> is a Tensor derived from <code class="docutils literal notranslate"><span class="pre">X</span></code>, <code class="docutils literal notranslate"><span class="pre">y</span></code> and <code class="docutils literal notranslate"><span class="pre">w</span></code> that have ALSO been evaluated with the corresponding values.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">g</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;tf.Tensor: shape=(2, 1), dtype=float32, numpy=
array([[-38.      ],
       [-48.666668]], dtype=float32)&gt;
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">g</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([[-38.      ],
       [-48.666668]], dtype=float32)
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="implementing-linear-regresion-in-tf">
<h2>Implementing linear regresion in TF<a class="headerlink" href="#implementing-linear-regresion-in-tf" title="Permalink to this headline">¶</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">d</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s2">&quot;local/data/trilotropicos.csv&quot;</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">d</span><span class="o">.</span><span class="n">densidad_escamas</span><span class="o">.</span><span class="n">values</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">r_</span><span class="p">[[</span><span class="n">d</span><span class="o">.</span><span class="n">longitud</span><span class="o">.</span><span class="n">values</span><span class="p">]]</span><span class="o">.</span><span class="n">T</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">y</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">d</span><span class="o">.</span><span class="n">longitud</span><span class="p">,</span> <span class="n">d</span><span class="o">.</span><span class="n">densidad_escamas</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="n">d</span><span class="o">.</span><span class="n">columns</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="n">d</span><span class="o">.</span><span class="n">columns</span><span class="p">[</span><span class="mi">1</span><span class="p">]);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(150, 1) (150,)
</pre></div>
</div>
<img alt="../_images/U3.02 - TF for symbolic computing_23_1.png" src="../_images/U3.02 - TF for symbolic computing_23_1.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LinearRegression</span>

<span class="n">lr</span> <span class="o">=</span> <span class="n">LinearRegression</span><span class="p">()</span>
<span class="n">lr</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span><span class="n">y</span><span class="p">)</span>
<span class="n">lr</span><span class="o">.</span><span class="n">coef_</span><span class="p">,</span> <span class="n">lr</span><span class="o">.</span><span class="n">intercept_</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(array([-0.71805906], dtype=float32), 12.689999)
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="version-1-raw-low-level-with-gradient-descent">
<h2>Version 1: raw low level with gradient descent<a class="headerlink" href="#version-1-raw-low-level-with-gradient-descent" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><p>beware of typing. <code class="docutils literal notranslate"><span class="pre">tensorflow</span></code> is very sensitive to numeric data types (<code class="docutils literal notranslate"><span class="pre">tf.float32</span></code>, <code class="docutils literal notranslate"><span class="pre">tf.float64</span></code>, etc.) Default types in <code class="docutils literal notranslate"><span class="pre">numpy</span></code> and <code class="docutils literal notranslate"><span class="pre">tensorflow</span></code> might not always be the same</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">progressbar</span> <span class="kn">import</span> <span class="n">progressbar</span> <span class="k">as</span> <span class="n">pbar</span>

<span class="n">epochs</span> <span class="o">=</span> <span class="mi">4000</span>
<span class="n">learning_rate</span> <span class="o">=</span> <span class="mf">0.01</span>

<span class="c1"># symbolic variables</span>
<span class="n">w</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="mi">1</span><span class="p">),</span> <span class="n">scale</span><span class="o">=.</span><span class="mi">6</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">b</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,),</span> <span class="n">scale</span><span class="o">=.</span><span class="mi">6</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">h</span> <span class="o">=</span> <span class="p">[]</span>

<span class="c1">#optimization loop</span>
<span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="n">pbar</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">epochs</span><span class="p">)):</span>
    <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">GradientTape</span><span class="p">()</span> <span class="k">as</span> <span class="n">t</span><span class="p">:</span>
        <span class="n">preds</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">X</span><span class="p">,</span><span class="n">w</span><span class="p">)</span><span class="o">+</span><span class="n">b</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_mean</span><span class="p">(</span> <span class="p">(</span><span class="n">preds</span><span class="o">-</span><span class="n">y</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">))</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span>
        
    <span class="n">gw</span><span class="p">,</span> <span class="n">gb</span> <span class="o">=</span> <span class="n">t</span><span class="o">.</span><span class="n">gradient</span><span class="p">(</span><span class="n">loss</span><span class="p">,</span> <span class="p">[</span><span class="n">w</span><span class="p">,</span> <span class="n">b</span><span class="p">])</span>
    
    <span class="n">w</span><span class="o">.</span><span class="n">assign_sub</span><span class="p">(</span><span class="n">learning_rate</span> <span class="o">*</span> <span class="n">gw</span><span class="p">)</span>
    <span class="n">b</span><span class="o">.</span><span class="n">assign_sub</span><span class="p">(</span><span class="n">learning_rate</span> <span class="o">*</span> <span class="n">gb</span><span class="p">)</span>
    
    <span class="n">h</span><span class="o">.</span><span class="n">append</span><span class="p">([</span><span class="n">gw</span><span class="o">.</span><span class="n">numpy</span><span class="p">()[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">],</span> <span class="n">gb</span><span class="o">.</span><span class="n">numpy</span><span class="p">()[</span><span class="mi">0</span><span class="p">],</span> <span class="n">w</span><span class="o">.</span><span class="n">numpy</span><span class="p">()[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">],</span> <span class="n">b</span><span class="o">.</span><span class="n">numpy</span><span class="p">()[</span><span class="mi">0</span><span class="p">],</span> <span class="n">loss</span><span class="o">.</span><span class="n">numpy</span><span class="p">()])</span>
<span class="n">h</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">r_</span><span class="p">[</span><span class="n">h</span><span class="p">]</span>
<span class="nb">print</span> <span class="p">(</span><span class="n">b</span><span class="o">.</span><span class="n">numpy</span><span class="p">(),</span> <span class="n">w</span><span class="o">.</span><span class="n">numpy</span><span class="p">())</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>100% (4000 of 4000) |####################| Elapsed Time: 0:00:03 Time:  0:00:03
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[12.677747] [[-0.715652]]
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">rmse</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_mean</span><span class="p">((</span><span class="n">tf</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">X</span><span class="p">,</span><span class="n">w</span><span class="p">)</span><span class="o">+</span><span class="n">b</span><span class="o">-</span><span class="n">y</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span><span class="mi">2</span><span class="p">));</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">h</span><span class="p">[:,</span><span class="o">-</span><span class="mi">1</span><span class="p">]);</span> <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;step number&quot;</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;loss&quot;</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">();</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;RMSE </span><span class="si">%.3f</span><span class="s2">&quot;</span><span class="o">%</span><span class="k">rmse</span>);
<span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi">50</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(0.0, 50.0)
</pre></div>
</div>
<img alt="../_images/U3.02 - TF for symbolic computing_27_1.png" src="../_images/U3.02 - TF for symbolic computing_27_1.png" />
</div>
</div>
</div>
<div class="section" id="version-2-using-tf-function-to-speed-up">
<h2>Version 2: using <code class="docutils literal notranslate"><span class="pre">tf.function</span></code> to speed up<a class="headerlink" href="#version-2-using-tf-function-to-speed-up" title="Permalink to this headline">¶</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">epochs</span> <span class="o">=</span> <span class="mi">4000</span>

<span class="c1"># initialize weights</span>
<span class="n">w</span><span class="o">.</span><span class="n">assign</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span><span class="mi">1</span><span class="p">))</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span><span class="o">*.</span><span class="mi">6</span><span class="p">)</span> 
<span class="n">b</span><span class="o">.</span><span class="n">assign</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,))</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">))</span>

<span class="nd">@tf</span><span class="o">.</span><span class="n">function</span>
<span class="k">def</span> <span class="nf">get_gradient</span><span class="p">(</span><span class="n">w</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
    <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">GradientTape</span><span class="p">()</span> <span class="k">as</span> <span class="n">t</span><span class="p">:</span>
        <span class="n">preds</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">X</span><span class="p">,</span><span class="n">w</span><span class="p">)</span><span class="o">+</span><span class="n">b</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_mean</span><span class="p">(</span> <span class="p">(</span><span class="n">preds</span><span class="o">-</span><span class="n">y</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span>
        
    <span class="n">gw</span><span class="p">,</span> <span class="n">gb</span> <span class="o">=</span> <span class="n">t</span><span class="o">.</span><span class="n">gradient</span><span class="p">(</span><span class="n">loss</span><span class="p">,</span> <span class="p">[</span><span class="n">w</span><span class="p">,</span> <span class="n">b</span><span class="p">])</span>
    <span class="k">return</span> <span class="n">gw</span><span class="p">,</span> <span class="n">gb</span><span class="p">,</span> <span class="n">loss</span>

<span class="c1">#optimization loop</span>
<span class="n">h</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="n">pbar</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">epochs</span><span class="p">)):</span>
        
    <span class="n">gw</span><span class="p">,</span> <span class="n">gb</span><span class="p">,</span> <span class="n">loss</span> <span class="o">=</span> <span class="n">get_gradient</span><span class="p">(</span><span class="n">w</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">))</span>
    
    <span class="n">w</span><span class="o">.</span><span class="n">assign_sub</span><span class="p">(</span><span class="n">learning_rate</span> <span class="o">*</span> <span class="n">gw</span><span class="p">)</span>
    <span class="n">b</span><span class="o">.</span><span class="n">assign_sub</span><span class="p">(</span><span class="n">learning_rate</span> <span class="o">*</span> <span class="n">gb</span><span class="p">)</span>

    <span class="n">h</span><span class="o">.</span><span class="n">append</span><span class="p">([</span><span class="n">gw</span><span class="o">.</span><span class="n">numpy</span><span class="p">()[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">],</span> <span class="n">gb</span><span class="o">.</span><span class="n">numpy</span><span class="p">()[</span><span class="mi">0</span><span class="p">],</span> <span class="n">w</span><span class="o">.</span><span class="n">numpy</span><span class="p">()[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">],</span> <span class="n">b</span><span class="o">.</span><span class="n">numpy</span><span class="p">()[</span><span class="mi">0</span><span class="p">],</span> <span class="n">loss</span><span class="o">.</span><span class="n">numpy</span><span class="p">()])</span>
<span class="n">h</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">r_</span><span class="p">[</span><span class="n">h</span><span class="p">]</span>

<span class="nb">print</span> <span class="p">(</span><span class="n">b</span><span class="o">.</span><span class="n">numpy</span><span class="p">(),</span> <span class="n">w</span><span class="o">.</span><span class="n">numpy</span><span class="p">())</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>100% (4000 of 4000) |####################| Elapsed Time: 0:00:01 Time:  0:00:01
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[12.678027] [[-0.71570694]]
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">predictions</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">X</span><span class="p">,</span><span class="n">w</span><span class="p">)</span><span class="o">+</span><span class="n">b</span>

<span class="n">rmse</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_mean</span><span class="p">((</span><span class="n">predictions</span><span class="o">-</span><span class="n">y</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span><span class="mi">2</span><span class="p">));</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">h</span><span class="p">[:,</span><span class="o">-</span><span class="mi">1</span><span class="p">]);</span> <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;step number&quot;</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;loss&quot;</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">();</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;RMSE </span><span class="si">%.3f</span><span class="s2">&quot;</span><span class="o">%</span><span class="k">rmse</span>);
<span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi">50</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(0.0, 50.0)
</pre></div>
</div>
<img alt="../_images/U3.02 - TF for symbolic computing_30_1.png" src="../_images/U3.02 - TF for symbolic computing_30_1.png" />
</div>
</div>
</div>
<div class="section" id="version-3-using-batches-with-random-shuffling-stochastic-gradient-descent">
<h2>Version 3: using batches with random shuffling (stochastic gradient descent)<a class="headerlink" href="#version-3-using-batches-with-random-shuffling-stochastic-gradient-descent" title="Permalink to this headline">¶</a></h2>
<p>notice we tune the number of epochs as the number of weights updates increases</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#optimization loop</span>
<span class="n">batch_size</span> <span class="o">=</span> <span class="mi">16</span>
<span class="n">epochs</span> <span class="o">=</span> <span class="mi">400</span>

<span class="c1"># initialize weights</span>
<span class="n">w</span><span class="o">.</span><span class="n">assign</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span><span class="mi">1</span><span class="p">))</span><span class="o">*.</span><span class="mi">6</span><span class="p">)</span> 
<span class="n">b</span><span class="o">.</span><span class="n">assign</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,)))</span>

<span class="n">h</span> <span class="o">=</span> <span class="p">[]</span>

<span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="n">pbar</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">epochs</span><span class="p">)):</span>
    
    <span class="n">idxs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">permutation</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">X</span><span class="p">))</span>
    
    <span class="k">for</span> <span class="n">step</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">X</span><span class="p">)</span><span class="o">//</span><span class="n">batch_size</span><span class="o">+</span><span class="p">((</span><span class="nb">len</span><span class="p">(</span><span class="n">X</span><span class="p">)</span><span class="o">%</span><span class="k">batch_size</span>)!=0)):
        
        <span class="n">X_batch</span> <span class="o">=</span> <span class="n">X</span><span class="p">[</span><span class="n">idxs</span><span class="p">][</span><span class="n">step</span><span class="o">*</span><span class="n">batch_size</span><span class="p">:(</span><span class="n">step</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span><span class="o">*</span><span class="n">batch_size</span><span class="p">]</span>
        <span class="n">y_batch</span> <span class="o">=</span> <span class="n">y</span><span class="p">[</span><span class="n">idxs</span><span class="p">][</span><span class="n">step</span><span class="o">*</span><span class="n">batch_size</span><span class="p">:(</span><span class="n">step</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span><span class="o">*</span><span class="n">batch_size</span><span class="p">]</span>
        
        <span class="n">gw</span><span class="p">,</span> <span class="n">gb</span><span class="p">,</span> <span class="n">loss</span> <span class="o">=</span> <span class="n">get_gradient</span><span class="p">(</span><span class="n">w</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">X_batch</span><span class="p">,</span> <span class="n">y_batch</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">))</span>

        <span class="n">w</span><span class="o">.</span><span class="n">assign_sub</span><span class="p">(</span><span class="n">learning_rate</span> <span class="o">*</span> <span class="n">gw</span><span class="p">)</span>
        <span class="n">b</span><span class="o">.</span><span class="n">assign_sub</span><span class="p">(</span><span class="n">learning_rate</span> <span class="o">*</span> <span class="n">gb</span><span class="p">)</span>
        
        <span class="n">h</span><span class="o">.</span><span class="n">append</span><span class="p">([</span><span class="n">gw</span><span class="o">.</span><span class="n">numpy</span><span class="p">()[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">],</span> <span class="n">gb</span><span class="o">.</span><span class="n">numpy</span><span class="p">()[</span><span class="mi">0</span><span class="p">],</span> <span class="n">w</span><span class="o">.</span><span class="n">numpy</span><span class="p">()[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">],</span> <span class="n">b</span><span class="o">.</span><span class="n">numpy</span><span class="p">()[</span><span class="mi">0</span><span class="p">],</span> <span class="n">loss</span><span class="o">.</span><span class="n">numpy</span><span class="p">()])</span>
<span class="n">h</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">r_</span><span class="p">[</span><span class="n">h</span><span class="p">]</span>
<span class="nb">print</span> <span class="p">(</span><span class="n">b</span><span class="o">.</span><span class="n">numpy</span><span class="p">(),</span> <span class="n">w</span><span class="o">.</span><span class="n">numpy</span><span class="p">())</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>100% (400 of 400) |######################| Elapsed Time: 0:00:01 Time:  0:00:01
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[12.652696] [[-0.7733341]]
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">predictions</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">X</span><span class="p">,</span><span class="n">w</span><span class="p">)</span><span class="o">+</span><span class="n">b</span>

<span class="n">rmse</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_mean</span><span class="p">((</span><span class="n">predictions</span><span class="o">-</span><span class="n">y</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span><span class="mi">2</span><span class="p">));</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">h</span><span class="p">[:,</span><span class="o">-</span><span class="mi">1</span><span class="p">]);</span> <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;step number&quot;</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;loss&quot;</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">();</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;RMSE </span><span class="si">%.3f</span><span class="s2">&quot;</span><span class="o">%</span><span class="k">rmse</span>);
<span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi">50</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(0.0, 50.0)
</pre></div>
</div>
<img alt="../_images/U3.02 - TF for symbolic computing_33_1.png" src="../_images/U3.02 - TF for symbolic computing_33_1.png" />
</div>
</div>
</div>
<div class="section" id="version-4-packing-up-with-keras-class-api-and-custom-sgd">
<h2>Version 4: packing up with Keras <code class="docutils literal notranslate"><span class="pre">class</span></code> API  and custom SGD<a class="headerlink" href="#version-4-packing-up-with-keras-class-api-and-custom-sgd" title="Permalink to this headline">¶</a></h2>
<p>observe:</p>
<ul class="simple">
<li><p>the<code class="docutils literal notranslate"><span class="pre">build</span></code> method that is called by Keras whenever <code class="docutils literal notranslate"><span class="pre">input_shape</span></code> is known</p></li>
<li><p>we use <code class="docutils literal notranslate"><span class="pre">add_weight</span></code> so that our model weights are known to the Keras model framework (<code class="docutils literal notranslate"><span class="pre">trainable_variables</span></code>, <code class="docutils literal notranslate"><span class="pre">get_weights</span></code>, etc.)</p></li>
</ul>
<p>see <a class="reference external" href="https://www.tensorflow.org/guide/keras/custom_layers_and_models">here</a></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">LinearRegressionModel4</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">Model</span><span class="p">):</span>
    
    <span class="k">def</span> <span class="nf">build</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_shape</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">w</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">add_weight</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="n">input_shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="mi">1</span><span class="p">),</span> <span class="n">initializer</span><span class="o">=</span><span class="s1">&#39;random_normal&#39;</span><span class="p">,</span>
                                 <span class="n">trainable</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
        
        <span class="bp">self</span><span class="o">.</span><span class="n">b</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">add_weight</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,),</span> <span class="n">initializer</span><span class="o">=</span><span class="s1">&#39;random_normal&#39;</span><span class="p">,</span>
                                 <span class="n">trainable</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
        
    <span class="k">def</span> <span class="nf">call</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">tf</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">w</span><span class="p">)</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">b</span>
    
    <span class="nd">@tf</span><span class="o">.</span><span class="n">function</span>
    <span class="k">def</span> <span class="nf">get_gradient</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
        <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">GradientTape</span><span class="p">()</span> <span class="k">as</span> <span class="n">t</span><span class="p">:</span>
            <span class="n">loss</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_mean</span><span class="p">(</span> <span class="p">(</span><span class="bp">self</span><span class="p">(</span><span class="n">X</span><span class="p">)</span><span class="o">-</span><span class="n">y</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span>

        <span class="n">gw</span><span class="p">,</span> <span class="n">gb</span> <span class="o">=</span> <span class="n">t</span><span class="o">.</span><span class="n">gradient</span><span class="p">(</span><span class="n">loss</span><span class="p">,</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">w</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">b</span><span class="p">])</span>
        <span class="k">return</span> <span class="n">gw</span><span class="p">,</span> <span class="n">gb</span><span class="p">,</span> <span class="n">loss</span>

    <span class="k">def</span> <span class="nf">fit</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span><span class="n">y</span><span class="p">,</span> <span class="n">epochs</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">16</span><span class="p">,</span> <span class="n">learning_rate</span><span class="o">=</span><span class="mf">0.01</span><span class="p">):</span>
        <span class="n">y</span> <span class="o">=</span> <span class="n">y</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">h</span><span class="o">=</span><span class="p">[]</span>
        <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="n">pbar</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">epochs</span><span class="p">)):</span>
            <span class="n">idxs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">permutation</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">X</span><span class="p">))</span>
            <span class="k">for</span> <span class="n">step</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">X</span><span class="p">)</span><span class="o">//</span><span class="n">batch_size</span><span class="o">+</span><span class="p">((</span><span class="nb">len</span><span class="p">(</span><span class="n">X</span><span class="p">)</span><span class="o">%</span><span class="k">batch_size</span>)!=0)):
                <span class="n">X_batch</span> <span class="o">=</span> <span class="n">X</span><span class="p">[</span><span class="n">idxs</span><span class="p">][</span><span class="n">step</span><span class="o">*</span><span class="n">batch_size</span><span class="p">:(</span><span class="n">step</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span><span class="o">*</span><span class="n">batch_size</span><span class="p">]</span>
                <span class="n">y_batch</span> <span class="o">=</span> <span class="n">y</span><span class="p">[</span><span class="n">idxs</span><span class="p">][</span><span class="n">step</span><span class="o">*</span><span class="n">batch_size</span><span class="p">:(</span><span class="n">step</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span><span class="o">*</span><span class="n">batch_size</span><span class="p">]</span>            

                <span class="n">gw</span><span class="p">,</span> <span class="n">gb</span><span class="p">,</span> <span class="n">loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_gradient</span><span class="p">(</span><span class="n">X_batch</span><span class="p">,</span><span class="n">y_batch</span><span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">w</span><span class="o">.</span><span class="n">assign_sub</span><span class="p">(</span><span class="n">learning_rate</span> <span class="o">*</span> <span class="n">gw</span><span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">b</span><span class="o">.</span><span class="n">assign_sub</span><span class="p">(</span><span class="n">learning_rate</span> <span class="o">*</span> <span class="n">gb</span><span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">h</span><span class="o">.</span><span class="n">append</span><span class="p">([</span><span class="n">gw</span><span class="o">.</span><span class="n">numpy</span><span class="p">()[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">],</span> <span class="n">gb</span><span class="o">.</span><span class="n">numpy</span><span class="p">()[</span><span class="mi">0</span><span class="p">],</span> <span class="n">w</span><span class="o">.</span><span class="n">numpy</span><span class="p">()[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">],</span> <span class="n">b</span><span class="o">.</span><span class="n">numpy</span><span class="p">()[</span><span class="mi">0</span><span class="p">],</span> <span class="n">loss</span><span class="o">.</span><span class="n">numpy</span><span class="p">()])</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">h</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">r_</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">h</span><span class="p">]</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">LinearRegressionModel4</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<p>observe that we can use the object directly on data to get predictions</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">model</span><span class="p">(</span><span class="n">X</span><span class="p">[:</span><span class="mi">2</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;tf.Tensor: shape=(2, 1), dtype=float32, numpy=
array([[-0.04066426],
       [-0.04316743]], dtype=float32)&gt;
</pre></div>
</div>
</div>
</div>
<p>or with the  <code class="docutils literal notranslate"><span class="pre">.predict</span></code> method</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X</span><span class="p">[:</span><span class="mi">2</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([[-0.04066426],
       [-0.04316743]], dtype=float32)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">trainable_variables</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[&lt;tf.Variable &#39;linear_regression_model4/Variable:0&#39; shape=(1, 1) dtype=float32, numpy=array([[0.00150557]], dtype=float32)&gt;,
 &lt;tf.Variable &#39;linear_regression_model4/Variable:0&#39; shape=(1,) dtype=float32, numpy=array([-0.0464113], dtype=float32)&gt;]
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">get_weights</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[array([[0.00150557]], dtype=float32), array([-0.0464113], dtype=float32)]
</pre></div>
</div>
</div>
</div>
<p>and fit the model</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">400</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">16</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>100% (400 of 400) |######################| Elapsed Time: 0:00:02 Time:  0:00:02
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">b</span><span class="o">.</span><span class="n">numpy</span><span class="p">(),</span> <span class="n">model</span><span class="o">.</span><span class="n">w</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(array([12.6924925], dtype=float32), array([[-0.5818763]], dtype=float32))
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">predictions</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>

<span class="n">rmse</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_mean</span><span class="p">((</span><span class="n">predictions</span><span class="o">-</span><span class="n">y</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span><span class="mi">2</span><span class="p">));</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">h</span><span class="p">[:,</span><span class="o">-</span><span class="mi">1</span><span class="p">]);</span> <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;step number&quot;</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;loss&quot;</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">();</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;RMSE </span><span class="si">%.3f</span><span class="s2">&quot;</span><span class="o">%</span><span class="k">rmse</span>);
<span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi">50</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(0.0, 50.0)
</pre></div>
</div>
<img alt="../_images/U3.02 - TF for symbolic computing_46_1.png" src="../_images/U3.02 - TF for symbolic computing_46_1.png" />
</div>
</div>
</div>
<div class="section" id="version-5-sequential-keras-model-with-standard-loop">
<h2>Version 5: Sequential Keras model with standard loop<a class="headerlink" href="#version-5-sequential-keras-model-with-standard-loop" title="Permalink to this headline">¶</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">tensorflow.keras</span> <span class="kn">import</span> <span class="n">Sequential</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras.layers</span> <span class="kn">import</span> <span class="n">Dense</span>
    
<span class="k">def</span> <span class="nf">get_model5</span><span class="p">():</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">Sequential</span><span class="p">()</span>
    <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">input_shape</span><span class="o">=</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],),</span> <span class="n">activation</span><span class="o">=</span><span class="s2">&quot;linear&quot;</span><span class="p">))</span>
    <span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">optimizer</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">optimizers</span><span class="o">.</span><span class="n">SGD</span><span class="p">(</span><span class="n">learning_rate</span><span class="o">=</span><span class="mf">0.01</span><span class="p">),</span> 
                  <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;mean_absolute_error&quot;</span><span class="p">],</span>
                  <span class="n">loss</span><span class="o">=</span><span class="s2">&quot;mse&quot;</span><span class="p">)</span>
<span class="c1"># equivalent forms for loss    </span>
<span class="c1">#                  loss = lambda y_true, y_pred: tf.reduce_mean((y_true-y_pred)**2))</span>
<span class="c1">#                  loss=&quot;mean_squared_error&quot;)</span>
<span class="c1">#                  loss=tf.keras.metrics.mean_squared_error)</span>
    <span class="k">return</span> <span class="n">model</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
<span class="n">X_train</span><span class="p">,</span> <span class="n">X_val</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_val</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span><span class="n">y</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">),</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">)</span>
<span class="n">X_train</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">X_val</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">y_train</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">y_val</span><span class="o">.</span><span class="n">shape</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>((120, 1), (30, 1), (120, 1), (30, 1))
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">!</span>rm -rf logs
<span class="n">model</span> <span class="o">=</span> <span class="n">get_model5</span><span class="p">()</span>

<span class="n">tb_callback</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">callbacks</span><span class="o">.</span><span class="n">TensorBoard</span><span class="p">(</span><span class="s1">&#39;./logs&#39;</span><span class="p">,</span> <span class="n">update_freq</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span><span class="n">y_train</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> 
          <span class="n">callbacks</span><span class="o">=</span><span class="p">[</span><span class="n">tb_callback</span><span class="p">],</span> <span class="n">validation_data</span><span class="o">=</span><span class="p">(</span><span class="n">X_val</span><span class="p">,</span> <span class="n">y_val</span><span class="p">))</span>

<span class="n">model</span><span class="o">.</span><span class="n">weights</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[&lt;tf.Variable &#39;dense_12/kernel:0&#39; shape=(1, 1) dtype=float32, numpy=array([[-0.5444805]], dtype=float32)&gt;,
 &lt;tf.Variable &#39;dense_12/bias:0&#39; shape=(1,) dtype=float32, numpy=array([11.90973], dtype=float32)&gt;]
</pre></div>
</div>
</div>
</div>
<p>history is now logged only per epoch</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">history</span><span class="o">.</span><span class="n">history</span><span class="o">.</span><span class="n">keys</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>dict_keys([&#39;loss&#39;, &#39;mean_absolute_error&#39;, &#39;val_loss&#39;, &#39;val_mean_absolute_error&#39;])
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">predictions</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
<span class="n">rmse</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">((</span><span class="n">predictions</span><span class="o">-</span><span class="n">y</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span><span class="mi">2</span><span class="p">));</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">history</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="s2">&quot;val_loss&quot;</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;val&quot;</span><span class="p">);</span> 
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">history</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="s2">&quot;loss&quot;</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;train&quot;</span><span class="p">);</span> 
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;step number&quot;</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;loss&quot;</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">();</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;RMSE </span><span class="si">%.3f</span><span class="s2">&quot;</span><span class="o">%</span><span class="k">rmse</span>); plt.legend();
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/U3.02 - TF for symbolic computing_53_0.png" src="../_images/U3.02 - TF for symbolic computing_53_0.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">mae</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">predictions</span><span class="o">-</span><span class="n">y</span><span class="p">))</span>

<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span><span class="mi">2</span><span class="p">));</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">history</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="s2">&quot;val_mean_absolute_error&quot;</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;val&quot;</span><span class="p">);</span> 
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">history</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="s2">&quot;mean_absolute_error&quot;</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;train&quot;</span><span class="p">);</span> 
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;step number&quot;</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;MAE&quot;</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">();</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;MAE </span><span class="si">%.3f</span><span class="s2">&quot;</span><span class="o">%</span><span class="k">mae</span>); plt.legend();
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/U3.02 - TF for symbolic computing_54_0.png" src="../_images/U3.02 - TF for symbolic computing_54_0.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%</span><span class="k">tensorboard</span> --logdir logs
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html">
<iframe id="tensorboard-frame-f3cce0fed2838b5b" width="100%" height="800" frameborder="0">
</iframe>
<script>
  (function() {
    const frame = document.getElementById("tensorboard-frame-f3cce0fed2838b5b");
    const url = new URL("/", window.location);
    url.port = 6006;
    frame.src = url;
  })();
</script>
</div></div>
</div>
</div>
<div class="section" id="version-6-custom-model-with-keras-class-api-and-standard-loop">
<h2>Version 6: Custom model with Keras <code class="docutils literal notranslate"><span class="pre">class</span></code> API  and standard loop<a class="headerlink" href="#version-6-custom-model-with-keras-class-api-and-standard-loop" title="Permalink to this headline">¶</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">LinearRegressionModel6</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">Model</span><span class="p">):</span>
    
    <span class="k">def</span> <span class="nf">build</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_shape</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">w</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">add_weight</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="n">input_shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="mi">1</span><span class="p">),</span>
                                 <span class="n">initializer</span><span class="o">=</span><span class="s1">&#39;random_normal&#39;</span><span class="p">,</span>
                                 <span class="n">trainable</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
        
        <span class="bp">self</span><span class="o">.</span><span class="n">b</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">add_weight</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,),</span>
                                 <span class="n">initializer</span><span class="o">=</span><span class="s1">&#39;random_normal&#39;</span><span class="p">,</span>
                                 <span class="n">trainable</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
        
    <span class="k">def</span> <span class="nf">call</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">tf</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">w</span><span class="p">)</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">b</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">LinearRegressionModel6</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">!</span>rm -rf logs
<span class="n">model</span> <span class="o">=</span> <span class="n">LinearRegressionModel6</span><span class="p">()</span>
<span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">optimizer</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">optimizers</span><span class="o">.</span><span class="n">SGD</span><span class="p">(</span><span class="n">learning_rate</span><span class="o">=</span><span class="mf">0.02</span><span class="p">),</span> 
           <span class="n">loss</span><span class="o">=</span><span class="s2">&quot;mse&quot;</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;mean_absolute_error&#39;</span><span class="p">])</span>

<span class="n">tb_callback</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">callbacks</span><span class="o">.</span><span class="n">TensorBoard</span><span class="p">(</span><span class="s1">&#39;./logs&#39;</span><span class="p">,</span> <span class="n">update_freq</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>


<span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span><span class="n">y_train</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">callbacks</span><span class="o">=</span><span class="p">[</span><span class="n">tb_callback</span><span class="p">],</span> 
       <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">validation_data</span><span class="o">=</span><span class="p">(</span><span class="n">X_val</span><span class="p">,</span> <span class="n">y_val</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;tensorflow.python.keras.callbacks.History at 0x7fa1e8358f70&gt;
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">b</span><span class="o">.</span><span class="n">numpy</span><span class="p">(),</span> <span class="n">model</span><span class="o">.</span><span class="n">w</span><span class="o">.</span><span class="n">numpy</span><span class="p">()[</span><span class="mi">0</span><span class="p">]</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(array([12.178291], dtype=float32), array([-0.3399362], dtype=float32))
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">predictions</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
<span class="n">rmse</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">((</span><span class="n">predictions</span><span class="o">-</span><span class="n">y</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span><span class="mi">2</span><span class="p">));</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">history</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="s2">&quot;loss&quot;</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;train&quot;</span><span class="p">);</span> 
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">history</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="s2">&quot;val_loss&quot;</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;val&quot;</span><span class="p">);</span> 
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;step number&quot;</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;loss&quot;</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">();</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;RMSE </span><span class="si">%.3f</span><span class="s2">&quot;</span><span class="o">%</span><span class="k">rmse</span>); plt.legend();
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/U3.02 - TF for symbolic computing_62_0.png" src="../_images/U3.02 - TF for symbolic computing_62_0.png" />
</div>
</div>
</div>
<div class="section" id="version-7-using-train-step-rightarrow-control-loss-and-gradients-on-a-custom-model">
<h2>Version 7: Using <code class="docutils literal notranslate"><span class="pre">train_step</span></code> <span class="math notranslate nohighlight">\(\rightarrow\)</span> control loss and gradients on a custom model.<a class="headerlink" href="#version-7-using-train-step-rightarrow-control-loss-and-gradients-on-a-custom-model" title="Permalink to this headline">¶</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">LinearRegressionModel7</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">Model</span><span class="p">):</span>
    
    <span class="k">def</span> <span class="nf">build</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_shape</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">w</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">add_weight</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="n">input_shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="mi">1</span><span class="p">),</span>
                                 <span class="n">initializer</span><span class="o">=</span><span class="s1">&#39;random_normal&#39;</span><span class="p">,</span>
                                 <span class="n">trainable</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
        
        <span class="bp">self</span><span class="o">.</span><span class="n">b</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">add_weight</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,),</span>
                                 <span class="n">initializer</span><span class="o">=</span><span class="s1">&#39;random_normal&#39;</span><span class="p">,</span>
                                 <span class="n">trainable</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
        
        <span class="bp">self</span><span class="o">.</span><span class="n">loss_fn</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">metrics</span><span class="o">.</span><span class="n">MeanSquaredError</span><span class="p">()</span>
        
    <span class="k">def</span> <span class="nf">call</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">tf</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">w</span><span class="p">)</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">b</span>

    <span class="k">def</span> <span class="nf">test_step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data</span><span class="p">):</span>
        <span class="c1"># here we implement loss by hand</span>
        <span class="k">return</span> <span class="p">{</span><span class="s1">&#39;loss&#39;</span><span class="p">:</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_mean</span><span class="p">((</span><span class="bp">self</span><span class="p">(</span><span class="n">X</span><span class="p">)</span><span class="o">-</span><span class="n">y</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span>  <span class="p">}</span>
    
    <span class="k">def</span> <span class="nf">train_step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data</span><span class="p">):</span>
        <span class="n">X</span><span class="p">,</span><span class="n">y</span> <span class="o">=</span> <span class="n">data</span>
        <span class="n">loss_fn</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">y_true</span><span class="p">,</span> <span class="n">y_preds</span><span class="p">:</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_mean</span><span class="p">((</span><span class="n">y_true</span><span class="o">-</span><span class="n">y_preds</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span>
        <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">GradientTape</span><span class="p">()</span> <span class="k">as</span> <span class="n">tape</span><span class="p">:</span>
            <span class="c1"># we use tf.keras loss function (equivalent to test_step)</span>
            <span class="n">loss_fn</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">metrics</span><span class="o">.</span><span class="n">mean_squared_error</span>
            <span class="n">loss</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_mean</span><span class="p">(</span><span class="n">loss_fn</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="bp">self</span><span class="p">(</span><span class="n">X</span><span class="p">)))</span>
            
        <span class="n">grads</span> <span class="o">=</span> <span class="n">tape</span><span class="o">.</span><span class="n">gradient</span><span class="p">(</span><span class="n">loss</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">trainable_variables</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="o">.</span><span class="n">apply_gradients</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">grads</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">trainable_variables</span><span class="p">))</span>
        
        <span class="k">return</span> <span class="p">{</span><span class="s1">&#39;loss&#39;</span><span class="p">:</span> <span class="n">loss</span><span class="p">}</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">LinearRegressionModel7</span><span class="p">()</span>
<span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">optimizer</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">optimizers</span><span class="o">.</span><span class="n">SGD</span><span class="p">(</span><span class="n">learning_rate</span><span class="o">=</span><span class="mf">0.02</span><span class="p">))</span>
<span class="c1">#model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.035))</span>
<span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span><span class="n">y_train</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">400</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">validation_data</span><span class="o">=</span><span class="p">(</span><span class="n">X_val</span><span class="p">,</span> <span class="n">y_val</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 1/400
24/24 [==============================] - 0s 2ms/step - loss: 19.7392 - val_loss: 10.4111
Epoch 2/400
24/24 [==============================] - 0s 1ms/step - loss: 15.2234 - val_loss: 8.6261
Epoch 3/400
24/24 [==============================] - 0s 1ms/step - loss: 10.7889 - val_loss: 9.8276
Epoch 4/400
24/24 [==============================] - 0s 1ms/step - loss: 10.9684 - val_loss: 8.2490
Epoch 5/400
24/24 [==============================] - 0s 1ms/step - loss: 9.4847 - val_loss: 6.2752
Epoch 6/400
24/24 [==============================] - 0s 1ms/step - loss: 8.2953 - val_loss: 7.2160
Epoch 7/400
24/24 [==============================] - 0s 1ms/step - loss: 7.0421 - val_loss: 5.1518
Epoch 8/400
24/24 [==============================] - 0s 1ms/step - loss: 7.2380 - val_loss: 6.7480
Epoch 9/400
24/24 [==============================] - 0s 1ms/step - loss: 5.9134 - val_loss: 4.8136
Epoch 10/400
24/24 [==============================] - 0s 1ms/step - loss: 5.5916 - val_loss: 4.8190
Epoch 11/400
24/24 [==============================] - 0s 2ms/step - loss: 5.6332 - val_loss: 4.9578
Epoch 12/400
24/24 [==============================] - 0s 1ms/step - loss: 5.1534 - val_loss: 4.8727
Epoch 13/400
24/24 [==============================] - 0s 1ms/step - loss: 4.5951 - val_loss: 5.9803
Epoch 14/400
24/24 [==============================] - 0s 1ms/step - loss: 4.4587 - val_loss: 4.3159
Epoch 15/400
24/24 [==============================] - 0s 2ms/step - loss: 3.8799 - val_loss: 3.9435
Epoch 16/400
24/24 [==============================] - 0s 1ms/step - loss: 4.4901 - val_loss: 3.8532
Epoch 17/400
24/24 [==============================] - 0s 1ms/step - loss: 3.8850 - val_loss: 5.1911
Epoch 18/400
24/24 [==============================] - 0s 1ms/step - loss: 3.7412 - val_loss: 4.4341
Epoch 19/400
24/24 [==============================] - 0s 2ms/step - loss: 3.2783 - val_loss: 5.0278
Epoch 20/400
24/24 [==============================] - 0s 1ms/step - loss: 3.5729 - val_loss: 4.3133
Epoch 21/400
24/24 [==============================] - 0s 2ms/step - loss: 3.6199 - val_loss: 3.9117
Epoch 22/400
24/24 [==============================] - 0s 1ms/step - loss: 3.1410 - val_loss: 5.0487
Epoch 23/400
24/24 [==============================] - 0s 1ms/step - loss: 3.2920 - val_loss: 3.9479
Epoch 24/400
24/24 [==============================] - 0s 1ms/step - loss: 3.3921 - val_loss: 6.0462
Epoch 25/400
24/24 [==============================] - 0s 1ms/step - loss: 3.4760 - val_loss: 4.3797
Epoch 26/400
24/24 [==============================] - 0s 1ms/step - loss: 3.4015 - val_loss: 4.1026
Epoch 27/400
24/24 [==============================] - 0s 1ms/step - loss: 3.3626 - val_loss: 4.3933
Epoch 28/400
24/24 [==============================] - 0s 1ms/step - loss: 3.1681 - val_loss: 4.3973
Epoch 29/400
24/24 [==============================] - 0s 1ms/step - loss: 3.0594 - val_loss: 4.4612
Epoch 30/400
24/24 [==============================] - 0s 1ms/step - loss: 3.3908 - val_loss: 4.2964
Epoch 31/400
24/24 [==============================] - 0s 2ms/step - loss: 3.2458 - val_loss: 4.2169
Epoch 32/400
24/24 [==============================] - 0s 1ms/step - loss: 3.6394 - val_loss: 4.8273
Epoch 33/400
24/24 [==============================] - 0s 1ms/step - loss: 3.1401 - val_loss: 4.9958
Epoch 34/400
24/24 [==============================] - 0s 1ms/step - loss: 3.4363 - val_loss: 5.2287
Epoch 35/400
24/24 [==============================] - 0s 2ms/step - loss: 2.9438 - val_loss: 4.2773
Epoch 36/400
24/24 [==============================] - 0s 2ms/step - loss: 2.9743 - val_loss: 4.2949
Epoch 37/400
24/24 [==============================] - 0s 1ms/step - loss: 2.9537 - val_loss: 4.6139
Epoch 38/400
24/24 [==============================] - 0s 1ms/step - loss: 3.0173 - val_loss: 4.5316
Epoch 39/400
24/24 [==============================] - 0s 1ms/step - loss: 3.0289 - val_loss: 4.6343
Epoch 40/400
24/24 [==============================] - 0s 2ms/step - loss: 3.3441 - val_loss: 7.9945
Epoch 41/400
24/24 [==============================] - 0s 1ms/step - loss: 3.5563 - val_loss: 5.7548
Epoch 42/400
24/24 [==============================] - 0s 1ms/step - loss: 2.7597 - val_loss: 4.9217
Epoch 43/400
24/24 [==============================] - 0s 1ms/step - loss: 2.9478 - val_loss: 4.7706
Epoch 44/400
24/24 [==============================] - 0s 1ms/step - loss: 3.3478 - val_loss: 4.6335
Epoch 45/400
24/24 [==============================] - 0s 1ms/step - loss: 3.3791 - val_loss: 4.4372
Epoch 46/400
24/24 [==============================] - 0s 1ms/step - loss: 3.4539 - val_loss: 7.7787
Epoch 47/400
24/24 [==============================] - 0s 1ms/step - loss: 2.7407 - val_loss: 5.3994
Epoch 48/400
24/24 [==============================] - 0s 1ms/step - loss: 3.4352 - val_loss: 4.9649
Epoch 49/400
24/24 [==============================] - 0s 2ms/step - loss: 4.1122 - val_loss: 5.2514
Epoch 50/400
24/24 [==============================] - 0s 1ms/step - loss: 3.1711 - val_loss: 4.4675
Epoch 51/400
24/24 [==============================] - 0s 1ms/step - loss: 3.5676 - val_loss: 4.6743
Epoch 52/400
24/24 [==============================] - 0s 1ms/step - loss: 3.1220 - val_loss: 4.4666
Epoch 53/400
24/24 [==============================] - 0s 1ms/step - loss: 3.0218 - val_loss: 4.4582
Epoch 54/400
24/24 [==============================] - 0s 1ms/step - loss: 3.4140 - val_loss: 4.8568
Epoch 55/400
24/24 [==============================] - 0s 1ms/step - loss: 3.0205 - val_loss: 4.9430
Epoch 56/400
24/24 [==============================] - 0s 2ms/step - loss: 3.2665 - val_loss: 4.4619
Epoch 57/400
24/24 [==============================] - 0s 1ms/step - loss: 3.9618 - val_loss: 4.9073
Epoch 58/400
24/24 [==============================] - 0s 1ms/step - loss: 3.0169 - val_loss: 4.4747
Epoch 59/400
24/24 [==============================] - 0s 1ms/step - loss: 3.3913 - val_loss: 7.2588
Epoch 60/400
24/24 [==============================] - 0s 2ms/step - loss: 3.2529 - val_loss: 4.5038
Epoch 61/400
24/24 [==============================] - 0s 1ms/step - loss: 3.1832 - val_loss: 6.9207
Epoch 62/400
24/24 [==============================] - 0s 1ms/step - loss: 3.2498 - val_loss: 4.8948
Epoch 63/400
24/24 [==============================] - 0s 1ms/step - loss: 3.2428 - val_loss: 4.7427
Epoch 64/400
24/24 [==============================] - 0s 1ms/step - loss: 3.4436 - val_loss: 5.1191
Epoch 65/400
24/24 [==============================] - 0s 1ms/step - loss: 2.7977 - val_loss: 4.7401
Epoch 66/400
24/24 [==============================] - 0s 1ms/step - loss: 3.7056 - val_loss: 5.5702
Epoch 67/400
24/24 [==============================] - 0s 1ms/step - loss: 3.3288 - val_loss: 4.9020
Epoch 68/400
24/24 [==============================] - 0s 1ms/step - loss: 2.7759 - val_loss: 5.6655
Epoch 69/400
24/24 [==============================] - 0s 1ms/step - loss: 3.4451 - val_loss: 4.6816
Epoch 70/400
24/24 [==============================] - 0s 2ms/step - loss: 3.4565 - val_loss: 4.5651
Epoch 71/400
24/24 [==============================] - 0s 1ms/step - loss: 2.9854 - val_loss: 4.5724
Epoch 72/400
24/24 [==============================] - 0s 1ms/step - loss: 3.2057 - val_loss: 4.5086
Epoch 73/400
24/24 [==============================] - 0s 1ms/step - loss: 3.2468 - val_loss: 4.6927
Epoch 74/400
24/24 [==============================] - 0s 1ms/step - loss: 3.5859 - val_loss: 4.9658
Epoch 75/400
24/24 [==============================] - 0s 1ms/step - loss: 3.3227 - val_loss: 4.6295
Epoch 76/400
24/24 [==============================] - 0s 1ms/step - loss: 3.7073 - val_loss: 5.2158
Epoch 77/400
24/24 [==============================] - 0s 1ms/step - loss: 2.8412 - val_loss: 6.5702
Epoch 78/400
24/24 [==============================] - 0s 1ms/step - loss: 2.9827 - val_loss: 4.7727
Epoch 79/400
24/24 [==============================] - 0s 1ms/step - loss: 3.2151 - val_loss: 4.9094
Epoch 80/400
24/24 [==============================] - 0s 1ms/step - loss: 3.0994 - val_loss: 4.5208
Epoch 81/400
24/24 [==============================] - 0s 1ms/step - loss: 2.8900 - val_loss: 4.8496
Epoch 82/400
24/24 [==============================] - 0s 1ms/step - loss: 3.3511 - val_loss: 6.1091
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 83/400
24/24 [==============================] - 0s 1ms/step - loss: 3.5397 - val_loss: 5.4955
Epoch 84/400
24/24 [==============================] - 0s 1ms/step - loss: 3.3515 - val_loss: 4.7732
Epoch 85/400
24/24 [==============================] - 0s 1ms/step - loss: 3.2623 - val_loss: 4.5740
Epoch 86/400
24/24 [==============================] - 0s 1ms/step - loss: 2.7377 - val_loss: 5.3030
Epoch 87/400
24/24 [==============================] - 0s 1ms/step - loss: 3.4061 - val_loss: 4.5091
Epoch 88/400
24/24 [==============================] - 0s 1ms/step - loss: 3.5258 - val_loss: 6.3239
Epoch 89/400
24/24 [==============================] - 0s 1ms/step - loss: 2.7549 - val_loss: 4.5868
Epoch 90/400
24/24 [==============================] - 0s 2ms/step - loss: 3.5264 - val_loss: 4.6695
Epoch 91/400
24/24 [==============================] - 0s 1ms/step - loss: 3.2475 - val_loss: 4.8328
Epoch 92/400
24/24 [==============================] - 0s 1ms/step - loss: 3.6530 - val_loss: 4.6356
Epoch 93/400
24/24 [==============================] - 0s 1ms/step - loss: 3.6038 - val_loss: 4.5931
Epoch 94/400
24/24 [==============================] - 0s 1ms/step - loss: 3.6830 - val_loss: 4.5053
Epoch 95/400
24/24 [==============================] - 0s 1ms/step - loss: 3.8501 - val_loss: 5.5858
Epoch 96/400
24/24 [==============================] - 0s 1ms/step - loss: 3.1866 - val_loss: 4.6843
Epoch 97/400
24/24 [==============================] - 0s 1ms/step - loss: 3.1612 - val_loss: 5.2507
Epoch 98/400
24/24 [==============================] - 0s 1ms/step - loss: 3.2030 - val_loss: 5.0807
Epoch 99/400
24/24 [==============================] - 0s 1ms/step - loss: 3.0927 - val_loss: 7.1620
Epoch 100/400
24/24 [==============================] - 0s 1ms/step - loss: 3.3667 - val_loss: 4.6335
Epoch 101/400
24/24 [==============================] - 0s 1ms/step - loss: 3.3066 - val_loss: 6.1708
Epoch 102/400
24/24 [==============================] - 0s 1ms/step - loss: 3.3150 - val_loss: 4.6138
Epoch 103/400
24/24 [==============================] - 0s 1ms/step - loss: 3.1687 - val_loss: 4.8142
Epoch 104/400
24/24 [==============================] - 0s 1ms/step - loss: 2.8442 - val_loss: 4.5084
Epoch 105/400
24/24 [==============================] - 0s 1ms/step - loss: 3.3430 - val_loss: 4.6853
Epoch 106/400
24/24 [==============================] - 0s 1ms/step - loss: 3.3867 - val_loss: 5.9911
Epoch 107/400
24/24 [==============================] - 0s 1ms/step - loss: 3.1700 - val_loss: 5.2810
Epoch 108/400
24/24 [==============================] - 0s 1ms/step - loss: 3.1819 - val_loss: 4.5475
Epoch 109/400
24/24 [==============================] - 0s 1ms/step - loss: 2.9465 - val_loss: 4.9394
Epoch 110/400
24/24 [==============================] - 0s 1ms/step - loss: 2.8356 - val_loss: 5.0962
Epoch 111/400
24/24 [==============================] - 0s 1ms/step - loss: 3.0768 - val_loss: 5.4739
Epoch 112/400
24/24 [==============================] - 0s 1ms/step - loss: 2.9067 - val_loss: 4.8131
Epoch 113/400
24/24 [==============================] - 0s 1ms/step - loss: 3.4948 - val_loss: 5.0904
Epoch 114/400
24/24 [==============================] - 0s 1ms/step - loss: 2.9924 - val_loss: 4.5589
Epoch 115/400
24/24 [==============================] - 0s 1ms/step - loss: 3.4852 - val_loss: 6.0146
Epoch 116/400
24/24 [==============================] - 0s 1ms/step - loss: 3.0386 - val_loss: 5.7977
Epoch 117/400
24/24 [==============================] - 0s 1ms/step - loss: 2.9425 - val_loss: 4.6983
Epoch 118/400
24/24 [==============================] - 0s 1ms/step - loss: 3.2699 - val_loss: 4.6807
Epoch 119/400
24/24 [==============================] - 0s 1ms/step - loss: 2.8962 - val_loss: 4.6749
Epoch 120/400
24/24 [==============================] - 0s 2ms/step - loss: 3.1749 - val_loss: 5.3955
Epoch 121/400
24/24 [==============================] - 0s 1ms/step - loss: 3.3616 - val_loss: 4.5606
Epoch 122/400
24/24 [==============================] - 0s 1ms/step - loss: 3.0712 - val_loss: 4.8948
Epoch 123/400
24/24 [==============================] - 0s 1ms/step - loss: 3.1144 - val_loss: 4.7683
Epoch 124/400
24/24 [==============================] - 0s 1ms/step - loss: 3.4346 - val_loss: 7.5459
Epoch 125/400
24/24 [==============================] - 0s 1ms/step - loss: 3.0353 - val_loss: 5.7878
Epoch 126/400
24/24 [==============================] - 0s 1ms/step - loss: 3.1597 - val_loss: 4.5611
Epoch 127/400
24/24 [==============================] - 0s 1ms/step - loss: 2.8801 - val_loss: 5.8573
Epoch 128/400
24/24 [==============================] - 0s 1ms/step - loss: 2.6887 - val_loss: 4.8658
Epoch 129/400
24/24 [==============================] - 0s 1ms/step - loss: 3.5759 - val_loss: 4.5432
Epoch 130/400
24/24 [==============================] - 0s 1ms/step - loss: 2.8463 - val_loss: 6.5964
Epoch 131/400
24/24 [==============================] - 0s 1ms/step - loss: 3.4910 - val_loss: 6.3812
Epoch 132/400
24/24 [==============================] - 0s 1ms/step - loss: 3.4392 - val_loss: 6.3256
Epoch 133/400
24/24 [==============================] - 0s 1ms/step - loss: 3.8018 - val_loss: 4.6272
Epoch 134/400
24/24 [==============================] - 0s 1ms/step - loss: 3.1876 - val_loss: 7.1076
Epoch 135/400
24/24 [==============================] - 0s 1ms/step - loss: 3.5682 - val_loss: 4.5004
Epoch 136/400
24/24 [==============================] - 0s 1ms/step - loss: 3.3016 - val_loss: 6.9445
Epoch 137/400
24/24 [==============================] - 0s 1ms/step - loss: 3.1889 - val_loss: 5.3125
Epoch 138/400
24/24 [==============================] - 0s 1ms/step - loss: 2.9806 - val_loss: 7.6909
Epoch 139/400
24/24 [==============================] - 0s 1ms/step - loss: 3.5020 - val_loss: 5.0420
Epoch 140/400
24/24 [==============================] - 0s 1ms/step - loss: 3.8124 - val_loss: 4.8797
Epoch 141/400
24/24 [==============================] - 0s 1ms/step - loss: 3.3235 - val_loss: 4.5073
Epoch 142/400
24/24 [==============================] - 0s 1ms/step - loss: 2.8785 - val_loss: 4.6010
Epoch 143/400
24/24 [==============================] - 0s 1ms/step - loss: 3.2391 - val_loss: 6.4446
Epoch 144/400
24/24 [==============================] - 0s 1ms/step - loss: 3.6059 - val_loss: 4.9432
Epoch 145/400
24/24 [==============================] - 0s 1ms/step - loss: 3.2065 - val_loss: 5.0549
Epoch 146/400
24/24 [==============================] - 0s 1ms/step - loss: 3.3395 - val_loss: 4.5182
Epoch 147/400
24/24 [==============================] - 0s 1ms/step - loss: 2.9309 - val_loss: 4.5095
Epoch 148/400
24/24 [==============================] - 0s 1ms/step - loss: 2.8934 - val_loss: 4.7204
Epoch 149/400
24/24 [==============================] - 0s 1ms/step - loss: 3.4578 - val_loss: 4.5119
Epoch 150/400
24/24 [==============================] - 0s 2ms/step - loss: 3.3904 - val_loss: 5.6962
Epoch 151/400
24/24 [==============================] - 0s 1ms/step - loss: 3.6866 - val_loss: 4.5775
Epoch 152/400
24/24 [==============================] - 0s 1ms/step - loss: 3.2612 - val_loss: 4.6691
Epoch 153/400
24/24 [==============================] - 0s 1ms/step - loss: 3.1120 - val_loss: 4.9876
Epoch 154/400
24/24 [==============================] - 0s 1ms/step - loss: 2.9532 - val_loss: 4.6896
Epoch 155/400
24/24 [==============================] - ETA: 0s - loss: 2.516 - 0s 1ms/step - loss: 3.2643 - val_loss: 5.4275
Epoch 156/400
24/24 [==============================] - 0s 1ms/step - loss: 3.0292 - val_loss: 4.8675
Epoch 157/400
24/24 [==============================] - 0s 1ms/step - loss: 3.5638 - val_loss: 4.5890
Epoch 158/400
24/24 [==============================] - 0s 1ms/step - loss: 3.1299 - val_loss: 4.5080
Epoch 159/400
24/24 [==============================] - 0s 1ms/step - loss: 3.3519 - val_loss: 7.0146
Epoch 160/400
24/24 [==============================] - 0s 1ms/step - loss: 3.1137 - val_loss: 5.0695
Epoch 161/400
24/24 [==============================] - 0s 1ms/step - loss: 3.2704 - val_loss: 4.5803
Epoch 162/400
24/24 [==============================] - 0s 1ms/step - loss: 3.3876 - val_loss: 4.7727
Epoch 163/400
24/24 [==============================] - 0s 1ms/step - loss: 3.3395 - val_loss: 4.5124
Epoch 164/400
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>24/24 [==============================] - 0s 1ms/step - loss: 2.8845 - val_loss: 4.8283
Epoch 165/400
24/24 [==============================] - 0s 1ms/step - loss: 3.3455 - val_loss: 4.5163
Epoch 166/400
24/24 [==============================] - 0s 1ms/step - loss: 2.8819 - val_loss: 5.1928
Epoch 167/400
24/24 [==============================] - 0s 1ms/step - loss: 3.1929 - val_loss: 4.5233
Epoch 168/400
24/24 [==============================] - 0s 1ms/step - loss: 3.5894 - val_loss: 4.8337
Epoch 169/400
24/24 [==============================] - 0s 1ms/step - loss: 2.8694 - val_loss: 5.3370
Epoch 170/400
24/24 [==============================] - 0s 2ms/step - loss: 2.8987 - val_loss: 5.0009
Epoch 171/400
24/24 [==============================] - 0s 1ms/step - loss: 2.7175 - val_loss: 4.7158
Epoch 172/400
24/24 [==============================] - 0s 1ms/step - loss: 3.7135 - val_loss: 4.5945
Epoch 173/400
24/24 [==============================] - 0s 1ms/step - loss: 3.1345 - val_loss: 4.5773
Epoch 174/400
24/24 [==============================] - 0s 1ms/step - loss: 2.9386 - val_loss: 4.5236
Epoch 175/400
24/24 [==============================] - 0s 1ms/step - loss: 3.2435 - val_loss: 5.9493
Epoch 176/400
24/24 [==============================] - 0s 1ms/step - loss: 3.2182 - val_loss: 6.1944
Epoch 177/400
24/24 [==============================] - 0s 1ms/step - loss: 2.9015 - val_loss: 5.8570
Epoch 178/400
24/24 [==============================] - 0s 1ms/step - loss: 3.1011 - val_loss: 4.5530
Epoch 179/400
24/24 [==============================] - 0s 1ms/step - loss: 2.9844 - val_loss: 5.5220
Epoch 180/400
24/24 [==============================] - 0s 2ms/step - loss: 3.2049 - val_loss: 4.6271
Epoch 181/400
24/24 [==============================] - 0s 1ms/step - loss: 3.0110 - val_loss: 4.5138
Epoch 182/400
24/24 [==============================] - 0s 1ms/step - loss: 3.8618 - val_loss: 4.6078
Epoch 183/400
24/24 [==============================] - 0s 1ms/step - loss: 3.2053 - val_loss: 4.5245
Epoch 184/400
24/24 [==============================] - 0s 1ms/step - loss: 3.1814 - val_loss: 5.2283
Epoch 185/400
24/24 [==============================] - 0s 1ms/step - loss: 3.3795 - val_loss: 4.6877
Epoch 186/400
24/24 [==============================] - 0s 1ms/step - loss: 3.0450 - val_loss: 5.5809
Epoch 187/400
24/24 [==============================] - 0s 1ms/step - loss: 3.1582 - val_loss: 4.5125
Epoch 188/400
24/24 [==============================] - 0s 1ms/step - loss: 3.2430 - val_loss: 4.5194
Epoch 189/400
24/24 [==============================] - 0s 1ms/step - loss: 2.9169 - val_loss: 4.9333
Epoch 190/400
24/24 [==============================] - 0s 1ms/step - loss: 3.3987 - val_loss: 4.6466
Epoch 191/400
24/24 [==============================] - 0s 1ms/step - loss: 2.8916 - val_loss: 4.5423
Epoch 192/400
24/24 [==============================] - 0s 1ms/step - loss: 3.9451 - val_loss: 5.7230
Epoch 193/400
24/24 [==============================] - 0s 1ms/step - loss: 3.1298 - val_loss: 4.5125
Epoch 194/400
24/24 [==============================] - 0s 1ms/step - loss: 3.3270 - val_loss: 5.1920
Epoch 195/400
24/24 [==============================] - 0s 1ms/step - loss: 3.0649 - val_loss: 4.5469
Epoch 196/400
24/24 [==============================] - 0s 1ms/step - loss: 3.1232 - val_loss: 6.2043
Epoch 197/400
24/24 [==============================] - 0s 1ms/step - loss: 3.0997 - val_loss: 4.7738
Epoch 198/400
24/24 [==============================] - 0s 1ms/step - loss: 3.5372 - val_loss: 4.8251
Epoch 199/400
24/24 [==============================] - 0s 1ms/step - loss: 3.4170 - val_loss: 4.7807
Epoch 200/400
24/24 [==============================] - 0s 1ms/step - loss: 3.5425 - val_loss: 4.7432
Epoch 201/400
24/24 [==============================] - 0s 1ms/step - loss: 3.3470 - val_loss: 4.7877
Epoch 202/400
24/24 [==============================] - 0s 1ms/step - loss: 3.2214 - val_loss: 5.5992
Epoch 203/400
24/24 [==============================] - 0s 1ms/step - loss: 2.6001 - val_loss: 4.6124
Epoch 204/400
24/24 [==============================] - 0s 1ms/step - loss: 3.2993 - val_loss: 6.2180
Epoch 205/400
24/24 [==============================] - 0s 1ms/step - loss: 3.1760 - val_loss: 5.8198
Epoch 206/400
24/24 [==============================] - 0s 1ms/step - loss: 3.0746 - val_loss: 4.7517
Epoch 207/400
24/24 [==============================] - 0s 1ms/step - loss: 3.3766 - val_loss: 5.6967
Epoch 208/400
24/24 [==============================] - 0s 1ms/step - loss: 3.6978 - val_loss: 4.7565
Epoch 209/400
24/24 [==============================] - 0s 1ms/step - loss: 2.7913 - val_loss: 6.6847
Epoch 210/400
24/24 [==============================] - 0s 1ms/step - loss: 3.4315 - val_loss: 6.5851
Epoch 211/400
24/24 [==============================] - 0s 1ms/step - loss: 3.2956 - val_loss: 5.0404
Epoch 212/400
24/24 [==============================] - 0s 1ms/step - loss: 2.9676 - val_loss: 4.7026
Epoch 213/400
24/24 [==============================] - 0s 1ms/step - loss: 3.5559 - val_loss: 6.6526
Epoch 214/400
24/24 [==============================] - 0s 1ms/step - loss: 3.5592 - val_loss: 5.3328
Epoch 215/400
24/24 [==============================] - 0s 1ms/step - loss: 2.6976 - val_loss: 6.2850
Epoch 216/400
24/24 [==============================] - 0s 1ms/step - loss: 3.3441 - val_loss: 4.6234
Epoch 217/400
24/24 [==============================] - 0s 1ms/step - loss: 3.0833 - val_loss: 4.5054
Epoch 218/400
24/24 [==============================] - 0s 1ms/step - loss: 3.0032 - val_loss: 7.0869
Epoch 219/400
24/24 [==============================] - 0s 1ms/step - loss: 3.2830 - val_loss: 5.0555
Epoch 220/400
24/24 [==============================] - 0s 1ms/step - loss: 3.0997 - val_loss: 5.2512
Epoch 221/400
24/24 [==============================] - 0s 1ms/step - loss: 3.5652 - val_loss: 5.0776
Epoch 222/400
24/24 [==============================] - 0s 1ms/step - loss: 3.6324 - val_loss: 5.3082
Epoch 223/400
24/24 [==============================] - 0s 1ms/step - loss: 3.2891 - val_loss: 4.5564
Epoch 224/400
24/24 [==============================] - 0s 1ms/step - loss: 3.4125 - val_loss: 5.3875
Epoch 225/400
24/24 [==============================] - 0s 1ms/step - loss: 3.1813 - val_loss: 5.1677
Epoch 226/400
24/24 [==============================] - 0s 1ms/step - loss: 3.1562 - val_loss: 4.5691
Epoch 227/400
24/24 [==============================] - 0s 1ms/step - loss: 3.2534 - val_loss: 5.8852
Epoch 228/400
24/24 [==============================] - 0s 1ms/step - loss: 3.2889 - val_loss: 5.1724
Epoch 229/400
24/24 [==============================] - 0s 1ms/step - loss: 2.9852 - val_loss: 4.9638
Epoch 230/400
24/24 [==============================] - 0s 1ms/step - loss: 3.0871 - val_loss: 5.0486
Epoch 231/400
24/24 [==============================] - 0s 1ms/step - loss: 3.8857 - val_loss: 6.4125
Epoch 232/400
24/24 [==============================] - 0s 1ms/step - loss: 2.9555 - val_loss: 5.4675
Epoch 233/400
24/24 [==============================] - 0s 1ms/step - loss: 2.7521 - val_loss: 5.5031
Epoch 234/400
24/24 [==============================] - 0s 1ms/step - loss: 2.8845 - val_loss: 4.9184
Epoch 235/400
24/24 [==============================] - 0s 1ms/step - loss: 2.8961 - val_loss: 5.2964
Epoch 236/400
24/24 [==============================] - 0s 1ms/step - loss: 3.4282 - val_loss: 5.1695
Epoch 237/400
24/24 [==============================] - ETA: 0s - loss: 6.991 - 0s 1ms/step - loss: 3.1710 - val_loss: 7.2873
Epoch 238/400
24/24 [==============================] - 0s 1ms/step - loss: 3.4732 - val_loss: 5.3854
Epoch 239/400
24/24 [==============================] - 0s 1ms/step - loss: 3.1505 - val_loss: 5.3578
Epoch 240/400
24/24 [==============================] - 0s 2ms/step - loss: 2.8412 - val_loss: 6.3642
Epoch 241/400
24/24 [==============================] - 0s 1ms/step - loss: 3.1505 - val_loss: 6.1352
Epoch 242/400
24/24 [==============================] - 0s 1ms/step - loss: 2.8444 - val_loss: 4.5288
Epoch 243/400
24/24 [==============================] - 0s 1ms/step - loss: 3.5304 - val_loss: 4.9148
Epoch 244/400
24/24 [==============================] - 0s 1ms/step - loss: 2.9437 - val_loss: 4.8567
Epoch 245/400
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>24/24 [==============================] - 0s 1ms/step - loss: 3.4456 - val_loss: 4.9064
Epoch 246/400
24/24 [==============================] - 0s 1ms/step - loss: 2.9256 - val_loss: 4.5851
Epoch 247/400
24/24 [==============================] - 0s 1ms/step - loss: 3.3140 - val_loss: 4.8369
Epoch 248/400
24/24 [==============================] - 0s 1ms/step - loss: 3.2571 - val_loss: 4.8283
Epoch 249/400
24/24 [==============================] - 0s 1ms/step - loss: 3.6508 - val_loss: 4.7139
Epoch 250/400
24/24 [==============================] - 0s 2ms/step - loss: 3.0250 - val_loss: 4.6851
Epoch 251/400
24/24 [==============================] - 0s 1ms/step - loss: 3.2481 - val_loss: 4.5649
Epoch 252/400
24/24 [==============================] - 0s 1ms/step - loss: 3.0071 - val_loss: 4.8930
Epoch 253/400
24/24 [==============================] - 0s 1ms/step - loss: 3.7613 - val_loss: 4.9439
Epoch 254/400
24/24 [==============================] - 0s 1ms/step - loss: 3.2931 - val_loss: 4.7106
Epoch 255/400
24/24 [==============================] - 0s 1ms/step - loss: 2.9258 - val_loss: 4.9721
Epoch 256/400
24/24 [==============================] - 0s 1ms/step - loss: 2.9071 - val_loss: 5.2074
Epoch 257/400
24/24 [==============================] - 0s 1ms/step - loss: 2.9952 - val_loss: 6.2338
Epoch 258/400
24/24 [==============================] - 0s 1ms/step - loss: 3.5967 - val_loss: 4.5942
Epoch 259/400
24/24 [==============================] - 0s 1ms/step - loss: 3.1790 - val_loss: 4.5631
Epoch 260/400
24/24 [==============================] - 0s 2ms/step - loss: 3.0022 - val_loss: 4.6645
Epoch 261/400
24/24 [==============================] - 0s 1ms/step - loss: 3.2457 - val_loss: 4.9213
Epoch 262/400
24/24 [==============================] - 0s 1ms/step - loss: 3.1038 - val_loss: 4.5222
Epoch 263/400
24/24 [==============================] - 0s 1ms/step - loss: 3.3526 - val_loss: 5.1351
Epoch 264/400
24/24 [==============================] - 0s 1ms/step - loss: 3.2454 - val_loss: 4.8370
Epoch 265/400
24/24 [==============================] - 0s 1ms/step - loss: 3.0049 - val_loss: 4.9374
Epoch 266/400
24/24 [==============================] - 0s 1ms/step - loss: 2.8983 - val_loss: 4.5287
Epoch 267/400
24/24 [==============================] - 0s 1ms/step - loss: 2.7920 - val_loss: 4.5661
Epoch 268/400
24/24 [==============================] - 0s 1ms/step - loss: 3.0345 - val_loss: 4.8191
Epoch 269/400
24/24 [==============================] - 0s 2ms/step - loss: 2.8817 - val_loss: 5.0568
Epoch 270/400
24/24 [==============================] - 0s 2ms/step - loss: 2.9873 - val_loss: 4.5337
Epoch 271/400
24/24 [==============================] - 0s 1ms/step - loss: 3.2966 - val_loss: 5.3696
Epoch 272/400
24/24 [==============================] - 0s 1ms/step - loss: 3.4022 - val_loss: 5.1148
Epoch 273/400
24/24 [==============================] - 0s 2ms/step - loss: 3.1639 - val_loss: 4.6669
Epoch 274/400
24/24 [==============================] - 0s 1ms/step - loss: 3.0287 - val_loss: 5.1569
Epoch 275/400
24/24 [==============================] - 0s 1ms/step - loss: 2.9712 - val_loss: 8.2092
Epoch 276/400
24/24 [==============================] - 0s 1ms/step - loss: 3.5930 - val_loss: 6.9999
Epoch 277/400
24/24 [==============================] - 0s 1ms/step - loss: 3.2499 - val_loss: 6.5855
Epoch 278/400
24/24 [==============================] - 0s 1ms/step - loss: 3.6112 - val_loss: 4.8626
Epoch 279/400
24/24 [==============================] - 0s 1ms/step - loss: 3.0971 - val_loss: 6.4404
Epoch 280/400
24/24 [==============================] - 0s 1ms/step - loss: 3.7170 - val_loss: 4.7717
Epoch 281/400
24/24 [==============================] - 0s 1ms/step - loss: 3.3751 - val_loss: 5.0465
Epoch 282/400
24/24 [==============================] - 0s 1ms/step - loss: 2.9713 - val_loss: 5.8153
Epoch 283/400
24/24 [==============================] - 0s 1ms/step - loss: 3.0481 - val_loss: 4.6912
Epoch 284/400
24/24 [==============================] - 0s 1ms/step - loss: 3.0906 - val_loss: 4.5264
Epoch 285/400
24/24 [==============================] - 0s 1ms/step - loss: 2.9897 - val_loss: 5.0227
Epoch 286/400
24/24 [==============================] - 0s 1ms/step - loss: 2.9813 - val_loss: 5.2658
Epoch 287/400
24/24 [==============================] - 0s 1ms/step - loss: 3.0341 - val_loss: 6.4348
Epoch 288/400
24/24 [==============================] - 0s 1ms/step - loss: 2.9439 - val_loss: 4.7360
Epoch 289/400
24/24 [==============================] - 0s 1ms/step - loss: 2.9886 - val_loss: 4.5372
Epoch 290/400
24/24 [==============================] - 0s 1ms/step - loss: 3.2938 - val_loss: 4.5678
Epoch 291/400
24/24 [==============================] - 0s 1ms/step - loss: 3.1344 - val_loss: 5.1717
Epoch 292/400
24/24 [==============================] - 0s 1ms/step - loss: 2.7215 - val_loss: 4.8224
Epoch 293/400
24/24 [==============================] - 0s 1ms/step - loss: 3.0839 - val_loss: 4.5141
Epoch 294/400
24/24 [==============================] - 0s 1ms/step - loss: 3.2527 - val_loss: 5.0322
Epoch 295/400
24/24 [==============================] - 0s 1ms/step - loss: 3.0858 - val_loss: 4.5309
Epoch 296/400
24/24 [==============================] - 0s 1ms/step - loss: 3.0333 - val_loss: 4.6329
Epoch 297/400
24/24 [==============================] - 0s 1ms/step - loss: 3.7716 - val_loss: 4.9677
Epoch 298/400
24/24 [==============================] - 0s 1ms/step - loss: 3.2222 - val_loss: 5.7610
Epoch 299/400
24/24 [==============================] - 0s 1ms/step - loss: 3.3510 - val_loss: 4.7178
Epoch 300/400
24/24 [==============================] - 0s 2ms/step - loss: 3.2460 - val_loss: 6.4251
Epoch 301/400
24/24 [==============================] - 0s 1ms/step - loss: 3.7770 - val_loss: 5.4635
Epoch 302/400
24/24 [==============================] - 0s 1ms/step - loss: 3.5653 - val_loss: 4.5456
Epoch 303/400
24/24 [==============================] - 0s 1ms/step - loss: 3.3741 - val_loss: 4.4877
Epoch 304/400
24/24 [==============================] - 0s 1ms/step - loss: 3.0304 - val_loss: 5.0502
Epoch 305/400
24/24 [==============================] - 0s 1ms/step - loss: 3.1638 - val_loss: 4.4903
Epoch 306/400
24/24 [==============================] - 0s 1ms/step - loss: 2.6095 - val_loss: 5.4170
Epoch 307/400
24/24 [==============================] - 0s 1ms/step - loss: 3.4339 - val_loss: 4.9049
Epoch 308/400
24/24 [==============================] - 0s 1ms/step - loss: 2.9716 - val_loss: 4.5272
Epoch 309/400
24/24 [==============================] - 0s 1ms/step - loss: 3.1444 - val_loss: 4.8777
Epoch 310/400
24/24 [==============================] - 0s 1ms/step - loss: 2.7741 - val_loss: 4.5906
Epoch 311/400
24/24 [==============================] - 0s 1ms/step - loss: 3.1414 - val_loss: 4.8848
Epoch 312/400
24/24 [==============================] - 0s 1ms/step - loss: 3.5413 - val_loss: 8.1215
Epoch 313/400
24/24 [==============================] - 0s 1ms/step - loss: 3.3083 - val_loss: 4.5732
Epoch 314/400
24/24 [==============================] - 0s 1ms/step - loss: 2.9486 - val_loss: 4.8381
Epoch 315/400
24/24 [==============================] - 0s 1ms/step - loss: 2.9268 - val_loss: 4.5132
Epoch 316/400
24/24 [==============================] - 0s 1ms/step - loss: 2.6872 - val_loss: 4.6124
Epoch 317/400
24/24 [==============================] - 0s 1ms/step - loss: 2.8528 - val_loss: 5.0954
Epoch 318/400
24/24 [==============================] - 0s 1ms/step - loss: 3.0860 - val_loss: 6.5249
Epoch 319/400
24/24 [==============================] - 0s 1ms/step - loss: 3.5809 - val_loss: 4.8388
Epoch 320/400
24/24 [==============================] - 0s 1ms/step - loss: 3.5726 - val_loss: 4.6098
Epoch 321/400
24/24 [==============================] - 0s 1ms/step - loss: 3.8006 - val_loss: 4.6081
Epoch 322/400
24/24 [==============================] - 0s 1ms/step - loss: 3.1549 - val_loss: 5.5604
Epoch 323/400
24/24 [==============================] - 0s 1ms/step - loss: 3.0366 - val_loss: 4.5582
Epoch 324/400
24/24 [==============================] - 0s 1ms/step - loss: 3.4456 - val_loss: 6.8731
Epoch 325/400
24/24 [==============================] - 0s 1ms/step - loss: 3.2296 - val_loss: 5.1777
Epoch 326/400
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>24/24 [==============================] - 0s 1ms/step - loss: 2.9151 - val_loss: 6.2347
Epoch 327/400
24/24 [==============================] - 0s 1ms/step - loss: 2.9756 - val_loss: 4.5187
Epoch 328/400
24/24 [==============================] - 0s 1ms/step - loss: 3.9403 - val_loss: 4.6651
Epoch 329/400
24/24 [==============================] - 0s 1ms/step - loss: 3.2621 - val_loss: 4.5243
Epoch 330/400
24/24 [==============================] - 0s 1ms/step - loss: 3.0554 - val_loss: 5.1681
Epoch 331/400
24/24 [==============================] - 0s 1ms/step - loss: 3.6799 - val_loss: 4.9799
Epoch 332/400
24/24 [==============================] - 0s 1ms/step - loss: 3.0299 - val_loss: 4.5008
Epoch 333/400
24/24 [==============================] - 0s 1ms/step - loss: 3.1639 - val_loss: 4.7375
Epoch 334/400
24/24 [==============================] - 0s 1ms/step - loss: 3.0940 - val_loss: 4.5052
Epoch 335/400
24/24 [==============================] - 0s 1ms/step - loss: 3.4677 - val_loss: 4.7556
Epoch 336/400
24/24 [==============================] - 0s 1ms/step - loss: 3.2755 - val_loss: 8.5235
Epoch 337/400
24/24 [==============================] - 0s 1ms/step - loss: 3.4908 - val_loss: 4.8687
Epoch 338/400
24/24 [==============================] - 0s 1ms/step - loss: 2.8486 - val_loss: 4.6473
Epoch 339/400
24/24 [==============================] - 0s 1ms/step - loss: 3.3363 - val_loss: 4.7819
Epoch 340/400
24/24 [==============================] - 0s 1ms/step - loss: 3.1961 - val_loss: 5.8207
Epoch 341/400
24/24 [==============================] - 0s 1ms/step - loss: 4.0682 - val_loss: 4.9453
Epoch 342/400
24/24 [==============================] - 0s 1ms/step - loss: 3.1707 - val_loss: 4.7592
Epoch 343/400
24/24 [==============================] - 0s 1ms/step - loss: 3.3303 - val_loss: 5.1973
Epoch 344/400
24/24 [==============================] - 0s 1ms/step - loss: 3.3304 - val_loss: 5.1652
Epoch 345/400
24/24 [==============================] - 0s 1ms/step - loss: 2.8000 - val_loss: 4.7183
Epoch 346/400
24/24 [==============================] - 0s 1ms/step - loss: 3.4231 - val_loss: 5.1706
Epoch 347/400
24/24 [==============================] - 0s 1ms/step - loss: 3.5406 - val_loss: 6.7287
Epoch 348/400
24/24 [==============================] - 0s 1ms/step - loss: 3.6553 - val_loss: 4.7983
Epoch 349/400
24/24 [==============================] - 0s 1ms/step - loss: 3.4701 - val_loss: 4.5108
Epoch 350/400
24/24 [==============================] - 0s 1ms/step - loss: 3.5020 - val_loss: 4.9899
Epoch 351/400
24/24 [==============================] - 0s 1ms/step - loss: 3.1496 - val_loss: 4.6589
Epoch 352/400
24/24 [==============================] - 0s 1ms/step - loss: 3.0850 - val_loss: 6.3351
Epoch 353/400
24/24 [==============================] - 0s 1ms/step - loss: 3.5102 - val_loss: 6.2340
Epoch 354/400
24/24 [==============================] - 0s 1ms/step - loss: 3.2017 - val_loss: 4.5220
Epoch 355/400
24/24 [==============================] - 0s 1ms/step - loss: 2.9720 - val_loss: 4.8878
Epoch 356/400
24/24 [==============================] - 0s 1ms/step - loss: 3.0545 - val_loss: 4.5907
Epoch 357/400
24/24 [==============================] - 0s 1ms/step - loss: 3.1901 - val_loss: 7.6787
Epoch 358/400
24/24 [==============================] - 0s 1ms/step - loss: 4.2209 - val_loss: 7.5607
Epoch 359/400
24/24 [==============================] - 0s 1ms/step - loss: 3.2610 - val_loss: 5.2355
Epoch 360/400
24/24 [==============================] - 0s 1ms/step - loss: 3.3522 - val_loss: 6.5614
Epoch 361/400
24/24 [==============================] - 0s 1ms/step - loss: 3.4958 - val_loss: 5.2501
Epoch 362/400
24/24 [==============================] - 0s 1ms/step - loss: 2.9216 - val_loss: 4.4845
Epoch 363/400
24/24 [==============================] - 0s 1ms/step - loss: 3.8385 - val_loss: 5.2525
Epoch 364/400
24/24 [==============================] - 0s 1ms/step - loss: 3.0932 - val_loss: 5.8102
Epoch 365/400
24/24 [==============================] - 0s 1ms/step - loss: 2.6340 - val_loss: 4.9525
Epoch 366/400
24/24 [==============================] - 0s 1ms/step - loss: 3.8410 - val_loss: 6.1945
Epoch 367/400
24/24 [==============================] - 0s 1ms/step - loss: 2.9822 - val_loss: 4.5271
Epoch 368/400
24/24 [==============================] - 0s 1ms/step - loss: 3.2659 - val_loss: 4.7355
Epoch 369/400
24/24 [==============================] - 0s 1ms/step - loss: 3.0818 - val_loss: 4.5593
Epoch 370/400
24/24 [==============================] - 0s 1ms/step - loss: 2.9521 - val_loss: 4.6371
Epoch 371/400
24/24 [==============================] - 0s 1ms/step - loss: 2.8998 - val_loss: 4.7987
Epoch 372/400
24/24 [==============================] - 0s 1ms/step - loss: 3.3982 - val_loss: 7.1434
Epoch 373/400
24/24 [==============================] - 0s 1ms/step - loss: 3.1357 - val_loss: 4.6521
Epoch 374/400
24/24 [==============================] - 0s 1ms/step - loss: 3.0701 - val_loss: 4.9505
Epoch 375/400
24/24 [==============================] - 0s 1ms/step - loss: 3.2118 - val_loss: 5.9603
Epoch 376/400
24/24 [==============================] - 0s 1ms/step - loss: 2.8714 - val_loss: 4.5610
Epoch 377/400
24/24 [==============================] - 0s 1ms/step - loss: 3.0741 - val_loss: 4.5655
Epoch 378/400
24/24 [==============================] - 0s 1ms/step - loss: 2.9147 - val_loss: 5.1252
Epoch 379/400
24/24 [==============================] - 0s 1ms/step - loss: 3.3136 - val_loss: 4.8565
Epoch 380/400
24/24 [==============================] - 0s 1ms/step - loss: 2.8233 - val_loss: 4.5308
Epoch 381/400
24/24 [==============================] - 0s 1ms/step - loss: 3.0940 - val_loss: 5.4559
Epoch 382/400
24/24 [==============================] - 0s 1ms/step - loss: 2.7085 - val_loss: 5.5234
Epoch 383/400
24/24 [==============================] - 0s 1ms/step - loss: 3.3648 - val_loss: 4.6329
Epoch 384/400
24/24 [==============================] - 0s 1ms/step - loss: 2.9839 - val_loss: 5.2792
Epoch 385/400
24/24 [==============================] - 0s 1ms/step - loss: 2.9126 - val_loss: 4.9616
Epoch 386/400
24/24 [==============================] - 0s 1ms/step - loss: 3.0359 - val_loss: 6.0464
Epoch 387/400
24/24 [==============================] - 0s 1ms/step - loss: 2.9036 - val_loss: 4.5359
Epoch 388/400
24/24 [==============================] - 0s 1ms/step - loss: 3.0232 - val_loss: 5.7742
Epoch 389/400
24/24 [==============================] - 0s 1ms/step - loss: 3.8014 - val_loss: 5.8940
Epoch 390/400
24/24 [==============================] - 0s 1ms/step - loss: 3.4787 - val_loss: 4.5703
Epoch 391/400
24/24 [==============================] - 0s 1ms/step - loss: 3.2001 - val_loss: 4.5262
Epoch 392/400
24/24 [==============================] - 0s 1ms/step - loss: 3.3495 - val_loss: 4.5869
Epoch 393/400
24/24 [==============================] - 0s 1ms/step - loss: 3.3612 - val_loss: 5.9375
Epoch 394/400
24/24 [==============================] - 0s 1ms/step - loss: 3.0854 - val_loss: 6.1935
Epoch 395/400
24/24 [==============================] - 0s 1ms/step - loss: 2.8251 - val_loss: 4.6047
Epoch 396/400
24/24 [==============================] - 0s 1ms/step - loss: 2.7991 - val_loss: 4.6788
Epoch 397/400
24/24 [==============================] - 0s 1ms/step - loss: 3.1593 - val_loss: 4.9373
Epoch 398/400
24/24 [==============================] - 0s 1ms/step - loss: 3.2137 - val_loss: 4.6710
Epoch 399/400
24/24 [==============================] - 0s 1ms/step - loss: 3.4695 - val_loss: 4.5911
Epoch 400/400
24/24 [==============================] - 0s 1ms/step - loss: 2.7998 - val_loss: 4.7009
</pre></div>
</div>
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;tensorflow.python.keras.callbacks.History at 0x7fa1aa8dd190&gt;
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="p">[</span><span class="n">i</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">model</span><span class="o">.</span><span class="n">trainable_variables</span><span class="p">]</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[array([[-0.62764317]], dtype=float32), array([12.133042], dtype=float32)]
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">predictions</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
<span class="n">rmse</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">((</span><span class="n">predictions</span><span class="o">-</span><span class="n">y</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span><span class="mi">2</span><span class="p">));</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">history</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="s2">&quot;loss&quot;</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;train&quot;</span><span class="p">);</span> 
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">history</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="s2">&quot;val_loss&quot;</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;val&quot;</span><span class="p">);</span> 
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;step number&quot;</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;loss&quot;</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">();</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;RMSE </span><span class="si">%.3f</span><span class="s2">&quot;</span><span class="o">%</span><span class="k">rmse</span>); plt.legend();
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/U3.02 - TF for symbolic computing_69_0.png" src="../_images/U3.02 - TF for symbolic computing_69_0.png" />
</div>
</div>
</div>
<div class="section" id="version-8-using-train-step-rightarrow-control-loss-and-gradients-on-a-standard-model">
<h2>Version 8: Using <code class="docutils literal notranslate"><span class="pre">train_step</span></code> <span class="math notranslate nohighlight">\(\rightarrow\)</span> control loss and gradients on a standard model.<a class="headerlink" href="#version-8-using-train-step-rightarrow-control-loss-and-gradients-on-a-standard-model" title="Permalink to this headline">¶</a></h2>
<p>observe that:</p>
<ul class="simple">
<li><p>we use a standard <code class="docutils literal notranslate"><span class="pre">Dense</span></code> layer,</p></li>
<li><p>we use a custom loss function and <code class="docutils literal notranslate"><span class="pre">optimizer.apply_gradients</span></code></p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">CustomModel</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">Model</span><span class="p">):</span>
    
    <span class="k">def</span> <span class="nf">test_step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data</span><span class="p">):</span>
        <span class="k">return</span> <span class="p">{</span><span class="s1">&#39;loss&#39;</span><span class="p">:</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_mean</span><span class="p">((</span><span class="bp">self</span><span class="p">(</span><span class="n">X</span><span class="p">)</span><span class="o">-</span><span class="n">y</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span><span class="p">)}</span>    
    
    <span class="k">def</span> <span class="nf">train_step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data</span><span class="p">):</span>
        <span class="n">X</span><span class="p">,</span><span class="n">y</span> <span class="o">=</span> <span class="n">data</span>
        
        <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">GradientTape</span><span class="p">()</span> <span class="k">as</span> <span class="n">tape</span><span class="p">:</span>
            <span class="n">y_pred</span> <span class="o">=</span> <span class="bp">self</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">training</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
            <span class="n">loss_value</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_mean</span><span class="p">((</span><span class="n">y_pred</span><span class="o">-</span><span class="n">y</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span>
            
        <span class="n">grads</span> <span class="o">=</span> <span class="n">tape</span><span class="o">.</span><span class="n">gradient</span><span class="p">(</span><span class="n">loss_value</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">trainable_variables</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="o">.</span><span class="n">apply_gradients</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">grads</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">trainable_variables</span><span class="p">))</span>
        
        <span class="k">return</span> <span class="p">{</span><span class="s1">&#39;loss&#39;</span><span class="p">:</span> <span class="n">loss_value</span><span class="p">}</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">tensorflow.keras.layers</span> <span class="kn">import</span> <span class="n">Dense</span><span class="p">,</span> <span class="n">Input</span>
    
<span class="k">def</span> <span class="nf">get_model8</span><span class="p">():</span>
    
    <span class="n">inputs</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Input</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">))</span>
    <span class="n">outputs</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s2">&quot;linear&quot;</span><span class="p">)(</span><span class="n">inputs</span><span class="p">)</span>
    
    <span class="n">model</span> <span class="o">=</span> <span class="n">CustomModel</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">outputs</span><span class="p">)</span>
    
    <span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">optimizer</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">optimizers</span><span class="o">.</span><span class="n">SGD</span><span class="p">(</span><span class="n">learning_rate</span><span class="o">=</span><span class="mf">0.02</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">model</span>
</pre></div>
</div>
</div>
</div>
<p>our custom loop (<strong>for any model</strong> !!!)</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">get_model8</span><span class="p">()</span>
<span class="n">model</span><span class="o">.</span><span class="n">summary</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Model: &quot;custom_model_3&quot;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_4 (InputLayer)         [(None, 1)]               0         
_________________________________________________________________
dense_15 (Dense)             (None, 1)                 2         
=================================================================
Total params: 2
Trainable params: 2
Non-trainable params: 0
_________________________________________________________________
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">weights</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[&lt;tf.Variable &#39;dense_15/kernel:0&#39; shape=(1, 1) dtype=float32, numpy=array([[0.79911673]], dtype=float32)&gt;,
 &lt;tf.Variable &#39;dense_15/bias:0&#39; shape=(1,) dtype=float32, numpy=array([0.], dtype=float32)&gt;]
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">trainable_variables</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[&lt;tf.Variable &#39;dense_15/kernel:0&#39; shape=(1, 1) dtype=float32, numpy=array([[0.79911673]], dtype=float32)&gt;,
 &lt;tf.Variable &#39;dense_15/bias:0&#39; shape=(1,) dtype=float32, numpy=array([0.], dtype=float32)&gt;]
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span><span class="n">y_train</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">),</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">16</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">validation_data</span><span class="o">=</span><span class="p">(</span><span class="n">X_val</span><span class="p">,</span> <span class="n">y_val</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;tensorflow.python.keras.callbacks.History at 0x7fa1b5c35040&gt;
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">trainable_variables</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[&lt;tf.Variable &#39;dense_15/kernel:0&#39; shape=(1, 1) dtype=float32, numpy=array([[-0.4444475]], dtype=float32)&gt;,
 &lt;tf.Variable &#39;dense_15/bias:0&#39; shape=(1,) dtype=float32, numpy=array([11.331306], dtype=float32)&gt;]
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">predictions</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
<span class="n">rmse</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">((</span><span class="n">predictions</span><span class="o">-</span><span class="n">y</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span><span class="mi">2</span><span class="p">));</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">history</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="s2">&quot;loss&quot;</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;train&quot;</span><span class="p">);</span> 
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">history</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="s2">&quot;val_loss&quot;</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;val&quot;</span><span class="p">);</span> 
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;step number&quot;</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;loss&quot;</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">();</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;RMSE </span><span class="si">%.3f</span><span class="s2">&quot;</span><span class="o">%</span><span class="k">rmse</span>); plt.legend();
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/U3.02 - TF for symbolic computing_80_0.png" src="../_images/U3.02 - TF for symbolic computing_80_0.png" />
</div>
</div>
</div>
<div class="section" id="version-9-using-train-on-batch-rightarrow-control-data">
<h2>Version 9: using <code class="docutils literal notranslate"><span class="pre">train_on_batch</span></code> <span class="math notranslate nohighlight">\(\rightarrow\)</span> control data<a class="headerlink" href="#version-9-using-train-on-batch-rightarrow-control-data" title="Permalink to this headline">¶</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">epochs</span> <span class="o">=</span> <span class="mi">400</span>
<span class="n">batch_size</span> <span class="o">=</span> <span class="mi">5</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">get_model8</span><span class="p">()</span>
<span class="n">h</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="n">pbar</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">epochs</span><span class="p">)):</span>
    <span class="n">idxs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">permutation</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">X</span><span class="p">))</span>
    <span class="k">for</span> <span class="n">step</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">X</span><span class="p">)</span><span class="o">//</span><span class="n">batch_size</span><span class="o">+</span><span class="p">((</span><span class="nb">len</span><span class="p">(</span><span class="n">X</span><span class="p">)</span><span class="o">%</span><span class="k">batch_size</span>)!=0)):
        <span class="n">X_batch</span> <span class="o">=</span> <span class="n">X</span><span class="p">[</span><span class="n">idxs</span><span class="p">][</span><span class="n">step</span><span class="o">*</span><span class="n">batch_size</span><span class="p">:(</span><span class="n">step</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span><span class="o">*</span><span class="n">batch_size</span><span class="p">]</span>
        <span class="n">y_batch</span> <span class="o">=</span> <span class="n">y</span><span class="p">[</span><span class="n">idxs</span><span class="p">][</span><span class="n">step</span><span class="o">*</span><span class="n">batch_size</span><span class="p">:(</span><span class="n">step</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span><span class="o">*</span><span class="n">batch_size</span><span class="p">]</span>       
        <span class="n">model</span><span class="o">.</span><span class="n">train_on_batch</span><span class="p">(</span><span class="n">X_batch</span><span class="p">,</span> <span class="n">y_batch</span><span class="p">)</span>
    <span class="n">h</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">test_step</span><span class="p">([</span><span class="n">X_batch</span><span class="p">,</span> <span class="n">y_batch</span><span class="p">])[</span><span class="s1">&#39;loss&#39;</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>100% (400 of 400) |######################| Elapsed Time: 0:00:24 Time:  0:00:24
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">trainable_variables</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[&lt;tf.Variable &#39;dense_22/kernel:0&#39; shape=(1, 1) dtype=float32, numpy=array([[0.14408377]], dtype=float32)&gt;,
 &lt;tf.Variable &#39;dense_22/bias:0&#39; shape=(1,) dtype=float32, numpy=array([10.004782], dtype=float32)&gt;]
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">predictions</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>

<span class="n">rmse</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_mean</span><span class="p">((</span><span class="n">predictions</span><span class="o">-</span><span class="n">y</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span><span class="mi">2</span><span class="p">));</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">h</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;step number&quot;</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;loss&quot;</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">();</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;RMSE </span><span class="si">%.3f</span><span class="s2">&quot;</span><span class="o">%</span><span class="k">rmse</span>);
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/U3.02 - TF for symbolic computing_85_0.png" src="../_images/U3.02 - TF for symbolic computing_85_0.png" />
</div>
</div>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "p38"
        },
        kernelOptions: {
            kernelName: "p38",
            path: "./content"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'p38'</script>

              </div>
              
        </div>
    </div>
    
    
    <div class='prev-next-bottom'>
        
    <a class='left-prev' id="prev-link" href="U3.01%20-%20Simbolic%20computing%20for%20ML.html" title="previous page">3.1 - Symbolic computing for ML</a>
    <a class='right-next' id="next-link" href="U3.03%20-%20Using%20tf.function.html" title="next page">3.3 - Using <code class="docutils literal notranslate"><span class="pre">tf.function</span></code></a>

    </div>
    <footer class="footer mt-5 mt-md-0">
    <div class="container">
      <p>
        
          By Raúl Ramos, Julián Arias / Universidad de Antioquia<br/>
        
            &copy; Copyright 2020.<br/>
      </p>
    </div>
  </footer>
</main>


      </div>
    </div>

    
  <script src="../_static/js/index.3da636dd464baa7582d2.js"></script>


    
    <!-- Google Analytics -->
    <script>
      window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;
      ga('create', 'UA-43235448-3', 'auto');
      ga('set', 'anonymizeIp', true);
      ga('send', 'pageview');
    </script>
    <script async src='https://www.google-analytics.com/analytics.js'></script>
    <!-- End Google Analytics -->
    
  </body>
</html>