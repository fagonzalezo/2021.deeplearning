
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>02 - NEURAL NETWORKS &#8212; Fundamentos de Deep Learning</title>
    
  <link rel="stylesheet" href="../_static/css/index.f658d18f9b420779cfdf24aa0a7e2d77.css">

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      
  <link rel="stylesheet"
    href="../_static/vendor/open-sans_all/1.44.1/index.css">
  <link rel="stylesheet"
    href="../_static/vendor/lato_latin-ext/1.44.1/index.css">

    
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="../_static/sphinx-book-theme.40e2e510f6b7d1648584402491bb10fe.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="../_static/js/index.d3f166471bb80abb5163.js">

    <script id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/togglebutton.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script >var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../_static/sphinx-book-theme.d31b09fe5c1d09cb49b26a786de4a05d.js"></script>
    <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["\\(", "\\)"]], "displayMath": [["\\[", "\\]"]], "processRefs": false, "processEnvironments": false}})</script>
    <script async="async" src="https://unpkg.com/thebelab@latest/lib/index.js"></script>
    <script >
        const thebe_selector = ".thebe"
        const thebe_selector_input = "pre"
        const thebe_selector_output = ".output"
    </script>
    <script async="async" src="../_static/sphinx-thebe.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="2.1 - The Perceptron" href="U2.01%20-%20The%20Perceptron.html" />
    <link rel="prev" title="LAB 01.01 - WARM UP" href="U1%20LAB%2001%20-%20WARMUP.html" />

    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en" />



  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
<a class="navbar-brand text-wrap" href="../index.html">
  
  <img src="../_static/fudea.jpg" class="logo" alt="logo">
  
  
  <h1 class="site-logo" id="site-title">Fundamentos de Deep Learning</h1>
  
</a>
</div><form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form>
<nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">
    <ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="../intro.html">
   Welcome
  </a>
 </li>
</ul>
<ul class="current nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="M00.html">
   Informaci√≥n 20211 - UdeA
  </a>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="M01.html">
   01 - INTRODUCTION
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="U1.01%20-%20DL%20Overview.html">
     1.1 - DL Overview
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="U1.02%20-%20Modelos%20derivados%20de%20los%20datos.html">
     1.2 - Models derived from data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="U1.03%20-%20Como%20se%20disena%20un%20algoritmo%20de%20Machine%20Learning.html">
     1.3 - ML algorithm design
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="U1%20LAB%2001%20-%20WARMUP.html">
     LAB 01.01 - WARM UP
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 current active collapsible-parent">
  <a class="current reference internal" href="#">
   02 - NEURAL NETWORKS
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="U2.01%20-%20The%20Perceptron.html">
     2.1 - The Perceptron
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="U2.02%20-%20The%20Multilayer%20Perceptron.html">
     2.2 - The Multilayer Perceptron
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="U2.03%20-%20Overfitting%20and%20regularization.html">
     2.3 - Overfitting and regularization
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="U2.04%20-%20Loss%20functions.html">
     2.4 - Loss functions in Tensorflow
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="U2.05%20-%20Network%20Architectures%20-%20Autoencoders.html">
     2.5 - Autoencoders
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="U2.06%20-%20Network%20Architectures%20-%20Multimodal%20information.html">
     2.6 - Multimodal architectures
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="U2.07%20-%20Vanishing%20gradients.html">
     2.7 - Vanishing gradients
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="U2.08%20-%20Weights%20initialization.html">
     2.8 - Weights initialization
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="U2%20LAB%2001%20-%20Customized%20loss%20functions%20and%20regularization.html">
     LAB 2.1 - Customized loss function
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="U2%20LAB%2002%20-%20Autoencoders.html">
     LAB 2.2 - Sparse Autoencoders
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="U2%20LAB%2003%20-%20Pairwise%20image%20classification.html">
     LAB 2.3 - Parwise classification
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="U2%20LAB%2004%20-%20Model%20instrumentation%20and%20monitoring.html">
     LAB 2.4 - Model instrumentation
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="M03.html">
   03 - TENSORFLOW CORE
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="U3.01%20-%20Simbolic%20computing%20for%20ML.html">
     3.1 - Symbolic computing for ML
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="U3.02%20-%20TF%20for%20symbolic%20computing.html">
     3.2 - TF symbolic engine
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="U3.03%20-%20Using%20tf.function.html">
     3.3 - Using
     <code class="docutils literal notranslate">
      <span class="pre">
       tf.function
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="U3.04%20-%20Batch%20Normalization.html">
     3.4 - Batch normalization
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="U3%20LAB%2001%20-%20Tensorflow%20model%20subclassing.html">
     LAB 3.1 - TF model subclassing
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="U3%20LAB%2002%20-%20Low%20level%20Tensorflow.html">
     LAB 3.2 - Low level
     <code class="docutils literal notranslate">
      <span class="pre">
       tensorflow
      </span>
     </code>
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="M04.html">
   04 - CONVOLUTIONAL NETWORKS
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="U4.01%20-%20Convolutions.html">
     4.1 - Convolutions
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="U4.02%20-%20Convolutional%20Neural%20Networks.html">
     4.2 - CNNs
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="U4.03%20-%20Transfer%20learning.html">
     4.3 - Transfer learning
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="U4.04%20-%20Object%20Detection.html">
     4.4 - Object detection
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="U4.05%20-%20Transposed%20convolutions.html">
     4.5 - Transposed convolutions
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="U4.06%20-%20Image%20segmentation.html">
     4.6 - Image segmentation
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
</ul>

</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="row topbar fixed-top container-xl">
    <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show">
    </div>
    <div class="col pl-2 topbar-main">
        
        <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
            data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
            aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
            title="Toggle navigation" data-toggle="tooltip" data-placement="left">
            <i class="fas fa-bars"></i>
            <i class="fas fa-arrow-left"></i>
            <i class="fas fa-arrow-up"></i>
        </button>
        
        
<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="../_sources/content/M02.md"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.md</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
            onClick="window.print()" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
</div>

        <!-- Source interaction buttons -->


        <!-- Full screen (wrap in <a> to have style consistency -->
        <a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
                data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
                title="Fullscreen mode"><i
                    class="fas fa-expand"></i></button></a>

        <!-- Launch buttons -->

    </div>

    <!-- Table of contents -->
    <div class="d-none d-md-block col-md-2 bd-toc show">
        
        <div class="tocsection onthispage pt-5 pb-3">
            <i class="fas fa-list"></i> Contents
        </div>
        <nav id="bd-toc-nav">
            <ul class="nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#redes-de-neuronas-artificiales">
   Redes de neuronas artificiales
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#laboratorio">
     LABORATORIO
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#autoencoders">
   Autoencoders
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id1">
     LABORATORIO
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#arquitecturas-multimodales">
   Arquitecturas multimodales
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id2">
     LABORATORIO
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#the-vanishing-gradient">
   The Vanishing Gradient
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#inicializacion-de-pesos">
   Inicializaci√≥n de pesos
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id3">
     LABORATORIO
    </a>
   </li>
  </ul>
 </li>
</ul>

        </nav>
        
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
        
              <div>
                
  <div class="section" id="neural-networks">
<h1>02 - NEURAL NETWORKS<a class="headerlink" href="#neural-networks" title="Permalink to this headline">¬∂</a></h1>
<div class="section" id="redes-de-neuronas-artificiales">
<h2>Redes de neuronas artificiales<a class="headerlink" href="#redes-de-neuronas-artificiales" title="Permalink to this headline">¬∂</a></h2>
<p><strong>1.1 - Introducci√≥n a las redes de neuronas artificiales</strong>: <a class="reference external" href="https://youtu.be/G1ymySPlh-0">Video 17mins</a><br/> Introducimos el concepto de redes de neuronas artificiales como una simplificaci√≥n de su an√°logo biol√≥gico.</p>
<p><strong>1.2 - Entrenamiento del perceptr√≥n</strong>: <a class="reference external" href="https://youtu.be/9wD-o2mHgyM">Video 11mins</a><br/> Describimos el algoritmo de entrenamiento del perceptr√≥n.</p>
<p><strong>1.3 - Perceptr√≥n multicapa</strong>: <a class="reference external" href="https://youtu.be/zS5WRTl8uvo">Video 14mins</a><br/> Ensamblamos una red de neuronas artificiales compuesta por varias capas de perceptrones.</p>
<p><strong>1.4 - Backpropagation</strong>: <a class="reference external" href="https://youtu.be/D8W1xryHKGo">Video 11mins</a><br/>Explicamos el algoritmo principal para entrenar redes neuronales.</p>
<p><strong>1.5 - Funciones de activaci√≥n</strong>: <a class="reference external" href="https://youtu.be/Lq0GXDxVNP0">Video 7mins</a><br/>Introducimos las funciones de activaci√≥n de neuronas y la funci√≥n softmax para la salida de la red.</p>
<p><strong>1.6 - Esquemas de entrenamiento</strong>: <a class="reference external" href="https://youtu.be/yFh4qIBW86s">Video 17mins</a><br/> Describimos distintas estrategias de entrenamiento: con batches, mini-batches y en l√≠nea y comprobamos experimentalmente su convergencia.</p>
<p><strong>1.7 - Sobreajuste (overfitting)</strong>: <a class="reference external" href="https://youtu.be/Vekgrq60Xx4">Video 15mins</a><br/>Explicamos la intuici√≥n de los errores de predicci√≥n por sobreajuste y algunas t√©cnicas para mitigarlo (early stopping, regularizaci√≥n)</p>
<p><strong>1.8 - Introducci√≥n a Keras</strong>: <a class="reference external" href="https://youtu.be/KwUiDqhwTcc">Video 22mins</a><br/>Damos las nociones fundamentales del uso de Keras, la librer√≠a de alto nivel de Tensorflow para la construcci√≥n de redes neuronales.</p>
<div class="section" id="laboratorio">
<h3>LABORATORIO<a class="headerlink" href="#laboratorio" title="Permalink to this headline">¬∂</a></h3>
<p><strong>LAB 1 - Customized loss function</strong>: <a class="reference external" href="https://youtu.be/_1nEydN1d-s">Video 6mins</a><br/>En este laboratorio crear√°s un modelo con Tensorflow/Keras y expandir√°s la funci√≥n de p√©rdida para la optimizaci√≥n con regularizadores L1 y L2.</p>
</div>
</div>
<div class="section" id="autoencoders">
<h2>Autoencoders<a class="headerlink" href="#autoencoders" title="Permalink to this headline">¬∂</a></h2>
<p><strong>2.1 - Introducci√≥n a autoencoders</strong>: <a class="reference external" href="https://youtu.be/k24X6la0vaU">Video 14mins</a> <br/>Introducimos la noci√≥n de autoencoder, como una arquitectura de red neuronal para aprendizaje no supervisado.</p>
<p><strong>2.2 - Autoencoders en Tensorflow</strong>: <a class="reference external" href="https://youtu.be/OFcST3ndQ4g">Video 9mins</a> <br/> Mostramos c√≥mo implementar autoencoders con Tensroflow y c√≥mo obtener la representaci√≥n en el espacio latente de nuevos datos de entrada.</p>
<p><strong>2.3 - Interpretabilidad de autoencoders</strong>: <a class="reference external" href="https://youtu.be/o9kUgnxmsfI">Video 13mins</a> <br/>Ilustramos c√≥mo podemos darle significado intuitivo a los pesos <em>aprendidos</em> por un autoencoder.</p>
<p><strong>2.4 - Interpretabilidad de autoencoders (2)</strong>: <a class="reference external" href="https://youtu.be/2W27N9iEzek">Video 4mins</a> <br/>Puntualizamos un aspecto del video anterior.</p>
<p><strong>2.5 - Denoising autoencoders</strong>: <a class="reference external" href="https://youtu.be/U6QHAX8cx0w">Video 10mins</a> <br/>Explicamos c√≥mo se pueden usar los autoencoders para aplicaciones de eliminaci√≥n de ruido.</p>
<div class="section" id="id1">
<h3>LABORATORIO<a class="headerlink" href="#id1" title="Permalink to this headline">¬∂</a></h3>
<p><strong>LAB 2 - Sparse autoencoders</strong>: <a class="reference external" href="https://youtu.be/6njflcFHjW8">Video 9mins</a><br/>En este laboratorio crear√°s un <strong>Sparse Autoencoder</strong> en el que las neuronas de la representaci√≥n latente adquirir√°n funciones m√°s especializadas.</p>
</div>
</div>
<div class="section" id="arquitecturas-multimodales">
<h2>Arquitecturas multimodales<a class="headerlink" href="#arquitecturas-multimodales" title="Permalink to this headline">¬∂</a></h2>
<p><strong>3.1 - Problemas multimodales</strong>: <a class="reference external" href="https://youtu.be/shfKOfA1Cxc">Video 11mins</a> <br/>Describimos el caso de uso en el que tenemos varias fuentes de informaci√≥n de naturaleza distinta de cada objeto de nuestro dataset (p.ej. im√°genes y datos vectoriales), y queremos generar modelos que se aprovechen de esa informaci√≥n.</p>
<p><strong>3.2 - Arquitecturas multimodales en Tensorflow</strong>: <a class="reference external" href="https://youtu.be/tBiMNVH4yF8">Video 15mins</a> <br/>Explicamos c√≥mo podemos usar el API funcional de Tensorflow para construir redes que solucionen problemas multimodales.</p>
<div class="section" id="id2">
<h3>LABORATORIO<a class="headerlink" href="#id2" title="Permalink to this headline">¬∂</a></h3>
<p><strong>LAB 3 - Pair-wise image classification</strong>: <a class="reference external" href="https://youtu.be/H6u5ECdNaRA">Video 9mins</a><br/>En este laboratorio montar√°s una arquitectura de red con m√∫ltiples entradas para una tarea de clasificaci√≥n de pares de im√°genes.</p>
</div>
</div>
<div class="section" id="the-vanishing-gradient">
<h2>The Vanishing Gradient<a class="headerlink" href="#the-vanishing-gradient" title="Permalink to this headline">¬∂</a></h2>
<p><strong>4.1 - El gradiente desvaneciente</strong>: <a class="reference external" href="https://youtu.be/pkR-D7GwDTY">Video 15min</a> <br/> Describimos uno de los problemas que impiden que las redes neuronales se puedan entrenar.</p>
<p><strong>4.2 - Histogramas de pesos</strong>: <a class="reference external" href="https://youtu.be/9HH8kpEkN8I">Video 8mins</a> <br/>Mostramos c√≥mo podemos hacerle seguimiento a la evoluci√≥n de los pesos de una red durante el entrenamiento.</p>
<p><strong>4.3 - Observando el gradiente desvaneciente con TensorBoard</strong>: <a class="reference external" href="https://youtu.be/jsuYeOGUJng">Video 15mins</a> <br/>Desarrollamos un caso pr√°ctico donde mostramos como utilizar TensorBoard para inspeccionar la evoluci√≥n de los pesos de una red durante el entrenamiento.</p>
</div>
<div class="section" id="inicializacion-de-pesos">
<h2>Inicializaci√≥n de pesos<a class="headerlink" href="#inicializacion-de-pesos" title="Permalink to this headline">¬∂</a></h2>
<p><strong>5.1 - Estrategias para acelerar el entrenamiento</strong>: <a class="reference external" href="https://youtu.be/Gv_m-u-G7pI">Video 6mins</a> <br/> Ponemos en perspectiva las distintas aproximaciones que estamos desarrollando para solventar los problemas del gradiente en el entrenamiento de las redes neuronales.</p>
<p><strong>5.2 - Inicializaci√≥n de pesos</strong>: <a class="reference external" href="https://youtu.be/dSsqXY_ypNQ">Video 18mins</a> <br/> Explicamos la intuici√≥n y la justificaci√≥n de las estrategias de inicializaci√≥n de pesos.</p>
<p><strong>5.3 - Observando los efectos de la inicializaci√≥n de pesos</strong>: <a class="reference external" href="https://youtu.be/-PVjugMJ9No">Video 18mins</a> <br/> Desarrollamos unos experimentos para poder observar en la pr√°ctica lo aprendido anteriormente.</p>
<div class="section" id="id3">
<h3>LABORATORIO<a class="headerlink" href="#id3" title="Permalink to this headline">¬∂</a></h3>
<p><strong>LAB 4 - Tensorflow callbacks</strong>: <a class="reference external" href="https://youtu.be/AiUBwWV3tgs">Video 8mins</a><br/>El objetivo de este laboratorio es que te familiarices con el mecanismo de callbacks de Tensorflow con el cual podr√°s incluir instrumentaci√≥n en tu modelo para realizarle seguimiento a lo que necesites durante el entrenamiento del mismo.</p>
<div class="toctree-wrapper compound">
</div>
</div>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./content"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
        </div>
    </div>
    
    
    <div class='prev-next-bottom'>
        
    <a class='left-prev' id="prev-link" href="U1%20LAB%2001%20-%20WARMUP.html" title="previous page">LAB 01.01 - WARM UP</a>
    <a class='right-next' id="next-link" href="U2.01%20-%20The%20Perceptron.html" title="next page">2.1 - The Perceptron</a>

    </div>
    <footer class="footer mt-5 mt-md-0">
    <div class="container">
      <p>
        
          By Ra√∫l Ramos, Juli√°n Arias / Universidad de Antioquia<br/>
        
            &copy; Copyright 2020.<br/>
      </p>
    </div>
  </footer>
</main>


      </div>
    </div>

    
  <script src="../_static/js/index.d3f166471bb80abb5163.js"></script>


    
    <!-- Google Analytics -->
    <script>
      window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;
      ga('create', 'UA-43235448-3', 'auto');
      ga('set', 'anonymizeIp', true);
      ga('send', 'pageview');
    </script>
    <script async src='https://www.google-analytics.com/analytics.js'></script>
    <!-- End Google Analytics -->
    
  </body>
</html>